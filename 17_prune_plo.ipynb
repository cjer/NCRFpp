{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.034028Z",
     "start_time": "2019-03-13T07:20:22.687626Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.382406Z",
     "start_time": "2019-03-13T07:20:24.037019Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:27.996727Z",
     "start_time": "2019-03-13T07:20:24.385088Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get token data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nlp/danb')\n",
    "sys.path.append('/home/nlp/danb/NER')\n",
    "\n",
    "import bclm\n",
    "import ne_evaluate_mentions as nem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CDT</td>\n",
       "      <td>CDT</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>הנשים</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|gen=M|num=S|per=1|tense=FUTURE</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>איש</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>מ</td>\n",
       "      <td>מ</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>ל</td>\n",
       "      <td>ל</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2     form    lemma      upostag      xpostag  \\\n",
       "0    0   1    עשרות      עשר          CDT          CDT   \n",
       "1    0   1    עשרות      עשר           CD           CD   \n",
       "2    1   2    אנשים    הנשים           VB           VB   \n",
       "3    1   2    אנשים      איש           NN           NN   \n",
       "4    2   3   מגיעים     הגיע           VB           VB   \n",
       "5    2   3   מגיעים     הגיע           BN           BN   \n",
       "6    3   4        מ        מ  PREPOSITION  PREPOSITION   \n",
       "7    3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "8    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "9    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "10   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "11   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "12   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "13   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "14   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "15   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "16   4   5   תאילנד   תאילנד          NNP          NNP   \n",
       "17   5   6        ל        ל  PREPOSITION  PREPOSITION   \n",
       "18   5   8   לישראל   לישראל          NNP          NNP   \n",
       "19   5   8   לישראל   לישראל           NN           NN   \n",
       "\n",
       "                                   feats token_id  sent_id  \n",
       "0                            gen=F|num=P        1        1  \n",
       "1                            gen=F|num=P        1        1  \n",
       "2   gen=F|gen=M|num=S|per=1|tense=FUTURE        2        1  \n",
       "3                            gen=M|num=P        2        1  \n",
       "4        gen=M|num=P|per=A|tense=BEINONI        3        1  \n",
       "5                      gen=M|num=P|per=A        3        1  \n",
       "6                                      _        4        1  \n",
       "7                            gen=M|num=S        4        1  \n",
       "8                      gen=M|num=P|num=S        4        1  \n",
       "9                            gen=M|num=S        4        1  \n",
       "10                           gen=F|num=S        4        1  \n",
       "11                     gen=F|gen=M|num=S        4        1  \n",
       "12                                     _        4        1  \n",
       "13                           gen=M|num=P        4        1  \n",
       "14                           gen=F|num=S        4        1  \n",
       "15                           gen=F|num=P        4        1  \n",
       "16                           gen=F|num=S        4        1  \n",
       "17                                     _        5        1  \n",
       "18                           gen=M|num=S        5        1  \n",
       "19                     gen=M|num=P|num=S        5        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_lat = bclm.read_lattices(bclm.LATTICES_PATHS['dev'])\n",
    "dev_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>הכל</td>\n",
       "      <td>הכיל</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נושא</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>עם</td>\n",
       "      <td>עם</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עם</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=3|tense=PAST</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>הם</td>\n",
       "      <td>הם</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>gen=M|num=P|per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>הוא</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "      <td>gen=F|num=S|per=2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>את</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NNT</td>\n",
       "      <td>NNT</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>הקליטה</td>\n",
       "      <td>הקליט</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|num=S|per=3|tense=PAST</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2      form   lemma upostag xpostag  \\\n",
       "0    0   1         ה       ה     DEF     DEF   \n",
       "1    0   2         ה       ה     REL     REL   \n",
       "2    0   3       הכל    הכיל      VB      VB   \n",
       "3    1   3        כל     כול     DTT     DTT   \n",
       "4    2   3        כל     כול     DTT     DTT   \n",
       "5    3   4    נושאים     נשא      VB      VB   \n",
       "6    3   4    נושאים    נושא      NN      NN   \n",
       "7    3   4    נושאים     נשא      BN      BN   \n",
       "8    4   5        עם      עם      IN      IN   \n",
       "9    4   6       עמם    עימם      VB      VB   \n",
       "10   4   6       עמם      עם      NN      NN   \n",
       "11   4   6       עמם    עימם      VB      VB   \n",
       "12   5   6        הם      הם   S_PRN   S_PRN   \n",
       "13   6   7        את     הוא     PRP     PRP   \n",
       "14   6   7        את      את      AT      AT   \n",
       "15   7   8  כישלונות  כישלון     NNT     NNT   \n",
       "16   7   8  כישלונות  כישלון      NN      NN   \n",
       "17   8   9         ה       ה     DEF     DEF   \n",
       "18   8  10         ה       ה     REL     REL   \n",
       "19   8  11    הקליטה   הקליט      VB      VB   \n",
       "\n",
       "                                        feats token_id  sent_id  \n",
       "0                                           _        1        1  \n",
       "1                                           _        1        1  \n",
       "2          gen=M|num=S|per=2|tense=IMPERATIVE        1        1  \n",
       "3                                           _        1        1  \n",
       "4                                           _        1        1  \n",
       "5             gen=M|num=P|per=A|tense=BEINONI        2        1  \n",
       "6                                 gen=M|num=P        2        1  \n",
       "7                           gen=M|num=P|per=A        2        1  \n",
       "8                                           _        3        1  \n",
       "9          gen=M|num=S|per=2|tense=IMPERATIVE        3        1  \n",
       "10  gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3        3        1  \n",
       "11               gen=M|num=S|per=3|tense=PAST        3        1  \n",
       "12                          gen=M|num=P|per=3        3        1  \n",
       "13                          gen=F|num=S|per=2        4        1  \n",
       "14                                          _        4        1  \n",
       "15                                gen=M|num=P        5        1  \n",
       "16                                gen=M|num=P        5        1  \n",
       "17                                          _        6        1  \n",
       "18                                          _        6        1  \n",
       "19               gen=F|num=S|per=3|tense=PAST        6        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lat = bclm.read_lattices(bclm.LATTICES_PATHS['test'])\n",
    "test_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose_layer0</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>O</td>\n",
       "      <td>CDT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>O</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str biose_layer0          upostag  set\n",
       "0        1         1     עשרות            O              CDT  dev\n",
       "1        1         2     אנשים            O               NN  dev\n",
       "2        1         3    מגיעים            O               BN  dev\n",
       "3        1         4   מתאילנד      O^S-GPE  PREPOSITION^NNP  dev\n",
       "4        1         5    לישראל      O^S-GPE  PREPOSITION^NNP  dev"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped = [5438, 5444, 5445, 5446, 5448, 5449, 5450, 5451, 5453, 5459]\n",
    "spdf = bclm.read_dataframe('spmrl')\n",
    "spdf = spdf[(~spdf.sent_id.isin(dropped))]\n",
    "tokens_ner_with_upos = bclm.get_token_df(spdf, fields = ['biose_layer0', 'upostag'])\n",
    "tokens_ner_with_upos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "dev         1\n",
       "test     5439\n",
       "train     501\n",
       "Name: sent_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdf.groupby('set').sent_id.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_gold_sents =   tokens_ner_with_upos.groupby('sent_id')[['token_str', 'biose_layer0']].apply(lambda x: x.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biose_count(path, sent_id_shift=1):\n",
    "    sents = nem.read_file_sents(path, fix_multi_tag=False, sent_id_shift=sent_id_shift)\n",
    "    bc = []\n",
    "    for i, sent in sents.iteritems():\n",
    "        for j, (tok, bio) in enumerate(sent):\n",
    "            bc.append([i, j+1, tok, bio, len(bio.split('^'))])\n",
    "\n",
    "    bc = pd.DataFrame(bc, columns=['sent_id', 'token_id', 'token_str', \n",
    "                                   'biose', 'biose_count'])\n",
    "    return bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_edges(lattices, bc,\n",
    "                    non_o_only=True, keep_all_if_no_valid=True):\n",
    "    valid_edges = []\n",
    "    for (i, df), (_, biose, biose_count) in zip(lattices.groupby(['sent_id', 'token_id']), \n",
    "                                                bc[['biose', 'biose_count']].itertuples()):\n",
    "        el = df[['ID1', 'ID2']].rename(columns={'ID1': 'source', 'ID2': 'target'})\n",
    "        #min_node = [n for n,v in G.nodes(data=True) if v['since'] == 'December 2008'][0]\n",
    "\n",
    "        g = nx.from_pandas_edgelist(el, create_using=nx.DiGraph)\n",
    "        min_node = el.source.min()\n",
    "        max_node = el.target.max()\n",
    "        #print(min_node,max_node)\n",
    "        #print(biose_count)\n",
    "        if non_o_only and not '-' in biose:\n",
    "            vp = list(nx.all_simple_paths(g, min_node, max_node))\n",
    "        else:\n",
    "            vp = [path for path in nx.all_simple_paths(g, min_node, max_node, cutoff=biose_count+1) if len(path)==biose_count+1]\n",
    "        if keep_all_if_no_valid and len(vp)==0:\n",
    "             vp = nx.all_simple_paths(g, min_node, max_node)\n",
    "        for path in vp:\n",
    "            for source, target in zip(path[:-1], path[1:]):\n",
    "                valid_edges.append((i[0], i[1], source, target))\n",
    "                \n",
    "    return valid_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lattices(df, path, cols = ['ID1', 'ID2', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'token_id']):\n",
    "    with open(path, 'w', encoding='utf8') as of:\n",
    "        for _, sent in df.groupby('sent_id'):\n",
    "            for _, row in sent[cols].iterrows():\n",
    "                of.write('\\t'.join(row.astype(str).tolist())+'\\n')\n",
    "            of.write('\\n')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>arch</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>cm</th>\n",
       "      <th>acc</th>\n",
       "      <th>model_base_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.945</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.51_seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unit       arch embed_type     cm    acc  \\\n",
       "4313  multitok  char_lstm     ft_oov  Match  0.945   \n",
       "\n",
       "                            model_base_name  \n",
       "4313  multitok.char_lstm.ft_oov_tok.51_seed  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erdf = pd.read_pickle('final_setup/plo_erdf.pkl')\n",
    "best_multi = (erdf.loc[(erdf.unit=='multitok') \n",
    "      & (erdf\n",
    "         .groupby(['unit', 'arch', 'embed_type', 'cm'])\n",
    "         .relevant_score\n",
    "         .transform(max)==erdf.relevant_score),\n",
    "         ['unit', 'arch', 'embed_type', 'cm', 'acc', 'model_base_name']]\n",
    " .sort_values('acc', ascending=False)\n",
    ")\n",
    "best_multi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'ID1', 'ID2']\n",
    "def get_pruned_lattice(lattices, bc, non_o_only=False):\n",
    "    valid_edges = get_valid_edges(lattices, bc, non_o_only=non_o_only)\n",
    "    pruned_lat = lattices[lattices[cols]\n",
    "                         .apply(lambda x: tuple(x) in valid_edges,\n",
    "                                axis=1)]\n",
    "    return pruned_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'final_setup/plo_decode_output'\n",
    "models_folder = 'final_setup/plo_models'\n",
    "pruned_folder = 'final_setup/plo_pruned/lattices'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_setup/plo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "final_setup/plo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n"
     ]
    }
   ],
   "source": [
    "for i, row in best_multi.iterrows():\n",
    "    pruned_dev_path =  os.path.join(pruned_folder, \n",
    "                                    'dev.'+row.model_base_name+'.lattices')\n",
    "    if not os.path.exists(pruned_dev_path):\n",
    "        print(pruned_dev_path)\n",
    "        dev_path = os.path.join(output_folder, \n",
    "                                'token_dev.'+row.model_base_name+'.bmes')\n",
    "        dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "        pdev_lat = get_pruned_lattice(dev_lat, dev_bc)\n",
    "        to_lattices(pdev_lat, pruned_dev_path)\n",
    "\n",
    "    pruned_test_path = os.path.join(pruned_folder, \n",
    "                                    'test.'+row.model_base_name+'.lattices')    \n",
    "    if not os.path.exists(pruned_test_path):\n",
    "        print(pruned_test_path)\n",
    "        test_path = os.path.join(output_folder, \n",
    "                                 'token_test.'+row.model_base_name+'.bmes')\n",
    "        test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "        ptest_lat = get_pruned_lattice(test_lat, test_bc)\n",
    "        to_lattices(ptest_lat, pruned_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run YAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_path = '/home/nlp/danb/yapproj/src/yap/yap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOPATH=/home/nlp/danb/yapproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/yapproj/src/yap/yap - invoke yap as a standalone app or as an api server\n",
      "\n",
      "Commands:\n",
      "\n",
      "    api         start api server\n",
      "    dep         runs dependency training/parsing\n",
      "    hebma       run lexicon-based morphological analyzer on raw input\n",
      "    joint       runs joint morpho-syntactic training and parsing\n",
      "    ma          run data-driven morphological analyzer on raw input\n",
      "    md          runs standalone morphological disambiguation training and parsing\n",
      "\n",
      "Use \"/home/nlp/danb/yapproj/src/yap/yap help <command>\" for more information about a command.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{yap_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_folder = 'final_setup/plo_pruned/lattices'\n",
    "yap_output_folder = 'final_setup/plo_pruned/yap_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/01/24 17:33:27.891920 GOMAXPROCS:\t40\n",
      "2020/01/24 17:33:27.892116 \n",
      "2020/01/24 17:33:27.892787 *** CONFIGURATION ***\n",
      "2020/01/24 17:33:27.892815 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/24 17:33:27.892857 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/24 17:33:27.892910 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/24 17:33:27.892932 Iterations:\t\t1\n",
      "2020/01/24 17:33:27.892952 Beam Size:\t\t64\n",
      "2020/01/24 17:33:27.892973 Beam Concurrent:\ttrue\n",
      "2020/01/24 17:33:27.892990 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/24 17:33:27.893007 Use Lemmas:\t\tfalse\n",
      "2020/01/24 17:33:27.893027 Use POP:\t\ttrue\n",
      "2020/01/24 17:33:27.893047 Infuse Gold Dev:\tfalse\n",
      "2020/01/24 17:33:27.893065 Limit (thousands):\t0\n",
      "2020/01/24 17:33:27.893081 Use CoNLL-U:\t\tfalse\n",
      "2020/01/24 17:33:27.893100 \n",
      "2020/01/24 17:33:27.893111 Features File:\tjointzeager.yaml\n",
      "2020/01/24 17:33:27.893673 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/24 17:33:27.894000 \n",
      "2020/01/24 17:33:27.894018 Data\n",
      "2020/01/24 17:33:27.894040 Test file  (ambig.  lattice):\tfinal_setup/plo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:33:27.894079 Out (disamb.) file:\t\t\tfinal_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.conll\n",
      "2020/01/24 17:33:27.894105 Out (segmt.) file:\t\t\tfinal_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.seg\n",
      "2020/01/24 17:33:27.894131 Out (mapping.) file:\t\t\tfinal_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.map\n",
      "2020/01/24 17:33:27.894787 \n",
      "2020/01/24 17:33:27.894810 Setup enumerations\n",
      "2020/01/24 17:33:27.894951 ETrans Len is 96\n",
      "2020/01/24 17:33:27.895296 \n",
      "2020/01/24 17:33:27.895319 Loading features\n",
      "2020/01/24 17:33:27.897103 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/24 17:33:27.897199 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/24 17:33:27.897330 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/24 17:33:27.897411 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/24 17:33:27.897448 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/24 17:33:27.897546 Loading POP transition dependent feature group POP\n",
      "2020/01/24 17:33:27.897582 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/24 17:33:27.897622 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/24 17:33:27.898089 \n",
      "2020/01/24 17:33:27.898125 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/24 17:33:27.898140 \n",
      "2020/01/24 17:33:27.898154 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/24 17:33:49.493320 Loaded model\n",
      "2020/01/24 17:33:49.493367 \n",
      "2020/01/24 17:33:49.493378 *** PARSING ***\n",
      "2020/01/24 17:33:49.493384 Parsing test\n",
      "2020/01/24 17:33:49.493402 Reading ambiguous lattices from final_setup/plo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:33:49.545592 Read 500 ambiguous lattices from final_setup/plo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:33:49.545655 Converting lattice format to internal structure\n",
      "2020/01/24 17:33:49.888825 Parsing instance 0\n",
      "2020/01/24 17:33:50.016808 Parsing instance 1\n",
      "2020/01/24 17:33:50.116118 Parsing instance 2\n",
      "2020/01/24 17:33:50.271143 Parsing instance 3\n",
      "2020/01/24 17:33:50.427666 Parsing instance 4\n",
      "2020/01/24 17:33:50.816870 Parsing instance 5\n",
      "2020/01/24 17:33:51.018468 Parsing instance 6\n",
      "2020/01/24 17:33:51.139076 Parsing instance 7\n",
      "2020/01/24 17:33:51.295389 Parsing instance 8\n",
      "2020/01/24 17:33:51.369031 Parsing instance 9\n",
      "2020/01/24 17:33:51.555341 Parsing instance 10\n",
      "2020/01/24 17:33:51.646266 Parsing instance 11\n",
      "2020/01/24 17:33:51.914035 Parsing instance 12\n",
      "2020/01/24 17:33:52.119373 Parsing instance 13\n",
      "2020/01/24 17:33:52.253963 Parsing instance 14\n",
      "2020/01/24 17:33:52.343415 Parsing instance 15\n",
      "2020/01/24 17:33:52.401541 Parsing instance 16\n",
      "2020/01/24 17:33:52.464442 Parsing instance 17\n",
      "2020/01/24 17:33:52.532620 Parsing instance 18\n",
      "2020/01/24 17:33:52.642529 Parsing instance 19\n",
      "2020/01/24 17:33:52.734477 Parsing instance 20\n",
      "2020/01/24 17:33:52.930114 Parsing instance 21\n",
      "2020/01/24 17:33:53.055819 Parsing instance 22\n",
      "2020/01/24 17:33:53.258008 Parsing instance 23\n",
      "2020/01/24 17:33:53.385618 Parsing instance 24\n",
      "2020/01/24 17:33:53.629759 Parsing instance 25\n",
      "2020/01/24 17:33:53.784555 Parsing instance 26\n",
      "2020/01/24 17:33:54.152818 Parsing instance 27\n",
      "2020/01/24 17:33:54.303445 Parsing instance 28\n",
      "2020/01/24 17:33:54.420479 Parsing instance 29\n",
      "2020/01/24 17:33:54.517123 Parsing instance 30\n",
      "2020/01/24 17:33:54.625168 Parsing instance 31\n",
      "2020/01/24 17:33:54.660650 Parsing instance 32\n",
      "2020/01/24 17:33:54.688677 Parsing instance 33\n",
      "2020/01/24 17:33:54.827104 Parsing instance 34\n",
      "2020/01/24 17:33:54.908912 Parsing instance 35\n",
      "2020/01/24 17:33:55.243513 Parsing instance 36\n",
      "2020/01/24 17:33:55.309325 Parsing instance 37\n",
      "2020/01/24 17:33:55.398672 Parsing instance 38\n",
      "2020/01/24 17:33:55.486105 Parsing instance 39\n",
      "2020/01/24 17:33:55.630118 Parsing instance 40\n",
      "2020/01/24 17:33:55.677555 Parsing instance 41\n",
      "2020/01/24 17:33:55.733894 Parsing instance 42\n",
      "2020/01/24 17:33:55.736581 Parsing instance 43\n",
      "2020/01/24 17:33:55.751721 Parsing instance 44\n",
      "2020/01/24 17:33:55.828990 Parsing instance 45\n",
      "2020/01/24 17:33:55.833917 Parsing instance 46\n",
      "2020/01/24 17:33:55.909563 Parsing instance 47\n",
      "2020/01/24 17:33:56.159875 Parsing instance 48\n",
      "2020/01/24 17:33:56.331029 Parsing instance 49\n",
      "2020/01/24 17:33:56.523478 Parsing instance 50\n",
      "2020/01/24 17:33:56.901814 Parsing instance 51\n",
      "2020/01/24 17:33:56.985414 Parsing instance 52\n",
      "2020/01/24 17:33:57.047013 Parsing instance 53\n",
      "2020/01/24 17:33:57.525330 Parsing instance 54\n",
      "2020/01/24 17:33:57.795926 Parsing instance 55\n",
      "2020/01/24 17:33:58.003198 Parsing instance 56\n",
      "2020/01/24 17:33:58.338605 Parsing instance 57\n",
      "2020/01/24 17:33:58.524235 Parsing instance 58\n",
      "2020/01/24 17:33:58.997042 Parsing instance 59\n",
      "2020/01/24 17:33:59.089259 Parsing instance 60\n",
      "2020/01/24 17:33:59.101388 Parsing instance 61\n",
      "2020/01/24 17:33:59.478966 Parsing instance 62\n",
      "2020/01/24 17:33:59.578178 Parsing instance 63\n",
      "2020/01/24 17:33:59.710432 Parsing instance 64\n",
      "2020/01/24 17:33:59.793620 Parsing instance 65\n",
      "2020/01/24 17:33:59.886321 Parsing instance 66\n",
      "2020/01/24 17:34:00.096505 Parsing instance 67\n",
      "2020/01/24 17:34:00.185966 Parsing instance 68\n",
      "2020/01/24 17:34:00.302382 Parsing instance 69\n",
      "2020/01/24 17:34:00.663805 Parsing instance 70\n",
      "2020/01/24 17:34:00.733079 Parsing instance 71\n",
      "2020/01/24 17:34:00.790339 Parsing instance 72\n",
      "2020/01/24 17:34:00.916938 Parsing instance 73\n",
      "2020/01/24 17:34:00.961983 Parsing instance 74\n",
      "2020/01/24 17:34:01.064722 Parsing instance 75\n",
      "2020/01/24 17:34:01.129492 Parsing instance 76\n",
      "2020/01/24 17:34:01.204524 Parsing instance 77\n",
      "2020/01/24 17:34:01.270262 Parsing instance 78\n",
      "2020/01/24 17:34:01.289242 Parsing instance 79\n",
      "2020/01/24 17:34:01.365897 Parsing instance 80\n",
      "2020/01/24 17:34:01.476441 Parsing instance 81\n",
      "2020/01/24 17:34:01.730499 Parsing instance 82\n",
      "2020/01/24 17:34:01.888470 Parsing instance 83\n",
      "2020/01/24 17:34:01.923984 Parsing instance 84\n",
      "2020/01/24 17:34:02.005540 Parsing instance 85\n",
      "2020/01/24 17:34:02.073563 Parsing instance 86\n",
      "2020/01/24 17:34:02.126122 Parsing instance 87\n",
      "2020/01/24 17:34:02.239569 Parsing instance 88\n",
      "2020/01/24 17:34:02.279450 Parsing instance 89\n",
      "2020/01/24 17:34:02.330906 Parsing instance 90\n",
      "2020/01/24 17:34:02.379789 Parsing instance 91\n",
      "2020/01/24 17:34:02.496925 Parsing instance 92\n",
      "2020/01/24 17:34:02.517461 Parsing instance 93\n",
      "2020/01/24 17:34:02.851482 Parsing instance 94\n",
      "2020/01/24 17:34:03.158969 Parsing instance 95\n",
      "2020/01/24 17:34:03.179451 Parsing instance 96\n",
      "2020/01/24 17:34:03.251426 Parsing instance 97\n",
      "2020/01/24 17:34:03.501341 Parsing instance 98\n",
      "2020/01/24 17:34:03.550481 Parsing instance 99\n",
      "2020/01/24 17:34:03.891927 Parsing instance 100\n",
      "2020/01/24 17:34:03.939462 Parsing instance 101\n",
      "2020/01/24 17:34:04.014253 Parsing instance 102\n",
      "2020/01/24 17:34:04.208779 Parsing instance 103\n",
      "2020/01/24 17:34:04.266221 Parsing instance 104\n",
      "2020/01/24 17:34:04.375557 Parsing instance 105\n",
      "2020/01/24 17:34:04.451097 Parsing instance 106\n",
      "2020/01/24 17:34:04.573073 Parsing instance 107\n",
      "2020/01/24 17:34:04.659073 Parsing instance 108\n",
      "2020/01/24 17:34:04.973302 Parsing instance 109\n",
      "2020/01/24 17:34:05.056196 Parsing instance 110\n",
      "2020/01/24 17:34:05.071583 Parsing instance 111\n",
      "2020/01/24 17:34:05.159556 Parsing instance 112\n",
      "2020/01/24 17:34:05.212433 Parsing instance 113\n",
      "2020/01/24 17:34:05.374423 Parsing instance 114\n",
      "2020/01/24 17:34:05.432499 Parsing instance 115\n",
      "2020/01/24 17:34:05.602032 Parsing instance 116\n",
      "2020/01/24 17:34:05.649873 Parsing instance 117\n",
      "2020/01/24 17:34:06.011156 Parsing instance 118\n",
      "2020/01/24 17:34:06.245467 Parsing instance 119\n",
      "2020/01/24 17:34:06.387695 Parsing instance 120\n",
      "2020/01/24 17:34:06.538096 Parsing instance 121\n",
      "2020/01/24 17:34:06.591724 Parsing instance 122\n",
      "2020/01/24 17:34:06.752789 Parsing instance 123\n",
      "2020/01/24 17:34:06.770930 Parsing instance 124\n",
      "2020/01/24 17:34:06.851479 Parsing instance 125\n",
      "2020/01/24 17:34:07.125336 Parsing instance 126\n",
      "2020/01/24 17:34:07.165038 Parsing instance 127\n",
      "2020/01/24 17:34:07.242005 Parsing instance 128\n",
      "2020/01/24 17:34:07.280053 Parsing instance 129\n",
      "2020/01/24 17:34:07.326495 Parsing instance 130\n",
      "2020/01/24 17:34:07.381654 Parsing instance 131\n",
      "2020/01/24 17:34:07.448069 Parsing instance 132\n",
      "2020/01/24 17:34:07.482960 Parsing instance 133\n",
      "2020/01/24 17:34:07.590606 Parsing instance 134\n",
      "2020/01/24 17:34:07.608879 Parsing instance 135\n",
      "2020/01/24 17:34:07.701866 Parsing instance 136\n",
      "2020/01/24 17:34:07.774213 Parsing instance 137\n",
      "2020/01/24 17:34:07.856041 Parsing instance 138\n",
      "2020/01/24 17:34:07.934476 Parsing instance 139\n",
      "2020/01/24 17:34:07.957580 Parsing instance 140\n",
      "2020/01/24 17:34:08.305236 Parsing instance 141\n",
      "2020/01/24 17:34:08.364573 Parsing instance 142\n",
      "2020/01/24 17:34:08.447290 Parsing instance 143\n",
      "2020/01/24 17:34:08.565489 Parsing instance 144\n",
      "2020/01/24 17:34:08.597437 Parsing instance 145\n",
      "2020/01/24 17:34:08.647444 Parsing instance 146\n",
      "2020/01/24 17:34:08.665741 Parsing instance 147\n",
      "2020/01/24 17:34:08.696104 Parsing instance 148\n",
      "2020/01/24 17:34:08.750030 Parsing instance 149\n",
      "2020/01/24 17:34:08.841371 Parsing instance 150\n",
      "2020/01/24 17:34:09.325476 Parsing instance 151\n",
      "2020/01/24 17:34:09.349159 Parsing instance 152\n",
      "2020/01/24 17:34:09.356876 Parsing instance 153\n",
      "2020/01/24 17:34:09.448607 Parsing instance 154\n",
      "2020/01/24 17:34:09.457744 Parsing instance 155\n",
      "2020/01/24 17:34:09.739569 Parsing instance 156\n",
      "2020/01/24 17:34:09.829709 Parsing instance 157\n",
      "2020/01/24 17:34:09.886442 Parsing instance 158\n",
      "2020/01/24 17:34:09.904474 Parsing instance 159\n",
      "2020/01/24 17:34:09.932742 Parsing instance 160\n",
      "2020/01/24 17:34:10.046977 Parsing instance 161\n",
      "2020/01/24 17:34:10.064444 Parsing instance 162\n",
      "2020/01/24 17:34:10.130553 Parsing instance 163\n",
      "2020/01/24 17:34:10.552200 Parsing instance 164\n",
      "2020/01/24 17:34:10.711637 Parsing instance 165\n",
      "2020/01/24 17:34:10.720915 Parsing instance 166\n",
      "2020/01/24 17:34:10.749156 Parsing instance 167\n",
      "2020/01/24 17:34:10.814002 Parsing instance 168\n",
      "2020/01/24 17:34:10.852533 Parsing instance 169\n",
      "2020/01/24 17:34:11.027997 Parsing instance 170\n",
      "2020/01/24 17:34:11.096098 Parsing instance 171\n",
      "2020/01/24 17:34:11.506700 Parsing instance 172\n",
      "2020/01/24 17:34:11.570328 Parsing instance 173\n",
      "2020/01/24 17:34:11.707178 Parsing instance 174\n",
      "2020/01/24 17:34:11.883034 Parsing instance 175\n",
      "2020/01/24 17:34:11.911894 Parsing instance 176\n",
      "2020/01/24 17:34:12.010322 Parsing instance 177\n",
      "2020/01/24 17:34:12.140809 Parsing instance 178\n",
      "2020/01/24 17:34:12.465447 Parsing instance 179\n",
      "2020/01/24 17:34:12.474458 Parsing instance 180\n",
      "2020/01/24 17:34:12.501584 Parsing instance 181\n",
      "2020/01/24 17:34:12.561227 Parsing instance 182\n",
      "2020/01/24 17:34:12.875317 Parsing instance 183\n",
      "2020/01/24 17:34:12.906361 Parsing instance 184\n",
      "2020/01/24 17:34:12.989264 Parsing instance 185\n",
      "2020/01/24 17:34:13.129736 Parsing instance 186\n",
      "2020/01/24 17:34:13.308322 Parsing instance 187\n",
      "2020/01/24 17:34:13.535955 Parsing instance 188\n",
      "2020/01/24 17:34:13.549422 Parsing instance 189\n",
      "2020/01/24 17:34:13.577665 Parsing instance 190\n",
      "2020/01/24 17:34:13.737682 Parsing instance 191\n",
      "2020/01/24 17:34:13.892509 Parsing instance 192\n",
      "2020/01/24 17:34:13.938502 Parsing instance 193\n",
      "2020/01/24 17:34:13.947960 Parsing instance 194\n",
      "2020/01/24 17:34:13.962125 Parsing instance 195\n",
      "2020/01/24 17:34:14.077608 Parsing instance 196\n",
      "2020/01/24 17:34:14.152311 Parsing instance 197\n",
      "2020/01/24 17:34:14.205565 Parsing instance 198\n",
      "2020/01/24 17:34:14.327248 Parsing instance 199\n",
      "2020/01/24 17:34:14.347120 Parsing instance 200\n",
      "2020/01/24 17:34:14.670830 Parsing instance 201\n",
      "2020/01/24 17:34:14.708149 Parsing instance 202\n",
      "2020/01/24 17:34:14.784876 Parsing instance 203\n",
      "2020/01/24 17:34:14.813984 Parsing instance 204\n",
      "2020/01/24 17:34:14.933921 Parsing instance 205\n",
      "2020/01/24 17:34:14.943557 Parsing instance 206\n",
      "2020/01/24 17:34:14.953303 Parsing instance 207\n",
      "2020/01/24 17:34:15.008723 Parsing instance 208\n",
      "2020/01/24 17:34:15.151142 Parsing instance 209\n",
      "2020/01/24 17:34:15.229196 Parsing instance 210\n",
      "2020/01/24 17:34:15.373615 Parsing instance 211\n",
      "2020/01/24 17:34:15.469130 Parsing instance 212\n",
      "2020/01/24 17:34:15.806240 Parsing instance 213\n",
      "2020/01/24 17:34:15.870830 Parsing instance 214\n",
      "2020/01/24 17:34:15.961839 Parsing instance 215\n",
      "2020/01/24 17:34:16.158200 Parsing instance 216\n",
      "2020/01/24 17:34:16.167676 Parsing instance 217\n",
      "2020/01/24 17:34:16.208947 Parsing instance 218\n",
      "2020/01/24 17:34:16.294424 Parsing instance 219\n",
      "2020/01/24 17:34:16.542882 Parsing instance 220\n",
      "2020/01/24 17:34:16.900848 Parsing instance 221\n",
      "2020/01/24 17:34:16.982013 Parsing instance 222\n",
      "2020/01/24 17:34:17.034281 Parsing instance 223\n",
      "2020/01/24 17:34:17.138161 Parsing instance 224\n",
      "2020/01/24 17:34:17.391088 Parsing instance 225\n",
      "2020/01/24 17:34:17.457521 Parsing instance 226\n",
      "2020/01/24 17:34:17.519229 Parsing instance 227\n",
      "2020/01/24 17:34:17.949892 Parsing instance 228\n",
      "2020/01/24 17:34:18.462914 Parsing instance 229\n",
      "2020/01/24 17:34:18.469095 Parsing instance 230\n",
      "2020/01/24 17:34:18.609834 Parsing instance 231\n",
      "2020/01/24 17:34:18.739750 Parsing instance 232\n",
      "2020/01/24 17:34:18.970575 Parsing instance 233\n",
      "2020/01/24 17:34:19.068797 Parsing instance 234\n",
      "2020/01/24 17:34:19.170763 Parsing instance 235\n",
      "2020/01/24 17:34:19.271212 Parsing instance 236\n",
      "2020/01/24 17:34:19.351927 Parsing instance 237\n",
      "2020/01/24 17:34:19.489003 Parsing instance 238\n",
      "2020/01/24 17:34:19.694548 Parsing instance 239\n",
      "2020/01/24 17:34:20.259204 Parsing instance 240\n",
      "2020/01/24 17:34:20.354025 Parsing instance 241\n",
      "2020/01/24 17:34:20.418851 Parsing instance 242\n",
      "2020/01/24 17:34:20.498736 Parsing instance 243\n",
      "2020/01/24 17:34:20.558619 Parsing instance 244\n",
      "2020/01/24 17:34:20.704197 Parsing instance 245\n",
      "2020/01/24 17:34:20.713635 Parsing instance 246\n",
      "2020/01/24 17:34:20.736661 Parsing instance 247\n",
      "2020/01/24 17:34:20.782604 Parsing instance 248\n",
      "2020/01/24 17:34:21.176460 Parsing instance 249\n",
      "2020/01/24 17:34:21.232827 Parsing instance 250\n",
      "2020/01/24 17:34:21.322118 Parsing instance 251\n",
      "2020/01/24 17:34:21.419711 Parsing instance 252\n",
      "2020/01/24 17:34:21.514043 Parsing instance 253\n",
      "2020/01/24 17:34:21.523801 Parsing instance 254\n",
      "2020/01/24 17:34:21.552316 Parsing instance 255\n",
      "2020/01/24 17:34:21.666964 Parsing instance 256\n",
      "2020/01/24 17:34:21.781105 Parsing instance 257\n",
      "2020/01/24 17:34:21.908471 Parsing instance 258\n",
      "2020/01/24 17:34:22.364378 Parsing instance 259\n",
      "2020/01/24 17:34:22.386710 Parsing instance 260\n",
      "2020/01/24 17:34:22.574252 Parsing instance 261\n",
      "2020/01/24 17:34:22.681358 Parsing instance 262\n",
      "2020/01/24 17:34:22.807358 Parsing instance 263\n",
      "2020/01/24 17:34:23.384846 Parsing instance 264\n",
      "2020/01/24 17:34:23.390520 Parsing instance 265\n",
      "2020/01/24 17:34:23.537144 Parsing instance 266\n",
      "2020/01/24 17:34:23.573464 Parsing instance 267\n",
      "2020/01/24 17:34:23.645764 Parsing instance 268\n",
      "2020/01/24 17:34:23.767617 Parsing instance 269\n",
      "2020/01/24 17:34:23.845557 Parsing instance 270\n",
      "2020/01/24 17:34:24.056616 Parsing instance 271\n",
      "2020/01/24 17:34:24.107141 Parsing instance 272\n",
      "2020/01/24 17:34:24.189442 Parsing instance 273\n",
      "2020/01/24 17:34:24.230047 Parsing instance 274\n",
      "2020/01/24 17:34:24.673836 Parsing instance 275\n",
      "2020/01/24 17:34:24.751481 Parsing instance 276\n",
      "2020/01/24 17:34:24.811592 Parsing instance 277\n",
      "2020/01/24 17:34:25.036067 Parsing instance 278\n",
      "2020/01/24 17:34:25.134201 Parsing instance 279\n",
      "2020/01/24 17:34:25.206048 Parsing instance 280\n",
      "2020/01/24 17:34:25.348900 Parsing instance 281\n",
      "2020/01/24 17:34:25.706795 Parsing instance 282\n",
      "2020/01/24 17:34:25.749537 Parsing instance 283\n",
      "2020/01/24 17:34:25.828115 Parsing instance 284\n",
      "2020/01/24 17:34:25.871194 Parsing instance 285\n",
      "2020/01/24 17:34:25.947282 Parsing instance 286\n",
      "2020/01/24 17:34:25.998941 Parsing instance 287\n",
      "2020/01/24 17:34:26.048478 Parsing instance 288\n",
      "2020/01/24 17:34:26.162382 Parsing instance 289\n",
      "2020/01/24 17:34:26.174396 Parsing instance 290\n",
      "2020/01/24 17:34:26.195219 Parsing instance 291\n",
      "2020/01/24 17:34:26.236624 Parsing instance 292\n",
      "2020/01/24 17:34:26.259049 Parsing instance 293\n",
      "2020/01/24 17:34:26.402453 Parsing instance 294\n",
      "2020/01/24 17:34:26.494865 Parsing instance 295\n",
      "2020/01/24 17:34:26.703521 Parsing instance 296\n",
      "2020/01/24 17:34:26.825679 Parsing instance 297\n",
      "2020/01/24 17:34:26.900292 Parsing instance 298\n",
      "2020/01/24 17:34:26.948457 Parsing instance 299\n",
      "2020/01/24 17:34:27.041957 Parsing instance 300\n",
      "2020/01/24 17:34:27.069489 Parsing instance 301\n",
      "2020/01/24 17:34:27.196042 Parsing instance 302\n",
      "2020/01/24 17:34:27.248071 Parsing instance 303\n",
      "2020/01/24 17:34:27.275758 Parsing instance 304\n",
      "2020/01/24 17:34:27.411669 Parsing instance 305\n",
      "2020/01/24 17:34:28.187286 Parsing instance 306\n",
      "2020/01/24 17:34:28.326885 Parsing instance 307\n",
      "2020/01/24 17:34:28.412016 Parsing instance 308\n",
      "2020/01/24 17:34:28.499494 Parsing instance 309\n",
      "2020/01/24 17:34:28.606896 Parsing instance 310\n",
      "2020/01/24 17:34:28.654240 Parsing instance 311\n",
      "2020/01/24 17:34:28.698281 Parsing instance 312\n",
      "2020/01/24 17:34:28.884221 Parsing instance 313\n",
      "2020/01/24 17:34:28.979256 Parsing instance 314\n",
      "2020/01/24 17:34:29.038010 Parsing instance 315\n",
      "2020/01/24 17:34:29.098403 Parsing instance 316\n",
      "2020/01/24 17:34:29.138302 Parsing instance 317\n",
      "2020/01/24 17:34:29.202515 Parsing instance 318\n",
      "2020/01/24 17:34:29.261833 Parsing instance 319\n",
      "2020/01/24 17:34:29.501256 Parsing instance 320\n",
      "2020/01/24 17:34:29.529334 Parsing instance 321\n",
      "2020/01/24 17:34:29.546622 Parsing instance 322\n",
      "2020/01/24 17:34:30.100314 Parsing instance 323\n",
      "2020/01/24 17:34:30.169816 Parsing instance 324\n",
      "2020/01/24 17:34:30.218810 Parsing instance 325\n",
      "2020/01/24 17:34:30.243062 Parsing instance 326\n",
      "2020/01/24 17:34:30.439031 Parsing instance 327\n",
      "2020/01/24 17:34:30.536768 Parsing instance 328\n",
      "2020/01/24 17:34:30.646080 Parsing instance 329\n",
      "2020/01/24 17:34:30.778725 Parsing instance 330\n",
      "2020/01/24 17:34:30.895137 Parsing instance 331\n",
      "2020/01/24 17:34:30.976877 Parsing instance 332\n",
      "2020/01/24 17:34:31.267386 Parsing instance 333\n",
      "2020/01/24 17:34:31.379657 Parsing instance 334\n",
      "2020/01/24 17:34:31.409658 Parsing instance 335\n",
      "2020/01/24 17:34:31.461796 Parsing instance 336\n",
      "2020/01/24 17:34:31.584078 Parsing instance 337\n",
      "2020/01/24 17:34:31.700138 Parsing instance 338\n",
      "2020/01/24 17:34:31.761419 Parsing instance 339\n",
      "2020/01/24 17:34:31.808953 Parsing instance 340\n",
      "2020/01/24 17:34:31.831787 Parsing instance 341\n",
      "2020/01/24 17:34:31.914829 Parsing instance 342\n",
      "2020/01/24 17:34:31.942852 Parsing instance 343\n",
      "2020/01/24 17:34:32.007291 Parsing instance 344\n",
      "2020/01/24 17:34:32.083013 Parsing instance 345\n",
      "2020/01/24 17:34:32.434144 Parsing instance 346\n",
      "2020/01/24 17:34:32.509996 Parsing instance 347\n",
      "2020/01/24 17:34:32.590055 Parsing instance 348\n",
      "2020/01/24 17:34:32.629116 Parsing instance 349\n",
      "2020/01/24 17:34:32.771006 Parsing instance 350\n",
      "2020/01/24 17:34:32.948600 Parsing instance 351\n",
      "2020/01/24 17:34:33.100119 Parsing instance 352\n",
      "2020/01/24 17:34:33.124518 Parsing instance 353\n",
      "2020/01/24 17:34:33.439655 Parsing instance 354\n",
      "2020/01/24 17:34:33.459518 Parsing instance 355\n",
      "2020/01/24 17:34:33.562255 Parsing instance 356\n",
      "2020/01/24 17:34:33.648585 Parsing instance 357\n",
      "2020/01/24 17:34:33.741846 Parsing instance 358\n",
      "2020/01/24 17:34:33.762192 Parsing instance 359\n",
      "2020/01/24 17:34:33.856412 Parsing instance 360\n",
      "2020/01/24 17:34:33.900865 Parsing instance 361\n",
      "2020/01/24 17:34:33.962717 Parsing instance 362\n",
      "2020/01/24 17:34:34.062042 Parsing instance 363\n",
      "2020/01/24 17:34:34.138839 Parsing instance 364\n",
      "2020/01/24 17:34:34.155441 Parsing instance 365\n",
      "2020/01/24 17:34:34.163676 Parsing instance 366\n",
      "2020/01/24 17:34:34.256556 Parsing instance 367\n",
      "2020/01/24 17:34:34.612124 Parsing instance 368\n",
      "2020/01/24 17:34:34.685881 Parsing instance 369\n",
      "2020/01/24 17:34:34.794930 Parsing instance 370\n",
      "2020/01/24 17:34:34.844056 Parsing instance 371\n",
      "2020/01/24 17:34:34.903812 Parsing instance 372\n",
      "2020/01/24 17:34:34.941531 Parsing instance 373\n",
      "2020/01/24 17:34:34.965386 Parsing instance 374\n",
      "2020/01/24 17:34:35.015872 Parsing instance 375\n",
      "2020/01/24 17:34:35.125606 Parsing instance 376\n",
      "2020/01/24 17:34:35.183094 Parsing instance 377\n",
      "2020/01/24 17:34:35.262785 Parsing instance 378\n",
      "2020/01/24 17:34:35.345539 Parsing instance 379\n",
      "2020/01/24 17:34:35.376910 Parsing instance 380\n",
      "2020/01/24 17:34:35.397133 Parsing instance 381\n",
      "2020/01/24 17:34:35.672166 Parsing instance 382\n",
      "2020/01/24 17:34:35.815652 Parsing instance 383\n",
      "2020/01/24 17:34:35.907037 Parsing instance 384\n",
      "2020/01/24 17:34:35.942872 Parsing instance 385\n",
      "2020/01/24 17:34:35.964458 Parsing instance 386\n",
      "2020/01/24 17:34:36.041714 Parsing instance 387\n",
      "2020/01/24 17:34:36.176469 Parsing instance 388\n",
      "2020/01/24 17:34:36.201329 Parsing instance 389\n",
      "2020/01/24 17:34:36.242754 Parsing instance 390\n",
      "2020/01/24 17:34:36.305226 Parsing instance 391\n",
      "2020/01/24 17:34:36.361865 Parsing instance 392\n",
      "2020/01/24 17:34:36.463324 Parsing instance 393\n",
      "2020/01/24 17:34:36.550770 Parsing instance 394\n",
      "2020/01/24 17:34:36.665366 Parsing instance 395\n",
      "2020/01/24 17:34:36.993520 Parsing instance 396\n",
      "2020/01/24 17:34:37.102617 Parsing instance 397\n",
      "2020/01/24 17:34:37.255061 Parsing instance 398\n",
      "2020/01/24 17:34:37.276660 Parsing instance 399\n",
      "2020/01/24 17:34:37.382004 Parsing instance 400\n",
      "2020/01/24 17:34:37.532171 Parsing instance 401\n",
      "2020/01/24 17:34:37.635789 Parsing instance 402\n",
      "2020/01/24 17:34:37.686535 Parsing instance 403\n",
      "2020/01/24 17:34:37.748357 Parsing instance 404\n",
      "2020/01/24 17:34:37.974757 Parsing instance 405\n",
      "2020/01/24 17:34:38.096412 Parsing instance 406\n",
      "2020/01/24 17:34:38.153841 Parsing instance 407\n",
      "2020/01/24 17:34:38.220199 Parsing instance 408\n",
      "2020/01/24 17:34:38.453889 Parsing instance 409\n",
      "2020/01/24 17:34:38.467782 Parsing instance 410\n",
      "2020/01/24 17:34:38.511373 Parsing instance 411\n",
      "2020/01/24 17:34:38.674605 Parsing instance 412\n",
      "2020/01/24 17:34:38.723645 Parsing instance 413\n",
      "2020/01/24 17:34:38.787624 Parsing instance 414\n",
      "2020/01/24 17:34:38.809383 Parsing instance 415\n",
      "2020/01/24 17:34:38.852308 Parsing instance 416\n",
      "2020/01/24 17:34:39.302851 Parsing instance 417\n",
      "2020/01/24 17:34:39.346257 Parsing instance 418\n",
      "2020/01/24 17:34:39.388302 Parsing instance 419\n",
      "2020/01/24 17:34:39.464407 Parsing instance 420\n",
      "2020/01/24 17:34:39.491288 Parsing instance 421\n",
      "2020/01/24 17:34:39.618597 Parsing instance 422\n",
      "2020/01/24 17:34:39.626379 Parsing instance 423\n",
      "2020/01/24 17:34:39.645537 Parsing instance 424\n",
      "2020/01/24 17:34:39.670075 Parsing instance 425\n",
      "2020/01/24 17:34:39.716489 Parsing instance 426\n",
      "2020/01/24 17:34:39.760047 Parsing instance 427\n",
      "2020/01/24 17:34:39.880097 Parsing instance 428\n",
      "2020/01/24 17:34:40.022795 Parsing instance 429\n",
      "2020/01/24 17:34:40.409289 Parsing instance 430\n",
      "2020/01/24 17:34:40.450384 Parsing instance 431\n",
      "2020/01/24 17:34:40.518085 Parsing instance 432\n",
      "2020/01/24 17:34:40.560374 Parsing instance 433\n",
      "2020/01/24 17:34:40.585802 Parsing instance 434\n",
      "2020/01/24 17:34:40.612398 Parsing instance 435\n",
      "2020/01/24 17:34:40.641403 Parsing instance 436\n",
      "2020/01/24 17:34:40.695141 Parsing instance 437\n",
      "2020/01/24 17:34:40.716277 Parsing instance 438\n",
      "2020/01/24 17:34:40.773712 Parsing instance 439\n",
      "2020/01/24 17:34:40.833491 Parsing instance 440\n",
      "2020/01/24 17:34:40.878813 Parsing instance 441\n",
      "2020/01/24 17:34:41.042023 Parsing instance 442\n",
      "2020/01/24 17:34:41.145293 Parsing instance 443\n",
      "2020/01/24 17:34:41.225913 Parsing instance 444\n",
      "2020/01/24 17:34:41.571580 Parsing instance 445\n",
      "2020/01/24 17:34:41.655890 Parsing instance 446\n",
      "2020/01/24 17:34:41.674910 Parsing instance 447\n",
      "2020/01/24 17:34:41.764004 Parsing instance 448\n",
      "2020/01/24 17:34:41.962487 Parsing instance 449\n",
      "2020/01/24 17:34:41.981824 Parsing instance 450\n",
      "2020/01/24 17:34:42.002019 Parsing instance 451\n",
      "2020/01/24 17:34:42.121852 Parsing instance 452\n",
      "2020/01/24 17:34:42.135947 Parsing instance 453\n",
      "2020/01/24 17:34:42.160283 Parsing instance 454\n",
      "2020/01/24 17:34:42.325518 Parsing instance 455\n",
      "2020/01/24 17:34:42.335471 Parsing instance 456\n",
      "2020/01/24 17:34:42.342500 Parsing instance 457\n",
      "2020/01/24 17:34:42.359705 Parsing instance 458\n",
      "2020/01/24 17:34:42.418606 Parsing instance 459\n",
      "2020/01/24 17:34:42.705996 Parsing instance 460\n",
      "2020/01/24 17:34:42.713607 Parsing instance 461\n",
      "2020/01/24 17:34:42.742287 Parsing instance 462\n",
      "2020/01/24 17:34:42.934908 Parsing instance 463\n",
      "2020/01/24 17:34:42.983360 Parsing instance 464\n",
      "2020/01/24 17:34:43.015631 Parsing instance 465\n",
      "2020/01/24 17:34:43.065489 Parsing instance 466\n",
      "2020/01/24 17:34:43.123556 Parsing instance 467\n",
      "2020/01/24 17:34:43.140980 Parsing instance 468\n",
      "2020/01/24 17:34:43.200847 Parsing instance 469\n",
      "2020/01/24 17:34:43.320610 Parsing instance 470\n",
      "2020/01/24 17:34:43.359746 Parsing instance 471\n",
      "2020/01/24 17:34:43.430417 Parsing instance 472\n",
      "2020/01/24 17:34:43.444737 Parsing instance 473\n",
      "2020/01/24 17:34:43.492935 Parsing instance 474\n",
      "2020/01/24 17:34:43.544691 Parsing instance 475\n",
      "2020/01/24 17:34:43.586980 Parsing instance 476\n",
      "2020/01/24 17:34:43.752297 Parsing instance 477\n",
      "2020/01/24 17:34:43.824413 Parsing instance 478\n",
      "2020/01/24 17:34:43.905835 Parsing instance 479\n",
      "2020/01/24 17:34:43.920240 Parsing instance 480\n",
      "2020/01/24 17:34:43.937788 Parsing instance 481\n",
      "2020/01/24 17:34:43.974500 Parsing instance 482\n",
      "2020/01/24 17:34:43.996100 Parsing instance 483\n",
      "2020/01/24 17:34:44.054381 Parsing instance 484\n",
      "2020/01/24 17:34:44.101103 Parsing instance 485\n",
      "2020/01/24 17:34:44.140142 Parsing instance 486\n",
      "2020/01/24 17:34:44.221384 Parsing instance 487\n",
      "2020/01/24 17:34:44.313073 Parsing instance 488\n",
      "2020/01/24 17:34:44.401058 Parsing instance 489\n",
      "2020/01/24 17:34:44.412310 Parsing instance 490\n",
      "2020/01/24 17:34:44.438228 Parsing instance 491\n",
      "2020/01/24 17:34:44.513590 Parsing instance 492\n",
      "2020/01/24 17:34:44.593661 Parsing instance 493\n",
      "2020/01/24 17:34:44.646919 Parsing instance 494\n",
      "2020/01/24 17:34:44.660026 Parsing instance 495\n",
      "2020/01/24 17:34:44.706327 Parsing instance 496\n",
      "2020/01/24 17:34:45.018946 Parsing instance 497\n",
      "2020/01/24 17:34:45.057174 Parsing instance 498\n",
      "2020/01/24 17:34:45.069948 Parsing instance 499\n",
      "2020/01/24 17:34:45.087035 PARSE Total Time: 55.198205633s\n",
      "2020/01/24 17:34:45.087065 Converting 500 to conll\n",
      "2020/01/24 17:34:45.087071 Writing to output file\n",
      "2020/01/24 17:34:45.132306 Wrote 500 in conll format to final_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.conll\n",
      "2020/01/24 17:34:45.132334 Writing to segmentation file\n",
      "2020/01/24 17:34:45.189779 Wrote 500 in segmentation format to final_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.seg\n",
      "2020/01/24 17:34:45.189824 Writing to mapping file\n",
      "2020/01/24 17:34:45.505026 Wrote 500 in mapping format to final_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.map\n",
      "2020/01/24 17:34:45.505064 Writing to gold segmentation file\n",
      "2020/01/24 17:34:46.035376 GOMAXPROCS:\t40\n",
      "2020/01/24 17:34:46.035549 \n",
      "2020/01/24 17:34:46.036447 *** CONFIGURATION ***\n",
      "2020/01/24 17:34:46.036472 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/24 17:34:46.036501 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/24 17:34:46.036523 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/24 17:34:46.036551 Iterations:\t\t1\n",
      "2020/01/24 17:34:46.036575 Beam Size:\t\t64\n",
      "2020/01/24 17:34:46.036595 Beam Concurrent:\ttrue\n",
      "2020/01/24 17:34:46.036612 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/24 17:34:46.036629 Use Lemmas:\t\tfalse\n",
      "2020/01/24 17:34:46.036649 Use POP:\t\ttrue\n",
      "2020/01/24 17:34:46.036669 Infuse Gold Dev:\tfalse\n",
      "2020/01/24 17:34:46.036686 Limit (thousands):\t0\n",
      "2020/01/24 17:34:46.036702 Use CoNLL-U:\t\tfalse\n",
      "2020/01/24 17:34:46.036721 \n",
      "2020/01/24 17:34:46.036732 Features File:\tjointzeager.yaml\n",
      "2020/01/24 17:34:46.037459 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/24 17:34:46.037785 \n",
      "2020/01/24 17:34:46.037803 Data\n",
      "2020/01/24 17:34:46.037822 Test file  (ambig.  lattice):\tfinal_setup/plo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:34:46.038116 Out (disamb.) file:\t\t\tfinal_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.conll\n",
      "2020/01/24 17:34:46.038145 Out (segmt.) file:\t\t\tfinal_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.seg\n",
      "2020/01/24 17:34:46.038169 Out (mapping.) file:\t\t\tfinal_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.map\n",
      "2020/01/24 17:34:46.038852 \n",
      "2020/01/24 17:34:46.038872 Setup enumerations\n",
      "2020/01/24 17:34:46.038974 ETrans Len is 96\n",
      "2020/01/24 17:34:46.039824 \n",
      "2020/01/24 17:34:46.039843 Loading features\n",
      "2020/01/24 17:34:46.041530 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/24 17:34:46.041601 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/24 17:34:46.041691 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/24 17:34:46.041747 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/24 17:34:46.041772 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/24 17:34:46.041838 Loading POP transition dependent feature group POP\n",
      "2020/01/24 17:34:46.041864 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/24 17:34:46.041895 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/24 17:34:46.042263 \n",
      "2020/01/24 17:34:46.042294 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/24 17:34:46.042308 \n",
      "2020/01/24 17:34:46.042320 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/24 17:35:06.080152 Loaded model\n",
      "2020/01/24 17:35:06.080196 \n",
      "2020/01/24 17:35:06.080202 *** PARSING ***\n",
      "2020/01/24 17:35:06.080226 Parsing test\n",
      "2020/01/24 17:35:06.080242 Reading ambiguous lattices from final_setup/plo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:35:06.162595 Read 706 ambiguous lattices from final_setup/plo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.51_seed.lattices\n",
      "2020/01/24 17:35:06.162624 Converting lattice format to internal structure\n",
      "2020/01/24 17:35:06.665732 Parsing instance 0\n",
      "2020/01/24 17:35:06.856133 Parsing instance 1\n",
      "2020/01/24 17:35:06.962627 Parsing instance 2\n",
      "2020/01/24 17:35:07.018613 Parsing instance 3\n",
      "2020/01/24 17:35:07.112426 Parsing instance 4\n",
      "2020/01/24 17:35:07.167657 Parsing instance 5\n",
      "2020/01/24 17:35:07.474146 Parsing instance 6\n",
      "2020/01/24 17:35:07.575389 Parsing instance 7\n",
      "2020/01/24 17:35:07.625889 Parsing instance 8\n",
      "2020/01/24 17:35:07.641105 Parsing instance 9\n",
      "2020/01/24 17:35:07.679559 Parsing instance 10\n",
      "2020/01/24 17:35:07.761205 Parsing instance 11\n",
      "2020/01/24 17:35:07.835945 Parsing instance 12\n",
      "2020/01/24 17:35:07.951065 Parsing instance 13\n",
      "2020/01/24 17:35:07.996389 Parsing instance 14\n",
      "2020/01/24 17:35:08.049377 Parsing instance 15\n",
      "2020/01/24 17:35:08.105749 Parsing instance 16\n",
      "2020/01/24 17:35:08.250138 Parsing instance 17\n",
      "2020/01/24 17:35:08.458477 Parsing instance 18\n",
      "2020/01/24 17:35:08.713745 Parsing instance 19\n",
      "2020/01/24 17:35:08.864665 Parsing instance 20\n",
      "2020/01/24 17:35:08.882014 Parsing instance 21\n",
      "2020/01/24 17:35:08.897988 Parsing instance 22\n",
      "2020/01/24 17:35:08.922967 Parsing instance 23\n",
      "2020/01/24 17:35:09.097842 Parsing instance 24\n",
      "2020/01/24 17:35:09.188688 Parsing instance 25\n",
      "2020/01/24 17:35:09.234583 Parsing instance 26\n",
      "2020/01/24 17:35:09.283982 Parsing instance 27\n",
      "2020/01/24 17:35:09.404956 Parsing instance 28\n",
      "2020/01/24 17:35:09.504278 Parsing instance 29\n",
      "2020/01/24 17:35:09.700136 Parsing instance 30\n",
      "2020/01/24 17:35:09.803513 Parsing instance 31\n",
      "2020/01/24 17:35:09.853949 Parsing instance 32\n",
      "2020/01/24 17:35:10.035137 Parsing instance 33\n",
      "2020/01/24 17:35:10.101616 Parsing instance 34\n",
      "2020/01/24 17:35:10.225825 Parsing instance 35\n",
      "2020/01/24 17:35:10.426214 Parsing instance 36\n",
      "2020/01/24 17:35:10.463149 Parsing instance 37\n",
      "2020/01/24 17:35:10.542606 Parsing instance 38\n",
      "2020/01/24 17:35:10.549974 Parsing instance 39\n",
      "2020/01/24 17:35:10.900973 Parsing instance 40\n",
      "2020/01/24 17:35:10.982457 Parsing instance 41\n",
      "2020/01/24 17:35:11.020257 Parsing instance 42\n",
      "2020/01/24 17:35:11.132288 Parsing instance 43\n",
      "2020/01/24 17:35:11.267392 Parsing instance 44\n",
      "2020/01/24 17:35:11.361906 Parsing instance 45\n",
      "2020/01/24 17:35:11.590776 Parsing instance 46\n",
      "2020/01/24 17:35:11.606170 Parsing instance 47\n",
      "2020/01/24 17:35:11.935228 Parsing instance 48\n",
      "2020/01/24 17:35:12.005474 Parsing instance 49\n",
      "2020/01/24 17:35:12.060718 Parsing instance 50\n",
      "2020/01/24 17:35:12.247827 Parsing instance 51\n",
      "2020/01/24 17:35:12.335307 Parsing instance 52\n",
      "2020/01/24 17:35:12.382987 Parsing instance 53\n",
      "2020/01/24 17:35:12.397957 Parsing instance 54\n",
      "2020/01/24 17:35:12.484323 Parsing instance 55\n",
      "2020/01/24 17:35:12.670310 Parsing instance 56\n",
      "2020/01/24 17:35:12.755950 Parsing instance 57\n",
      "2020/01/24 17:35:13.060103 Parsing instance 58\n",
      "2020/01/24 17:35:13.107197 Parsing instance 59\n",
      "2020/01/24 17:35:13.241023 Parsing instance 60\n",
      "2020/01/24 17:35:13.365527 Parsing instance 61\n",
      "2020/01/24 17:35:13.392818 Parsing instance 62\n",
      "2020/01/24 17:35:13.429430 Parsing instance 63\n",
      "2020/01/24 17:35:13.481849 Parsing instance 64\n",
      "2020/01/24 17:35:13.571244 Parsing instance 65\n",
      "2020/01/24 17:35:13.673403 Parsing instance 66\n",
      "2020/01/24 17:35:13.766398 Parsing instance 67\n",
      "2020/01/24 17:35:13.816973 Parsing instance 68\n",
      "2020/01/24 17:35:14.104158 Parsing instance 69\n",
      "2020/01/24 17:35:14.214023 Parsing instance 70\n",
      "2020/01/24 17:35:14.268896 Parsing instance 71\n",
      "2020/01/24 17:35:14.345842 Parsing instance 72\n",
      "2020/01/24 17:35:14.393270 Parsing instance 73\n",
      "2020/01/24 17:35:14.495735 Parsing instance 74\n",
      "2020/01/24 17:35:14.553435 Parsing instance 75\n",
      "2020/01/24 17:35:14.698771 Parsing instance 76\n",
      "2020/01/24 17:35:14.828436 Parsing instance 77\n",
      "2020/01/24 17:35:14.881878 Parsing instance 78\n",
      "2020/01/24 17:35:14.926503 Parsing instance 79\n",
      "2020/01/24 17:35:15.214650 Parsing instance 80\n",
      "2020/01/24 17:35:15.313641 Parsing instance 81\n",
      "2020/01/24 17:35:15.403273 Parsing instance 82\n",
      "2020/01/24 17:35:15.479381 Parsing instance 83\n",
      "2020/01/24 17:35:15.584283 Parsing instance 84\n",
      "2020/01/24 17:35:15.660710 Parsing instance 85\n",
      "2020/01/24 17:35:15.745084 Parsing instance 86\n",
      "2020/01/24 17:35:15.876281 Parsing instance 87\n",
      "2020/01/24 17:35:15.987807 Parsing instance 88\n",
      "2020/01/24 17:35:16.204730 Parsing instance 89\n",
      "2020/01/24 17:35:16.403707 Parsing instance 90\n",
      "2020/01/24 17:35:16.513534 Parsing instance 91\n",
      "2020/01/24 17:35:16.578535 Parsing instance 92\n",
      "2020/01/24 17:35:16.635671 Parsing instance 93\n",
      "2020/01/24 17:35:16.664450 Parsing instance 94\n",
      "2020/01/24 17:35:16.899335 Parsing instance 95\n",
      "2020/01/24 17:35:17.014991 Parsing instance 96\n",
      "2020/01/24 17:35:17.119318 Parsing instance 97\n",
      "2020/01/24 17:35:17.407357 Parsing instance 98\n",
      "2020/01/24 17:35:17.440715 Parsing instance 99\n",
      "2020/01/24 17:35:17.554794 Parsing instance 100\n",
      "2020/01/24 17:35:17.610340 Parsing instance 101\n",
      "2020/01/24 17:35:17.732134 Parsing instance 102\n",
      "2020/01/24 17:35:17.944135 Parsing instance 103\n",
      "2020/01/24 17:35:17.996976 Parsing instance 104\n",
      "2020/01/24 17:35:18.129519 Parsing instance 105\n",
      "2020/01/24 17:35:18.211849 Parsing instance 106\n",
      "2020/01/24 17:35:18.485132 Parsing instance 107\n",
      "2020/01/24 17:35:18.600469 Parsing instance 108\n",
      "2020/01/24 17:35:18.713923 Parsing instance 109\n",
      "2020/01/24 17:35:18.790026 Parsing instance 110\n",
      "2020/01/24 17:35:18.849864 Parsing instance 111\n",
      "2020/01/24 17:35:18.891000 Parsing instance 112\n",
      "2020/01/24 17:35:18.931390 Parsing instance 113\n",
      "2020/01/24 17:35:19.061254 Parsing instance 114\n",
      "2020/01/24 17:35:19.145760 Parsing instance 115\n",
      "2020/01/24 17:35:19.583267 Parsing instance 116\n",
      "2020/01/24 17:35:19.723641 Parsing instance 117\n",
      "2020/01/24 17:35:19.780400 Parsing instance 118\n",
      "2020/01/24 17:35:19.937325 Parsing instance 119\n",
      "2020/01/24 17:35:20.008455 Parsing instance 120\n",
      "2020/01/24 17:35:20.019649 Parsing instance 121\n",
      "2020/01/24 17:35:20.102529 Parsing instance 122\n",
      "2020/01/24 17:35:20.293928 Parsing instance 123\n",
      "2020/01/24 17:35:20.425608 Parsing instance 124\n",
      "2020/01/24 17:35:20.889386 Parsing instance 125\n",
      "2020/01/24 17:35:20.944596 Parsing instance 126\n",
      "2020/01/24 17:35:20.970454 Parsing instance 127\n",
      "2020/01/24 17:35:21.074815 Parsing instance 128\n",
      "2020/01/24 17:35:21.211604 Parsing instance 129\n",
      "2020/01/24 17:35:21.334568 Parsing instance 130\n",
      "2020/01/24 17:35:21.437526 Parsing instance 131\n",
      "2020/01/24 17:35:21.824458 Parsing instance 132\n",
      "2020/01/24 17:35:21.999407 Parsing instance 133\n",
      "2020/01/24 17:35:22.028649 Parsing instance 134\n",
      "2020/01/24 17:35:22.186076 Parsing instance 135\n",
      "2020/01/24 17:35:22.249077 Parsing instance 136\n",
      "2020/01/24 17:35:22.331748 Parsing instance 137\n",
      "2020/01/24 17:35:22.347754 Parsing instance 138\n",
      "2020/01/24 17:35:22.448748 Parsing instance 139\n",
      "2020/01/24 17:35:22.459974 Parsing instance 140\n",
      "2020/01/24 17:35:22.530041 Parsing instance 141\n",
      "2020/01/24 17:35:23.012418 Parsing instance 142\n",
      "2020/01/24 17:35:23.191293 Parsing instance 143\n",
      "2020/01/24 17:35:23.270693 Parsing instance 144\n",
      "2020/01/24 17:35:23.349264 Parsing instance 145\n",
      "2020/01/24 17:35:23.439075 Parsing instance 146\n",
      "2020/01/24 17:35:23.457993 Parsing instance 147\n",
      "2020/01/24 17:35:23.677351 Parsing instance 148\n",
      "2020/01/24 17:35:23.986942 Parsing instance 149\n",
      "2020/01/24 17:35:24.073882 Parsing instance 150\n",
      "2020/01/24 17:35:24.140090 Parsing instance 151\n",
      "2020/01/24 17:35:24.314203 Parsing instance 152\n",
      "2020/01/24 17:35:24.445720 Parsing instance 153\n",
      "2020/01/24 17:35:24.544495 Parsing instance 154\n",
      "2020/01/24 17:35:24.986675 Parsing instance 155\n",
      "2020/01/24 17:35:25.046025 Parsing instance 156\n",
      "2020/01/24 17:35:25.218756 Parsing instance 157\n",
      "2020/01/24 17:35:25.261275 Parsing instance 158\n",
      "2020/01/24 17:35:25.346742 Parsing instance 159\n",
      "2020/01/24 17:35:25.364529 Parsing instance 160\n",
      "2020/01/24 17:35:25.568361 Parsing instance 161\n",
      "2020/01/24 17:35:25.647152 Parsing instance 162\n",
      "2020/01/24 17:35:26.100872 Parsing instance 163\n",
      "2020/01/24 17:35:26.186727 Parsing instance 164\n",
      "2020/01/24 17:35:26.209192 Parsing instance 165\n",
      "2020/01/24 17:35:26.269086 Parsing instance 166\n",
      "2020/01/24 17:35:26.442045 Parsing instance 167\n",
      "2020/01/24 17:35:26.521413 Parsing instance 168\n",
      "2020/01/24 17:35:26.571694 Parsing instance 169\n",
      "2020/01/24 17:35:26.642862 Parsing instance 170\n",
      "2020/01/24 17:35:26.750733 Parsing instance 171\n",
      "2020/01/24 17:35:26.807932 Parsing instance 172\n",
      "2020/01/24 17:35:26.885931 Parsing instance 173\n",
      "2020/01/24 17:35:27.184550 Parsing instance 174\n",
      "2020/01/24 17:35:27.275872 Parsing instance 175\n",
      "2020/01/24 17:35:27.301199 Parsing instance 176\n",
      "2020/01/24 17:35:27.330909 Parsing instance 177\n",
      "2020/01/24 17:35:27.355187 Parsing instance 178\n",
      "2020/01/24 17:35:27.443124 Parsing instance 179\n",
      "2020/01/24 17:35:27.466060 Parsing instance 180\n",
      "2020/01/24 17:35:27.512416 Parsing instance 181\n",
      "2020/01/24 17:35:27.532656 Parsing instance 182\n",
      "2020/01/24 17:35:27.547556 Parsing instance 183\n",
      "2020/01/24 17:35:27.720620 Parsing instance 184\n",
      "2020/01/24 17:35:27.817474 Parsing instance 185\n",
      "2020/01/24 17:35:27.863837 Parsing instance 186\n",
      "2020/01/24 17:35:27.929788 Parsing instance 187\n",
      "2020/01/24 17:35:28.063168 Parsing instance 188\n",
      "2020/01/24 17:35:28.152766 Parsing instance 189\n",
      "2020/01/24 17:35:28.303336 Parsing instance 190\n",
      "2020/01/24 17:35:28.329847 Parsing instance 191\n",
      "2020/01/24 17:35:28.335229 Parsing instance 192\n",
      "2020/01/24 17:35:28.337171 Parsing instance 193\n",
      "2020/01/24 17:35:28.362369 Parsing instance 194\n",
      "2020/01/24 17:35:28.500540 Parsing instance 195\n",
      "2020/01/24 17:35:28.529848 Parsing instance 196\n",
      "2020/01/24 17:35:28.596024 Parsing instance 197\n",
      "2020/01/24 17:35:28.608701 Parsing instance 198\n",
      "2020/01/24 17:35:28.740544 Parsing instance 199\n",
      "2020/01/24 17:35:28.794052 Parsing instance 200\n",
      "2020/01/24 17:35:28.978835 Parsing instance 201\n",
      "2020/01/24 17:35:28.993755 Parsing instance 202\n",
      "2020/01/24 17:35:29.065841 Parsing instance 203\n",
      "2020/01/24 17:35:29.091793 Parsing instance 204\n",
      "2020/01/24 17:35:29.140358 Parsing instance 205\n",
      "2020/01/24 17:35:29.276373 Parsing instance 206\n",
      "2020/01/24 17:35:29.620487 Parsing instance 207\n",
      "2020/01/24 17:35:29.766037 Parsing instance 208\n",
      "2020/01/24 17:35:29.858435 Parsing instance 209\n",
      "2020/01/24 17:35:29.953058 Parsing instance 210\n",
      "2020/01/24 17:35:29.991842 Parsing instance 211\n",
      "2020/01/24 17:35:30.144344 Parsing instance 212\n",
      "2020/01/24 17:35:30.252257 Parsing instance 213\n",
      "2020/01/24 17:35:30.443999 Parsing instance 214\n",
      "2020/01/24 17:35:30.532944 Parsing instance 215\n",
      "2020/01/24 17:35:30.802804 Parsing instance 216\n",
      "2020/01/24 17:35:30.845629 Parsing instance 217\n",
      "2020/01/24 17:35:30.897067 Parsing instance 218\n",
      "2020/01/24 17:35:30.954922 Parsing instance 219\n",
      "2020/01/24 17:35:31.005080 Parsing instance 220\n",
      "2020/01/24 17:35:31.022193 Parsing instance 221\n",
      "2020/01/24 17:35:31.171784 Parsing instance 222\n",
      "2020/01/24 17:35:31.234051 Parsing instance 223\n",
      "2020/01/24 17:35:31.328767 Parsing instance 224\n",
      "2020/01/24 17:35:31.670720 Parsing instance 225\n",
      "2020/01/24 17:35:31.751208 Parsing instance 226\n",
      "2020/01/24 17:35:31.854951 Parsing instance 227\n",
      "2020/01/24 17:35:31.993186 Parsing instance 228\n",
      "2020/01/24 17:35:32.015110 Parsing instance 229\n",
      "2020/01/24 17:35:32.125711 Parsing instance 230\n",
      "2020/01/24 17:35:32.193342 Parsing instance 231\n",
      "2020/01/24 17:35:32.249390 Parsing instance 232\n",
      "2020/01/24 17:35:32.271257 Parsing instance 233\n",
      "2020/01/24 17:35:32.290175 Parsing instance 234\n",
      "2020/01/24 17:35:32.338561 Parsing instance 235\n",
      "2020/01/24 17:35:32.400672 Parsing instance 236\n",
      "2020/01/24 17:35:32.507222 Parsing instance 237\n",
      "2020/01/24 17:35:32.753439 Parsing instance 238\n",
      "2020/01/24 17:35:32.820897 Parsing instance 239\n",
      "2020/01/24 17:35:32.862902 Parsing instance 240\n",
      "2020/01/24 17:35:32.873303 Parsing instance 241\n",
      "2020/01/24 17:35:32.903349 Parsing instance 242\n",
      "2020/01/24 17:35:32.956282 Parsing instance 243\n",
      "2020/01/24 17:35:33.005842 Parsing instance 244\n",
      "2020/01/24 17:35:33.030642 Parsing instance 245\n",
      "2020/01/24 17:35:33.142129 Parsing instance 246\n",
      "2020/01/24 17:35:33.213238 Parsing instance 247\n",
      "2020/01/24 17:35:33.251003 Parsing instance 248\n",
      "2020/01/24 17:35:33.338977 Parsing instance 249\n",
      "2020/01/24 17:35:33.386571 Parsing instance 250\n",
      "2020/01/24 17:35:33.394909 Parsing instance 251\n",
      "2020/01/24 17:35:33.434112 Parsing instance 252\n",
      "2020/01/24 17:35:33.486013 Parsing instance 253\n",
      "2020/01/24 17:35:33.508176 Parsing instance 254\n",
      "2020/01/24 17:35:33.577331 Parsing instance 255\n",
      "2020/01/24 17:35:33.634545 Parsing instance 256\n",
      "2020/01/24 17:35:33.910613 Parsing instance 257\n",
      "2020/01/24 17:35:34.006991 Parsing instance 258\n",
      "2020/01/24 17:35:34.020559 Parsing instance 259\n",
      "2020/01/24 17:35:34.079346 Parsing instance 260\n",
      "2020/01/24 17:35:34.165968 Parsing instance 261\n",
      "2020/01/24 17:35:34.207439 Parsing instance 262\n",
      "2020/01/24 17:35:34.283046 Parsing instance 263\n",
      "2020/01/24 17:35:34.323205 Parsing instance 264\n",
      "2020/01/24 17:35:34.391194 Parsing instance 265\n",
      "2020/01/24 17:35:34.471268 Parsing instance 266\n",
      "2020/01/24 17:35:34.678338 Parsing instance 267\n",
      "2020/01/24 17:35:35.075063 Parsing instance 268\n",
      "2020/01/24 17:35:35.276811 Parsing instance 269\n",
      "2020/01/24 17:35:35.321597 Parsing instance 270\n",
      "2020/01/24 17:35:35.387885 Parsing instance 271\n",
      "2020/01/24 17:35:35.417820 Parsing instance 272\n",
      "2020/01/24 17:35:35.505089 Parsing instance 273\n",
      "2020/01/24 17:35:35.559550 Parsing instance 274\n",
      "2020/01/24 17:35:35.607888 Parsing instance 275\n",
      "2020/01/24 17:35:35.635635 Parsing instance 276\n",
      "2020/01/24 17:35:35.656091 Parsing instance 277\n",
      "2020/01/24 17:35:35.704898 Parsing instance 278\n",
      "2020/01/24 17:35:35.778606 Parsing instance 279\n",
      "2020/01/24 17:35:35.886613 Parsing instance 280\n",
      "2020/01/24 17:35:36.140612 Parsing instance 281\n",
      "2020/01/24 17:35:36.208102 Parsing instance 282\n",
      "2020/01/24 17:35:36.248616 Parsing instance 283\n",
      "2020/01/24 17:35:36.354180 Parsing instance 284\n",
      "2020/01/24 17:35:36.407791 Parsing instance 285\n",
      "2020/01/24 17:35:36.456430 Parsing instance 286\n",
      "2020/01/24 17:35:36.506277 Parsing instance 287\n",
      "2020/01/24 17:35:36.565460 Parsing instance 288\n",
      "2020/01/24 17:35:36.658511 Parsing instance 289\n",
      "2020/01/24 17:35:36.701803 Parsing instance 290\n",
      "2020/01/24 17:35:36.780620 Parsing instance 291\n",
      "2020/01/24 17:35:36.850396 Parsing instance 292\n",
      "2020/01/24 17:35:37.248407 Parsing instance 293\n",
      "2020/01/24 17:35:37.444809 Parsing instance 294\n",
      "2020/01/24 17:35:37.466851 Parsing instance 295\n",
      "2020/01/24 17:35:37.525626 Parsing instance 296\n",
      "2020/01/24 17:35:37.579843 Parsing instance 297\n",
      "2020/01/24 17:35:37.609598 Parsing instance 298\n",
      "2020/01/24 17:35:37.689098 Parsing instance 299\n",
      "2020/01/24 17:35:37.764358 Parsing instance 300\n",
      "2020/01/24 17:35:37.792094 Parsing instance 301\n",
      "2020/01/24 17:35:37.919185 Parsing instance 302\n",
      "2020/01/24 17:35:37.978749 Parsing instance 303\n",
      "2020/01/24 17:35:38.060164 Parsing instance 304\n",
      "2020/01/24 17:35:38.351738 Parsing instance 305\n",
      "2020/01/24 17:35:38.425367 Parsing instance 306\n",
      "2020/01/24 17:35:38.459321 Parsing instance 307\n",
      "2020/01/24 17:35:38.508099 Parsing instance 308\n",
      "2020/01/24 17:35:38.537007 Parsing instance 309\n",
      "2020/01/24 17:35:38.635805 Parsing instance 310\n",
      "2020/01/24 17:35:38.665888 Parsing instance 311\n",
      "2020/01/24 17:35:38.677276 Parsing instance 312\n",
      "2020/01/24 17:35:38.730338 Parsing instance 313\n",
      "2020/01/24 17:35:38.743748 Parsing instance 314\n",
      "2020/01/24 17:35:38.823942 Parsing instance 315\n",
      "2020/01/24 17:35:38.826408 Parsing instance 316\n",
      "2020/01/24 17:35:38.858469 Parsing instance 317\n",
      "2020/01/24 17:35:38.979676 Parsing instance 318\n",
      "2020/01/24 17:35:39.142346 Parsing instance 319\n",
      "2020/01/24 17:35:39.191599 Parsing instance 320\n",
      "2020/01/24 17:35:39.516182 Parsing instance 321\n",
      "2020/01/24 17:35:39.584074 Parsing instance 322\n",
      "2020/01/24 17:35:39.616224 Parsing instance 323\n",
      "2020/01/24 17:35:39.759406 Parsing instance 324\n",
      "2020/01/24 17:35:39.943005 Parsing instance 325\n",
      "2020/01/24 17:35:40.051844 Parsing instance 326\n",
      "2020/01/24 17:35:40.400580 Parsing instance 327\n",
      "2020/01/24 17:35:40.703026 Parsing instance 328\n",
      "2020/01/24 17:35:40.745970 Parsing instance 329\n",
      "2020/01/24 17:35:40.923276 Parsing instance 330\n",
      "2020/01/24 17:35:40.957151 Parsing instance 331\n",
      "2020/01/24 17:35:41.005989 Parsing instance 332\n",
      "2020/01/24 17:35:41.122647 Parsing instance 333\n",
      "2020/01/24 17:35:41.358884 Parsing instance 334\n",
      "2020/01/24 17:35:41.380414 Parsing instance 335\n",
      "2020/01/24 17:35:41.660987 Parsing instance 336\n",
      "2020/01/24 17:35:41.781330 Parsing instance 337\n",
      "2020/01/24 17:35:41.850664 Parsing instance 338\n",
      "2020/01/24 17:35:41.874523 Parsing instance 339\n",
      "2020/01/24 17:35:41.924899 Parsing instance 340\n",
      "2020/01/24 17:35:41.951683 Parsing instance 341\n",
      "2020/01/24 17:35:41.986444 Parsing instance 342\n",
      "2020/01/24 17:35:42.194247 Parsing instance 343\n",
      "2020/01/24 17:35:42.272466 Parsing instance 344\n",
      "2020/01/24 17:35:42.294938 Parsing instance 345\n",
      "2020/01/24 17:35:42.323433 Parsing instance 346\n",
      "2020/01/24 17:35:42.409031 Parsing instance 347\n",
      "2020/01/24 17:35:42.433618 Parsing instance 348\n",
      "2020/01/24 17:35:42.463752 Parsing instance 349\n",
      "2020/01/24 17:35:42.481544 Parsing instance 350\n",
      "2020/01/24 17:35:42.577002 Parsing instance 351\n",
      "2020/01/24 17:35:42.822344 Parsing instance 352\n",
      "2020/01/24 17:35:42.884856 Parsing instance 353\n",
      "2020/01/24 17:35:42.907301 Parsing instance 354\n",
      "2020/01/24 17:35:42.948768 Parsing instance 355\n",
      "2020/01/24 17:35:42.964776 Parsing instance 356\n",
      "2020/01/24 17:35:42.981290 Parsing instance 357\n",
      "2020/01/24 17:35:43.068404 Parsing instance 358\n",
      "2020/01/24 17:35:43.178262 Parsing instance 359\n",
      "2020/01/24 17:35:43.284716 Parsing instance 360\n",
      "2020/01/24 17:35:43.431699 Parsing instance 361\n",
      "2020/01/24 17:35:43.488920 Parsing instance 362\n",
      "2020/01/24 17:35:43.537708 Parsing instance 363\n",
      "2020/01/24 17:35:43.677201 Parsing instance 364\n",
      "2020/01/24 17:35:43.965858 Parsing instance 365\n",
      "2020/01/24 17:35:44.033795 Parsing instance 366\n",
      "2020/01/24 17:35:44.071318 Parsing instance 367\n",
      "2020/01/24 17:35:44.098751 Parsing instance 368\n",
      "2020/01/24 17:35:44.193881 Parsing instance 369\n",
      "2020/01/24 17:35:44.359139 Parsing instance 370\n",
      "2020/01/24 17:35:44.428698 Parsing instance 371\n",
      "2020/01/24 17:35:44.500753 Parsing instance 372\n",
      "2020/01/24 17:35:44.540929 Parsing instance 373\n",
      "2020/01/24 17:35:44.654476 Parsing instance 374\n",
      "2020/01/24 17:35:44.798450 Parsing instance 375\n",
      "2020/01/24 17:35:44.856442 Parsing instance 376\n",
      "2020/01/24 17:35:45.228510 Parsing instance 377\n",
      "2020/01/24 17:35:45.340561 Parsing instance 378\n",
      "2020/01/24 17:35:45.456551 Parsing instance 379\n",
      "2020/01/24 17:35:45.814020 Parsing instance 380\n",
      "2020/01/24 17:35:46.358474 Parsing instance 381\n",
      "2020/01/24 17:35:46.420091 Parsing instance 382\n",
      "2020/01/24 17:35:46.566750 Parsing instance 383\n",
      "2020/01/24 17:35:46.657040 Parsing instance 384\n",
      "2020/01/24 17:35:46.820728 Parsing instance 385\n",
      "2020/01/24 17:35:46.890513 Parsing instance 386\n",
      "2020/01/24 17:35:47.468675 Parsing instance 387\n",
      "2020/01/24 17:35:47.588790 Parsing instance 388\n",
      "2020/01/24 17:35:48.098068 Parsing instance 389\n",
      "2020/01/24 17:35:48.381227 Parsing instance 390\n",
      "2020/01/24 17:35:48.581928 Parsing instance 391\n",
      "2020/01/24 17:35:48.684734 Parsing instance 392\n",
      "2020/01/24 17:35:48.864858 Parsing instance 393\n",
      "2020/01/24 17:35:48.975611 Parsing instance 394\n",
      "2020/01/24 17:35:49.038063 Parsing instance 395\n",
      "2020/01/24 17:35:49.168873 Parsing instance 396\n",
      "2020/01/24 17:35:49.658029 Parsing instance 397\n",
      "2020/01/24 17:35:49.677012 Parsing instance 398\n",
      "2020/01/24 17:35:49.749211 Parsing instance 399\n",
      "2020/01/24 17:35:49.865618 Parsing instance 400\n",
      "2020/01/24 17:35:49.891822 Parsing instance 401\n",
      "2020/01/24 17:35:50.021369 Parsing instance 402\n",
      "2020/01/24 17:35:50.154255 Parsing instance 403\n",
      "2020/01/24 17:35:50.194082 Parsing instance 404\n",
      "2020/01/24 17:35:50.281139 Parsing instance 405\n",
      "2020/01/24 17:35:50.323115 Parsing instance 406\n",
      "2020/01/24 17:35:50.355527 Parsing instance 407\n",
      "2020/01/24 17:35:50.799565 Parsing instance 408\n",
      "2020/01/24 17:35:50.916320 Parsing instance 409\n",
      "2020/01/24 17:35:51.012158 Parsing instance 410\n",
      "2020/01/24 17:35:51.085703 Parsing instance 411\n",
      "2020/01/24 17:35:51.286588 Parsing instance 412\n",
      "2020/01/24 17:35:51.361846 Parsing instance 413\n",
      "2020/01/24 17:35:51.412440 Parsing instance 414\n",
      "2020/01/24 17:35:51.460779 Parsing instance 415\n",
      "2020/01/24 17:35:51.506671 Parsing instance 416\n",
      "2020/01/24 17:35:51.766053 Parsing instance 417\n",
      "2020/01/24 17:35:51.873933 Parsing instance 418\n",
      "2020/01/24 17:35:51.924733 Parsing instance 419\n",
      "2020/01/24 17:35:51.949503 Parsing instance 420\n",
      "2020/01/24 17:35:51.988952 Parsing instance 421\n",
      "2020/01/24 17:35:52.125237 Parsing instance 422\n",
      "2020/01/24 17:35:52.150161 Parsing instance 423\n",
      "2020/01/24 17:35:52.294013 Parsing instance 424\n",
      "2020/01/24 17:35:52.368020 Parsing instance 425\n",
      "2020/01/24 17:35:52.409030 Parsing instance 426\n",
      "2020/01/24 17:35:52.496524 Parsing instance 427\n",
      "2020/01/24 17:35:52.588032 Parsing instance 428\n",
      "2020/01/24 17:35:52.869284 Parsing instance 429\n",
      "2020/01/24 17:35:53.044302 Parsing instance 430\n",
      "2020/01/24 17:35:53.074024 Parsing instance 431\n",
      "2020/01/24 17:35:53.103726 Parsing instance 432\n",
      "2020/01/24 17:35:53.170067 Parsing instance 433\n",
      "2020/01/24 17:35:53.232442 Parsing instance 434\n",
      "2020/01/24 17:35:53.270726 Parsing instance 435\n",
      "2020/01/24 17:35:53.399326 Parsing instance 436\n",
      "2020/01/24 17:35:53.568729 Parsing instance 437\n",
      "2020/01/24 17:35:53.614792 Parsing instance 438\n",
      "2020/01/24 17:35:53.686187 Parsing instance 439\n",
      "2020/01/24 17:35:53.753268 Parsing instance 440\n",
      "2020/01/24 17:35:54.134204 Parsing instance 441\n",
      "2020/01/24 17:35:54.229736 Parsing instance 442\n",
      "2020/01/24 17:35:54.549908 Parsing instance 443\n",
      "2020/01/24 17:35:54.726564 Parsing instance 444\n",
      "2020/01/24 17:35:54.795338 Parsing instance 445\n",
      "2020/01/24 17:35:54.940953 Parsing instance 446\n",
      "2020/01/24 17:35:55.336574 Parsing instance 447\n",
      "2020/01/24 17:35:55.404216 Parsing instance 448\n",
      "2020/01/24 17:35:55.502137 Parsing instance 449\n",
      "2020/01/24 17:35:55.524160 Parsing instance 450\n",
      "2020/01/24 17:35:55.664289 Parsing instance 451\n",
      "2020/01/24 17:35:55.772478 Parsing instance 452\n",
      "2020/01/24 17:35:55.810702 Parsing instance 453\n",
      "2020/01/24 17:35:55.918381 Parsing instance 454\n",
      "2020/01/24 17:35:56.195707 Parsing instance 455\n",
      "2020/01/24 17:35:56.473998 Parsing instance 456\n",
      "2020/01/24 17:35:56.641672 Parsing instance 457\n",
      "2020/01/24 17:35:56.713261 Parsing instance 458\n",
      "2020/01/24 17:35:56.807883 Parsing instance 459\n",
      "2020/01/24 17:35:56.859558 Parsing instance 460\n",
      "2020/01/24 17:35:56.969523 Parsing instance 461\n",
      "2020/01/24 17:35:57.073410 Parsing instance 462\n",
      "2020/01/24 17:35:57.596596 Parsing instance 463\n",
      "2020/01/24 17:35:57.851924 Parsing instance 464\n",
      "2020/01/24 17:35:57.927132 Parsing instance 465\n",
      "2020/01/24 17:35:58.231317 Parsing instance 466\n",
      "2020/01/24 17:35:58.318860 Parsing instance 467\n",
      "2020/01/24 17:35:58.742930 Parsing instance 468\n",
      "2020/01/24 17:35:58.892753 Parsing instance 469\n",
      "2020/01/24 17:35:58.987785 Parsing instance 470\n",
      "2020/01/24 17:35:59.016540 Parsing instance 471\n",
      "2020/01/24 17:35:59.287688 Parsing instance 472\n",
      "2020/01/24 17:35:59.447202 Parsing instance 473\n",
      "2020/01/24 17:35:59.794962 Parsing instance 474\n",
      "2020/01/24 17:35:59.979595 Parsing instance 475\n",
      "2020/01/24 17:36:00.223080 Parsing instance 476\n",
      "2020/01/24 17:36:00.288441 Parsing instance 477\n",
      "2020/01/24 17:36:00.446583 Parsing instance 478\n",
      "2020/01/24 17:36:00.522003 Parsing instance 479\n",
      "2020/01/24 17:36:00.842436 Parsing instance 480\n",
      "2020/01/24 17:36:01.058702 Parsing instance 481\n",
      "2020/01/24 17:36:01.115343 Parsing instance 482\n",
      "2020/01/24 17:36:01.269629 Parsing instance 483\n",
      "2020/01/24 17:36:01.494470 Parsing instance 484\n",
      "2020/01/24 17:36:01.545708 Parsing instance 485\n",
      "2020/01/24 17:36:01.606966 Parsing instance 486\n",
      "2020/01/24 17:36:01.914851 Parsing instance 487\n",
      "2020/01/24 17:36:01.984108 Parsing instance 488\n",
      "2020/01/24 17:36:02.084349 Parsing instance 489\n",
      "2020/01/24 17:36:02.112754 Parsing instance 490\n",
      "2020/01/24 17:36:02.233905 Parsing instance 491\n",
      "2020/01/24 17:36:02.357519 Parsing instance 492\n",
      "2020/01/24 17:36:02.457604 Parsing instance 493\n",
      "2020/01/24 17:36:02.555199 Parsing instance 494\n",
      "2020/01/24 17:36:02.626857 Parsing instance 495\n",
      "2020/01/24 17:36:02.742174 Parsing instance 496\n",
      "2020/01/24 17:36:02.818552 Parsing instance 497\n",
      "2020/01/24 17:36:03.221282 Parsing instance 498\n",
      "2020/01/24 17:36:03.276867 Parsing instance 499\n",
      "2020/01/24 17:36:03.339370 Parsing instance 500\n",
      "2020/01/24 17:36:03.407586 Parsing instance 501\n",
      "2020/01/24 17:36:03.523852 Parsing instance 502\n",
      "2020/01/24 17:36:03.654035 Parsing instance 503\n",
      "2020/01/24 17:36:03.808987 Parsing instance 504\n",
      "2020/01/24 17:36:03.863900 Parsing instance 505\n",
      "2020/01/24 17:36:04.067899 Parsing instance 506\n",
      "2020/01/24 17:36:04.324771 Parsing instance 507\n",
      "2020/01/24 17:36:04.391723 Parsing instance 508\n",
      "2020/01/24 17:36:04.463095 Parsing instance 509\n",
      "2020/01/24 17:36:04.513785 Parsing instance 510\n",
      "2020/01/24 17:36:04.565762 Parsing instance 511\n",
      "2020/01/24 17:36:04.605505 Parsing instance 512\n",
      "2020/01/24 17:36:04.722228 Parsing instance 513\n",
      "2020/01/24 17:36:04.755143 Parsing instance 514\n",
      "2020/01/24 17:36:04.855968 Parsing instance 515\n",
      "2020/01/24 17:36:04.874625 Parsing instance 516\n",
      "2020/01/24 17:36:04.927115 Parsing instance 517\n",
      "2020/01/24 17:36:05.038011 Parsing instance 518\n",
      "2020/01/24 17:36:05.368843 Parsing instance 519\n",
      "2020/01/24 17:36:05.449202 Parsing instance 520\n",
      "2020/01/24 17:36:05.500814 Parsing instance 521\n",
      "2020/01/24 17:36:05.565598 Parsing instance 522\n",
      "2020/01/24 17:36:05.613923 Parsing instance 523\n",
      "2020/01/24 17:36:05.737047 Parsing instance 524\n",
      "2020/01/24 17:36:06.132772 Parsing instance 525\n",
      "2020/01/24 17:36:06.179776 Parsing instance 526\n",
      "2020/01/24 17:36:06.264298 Parsing instance 527\n",
      "2020/01/24 17:36:06.600350 Parsing instance 528\n",
      "2020/01/24 17:36:06.691935 Parsing instance 529\n",
      "2020/01/24 17:36:06.846195 Parsing instance 530\n",
      "2020/01/24 17:36:06.884963 Parsing instance 531\n",
      "2020/01/24 17:36:06.941787 Parsing instance 532\n",
      "2020/01/24 17:36:06.984387 Parsing instance 533\n",
      "2020/01/24 17:36:07.057236 Parsing instance 534\n",
      "2020/01/24 17:36:07.081740 Parsing instance 535\n",
      "2020/01/24 17:36:07.179696 Parsing instance 536\n",
      "2020/01/24 17:36:07.217902 Parsing instance 537\n",
      "2020/01/24 17:36:07.311753 Parsing instance 538\n",
      "2020/01/24 17:36:07.825028 Parsing instance 539\n",
      "2020/01/24 17:36:08.123727 Parsing instance 540\n",
      "2020/01/24 17:36:08.304670 Parsing instance 541\n",
      "2020/01/24 17:36:08.798398 Parsing instance 542\n",
      "2020/01/24 17:36:08.949889 Parsing instance 543\n",
      "2020/01/24 17:36:09.044403 Parsing instance 544\n",
      "2020/01/24 17:36:09.096504 Parsing instance 545\n",
      "2020/01/24 17:36:09.385077 Parsing instance 546\n",
      "2020/01/24 17:36:09.443156 Parsing instance 547\n",
      "2020/01/24 17:36:09.558097 Parsing instance 548\n",
      "2020/01/24 17:36:09.816652 Parsing instance 549\n",
      "2020/01/24 17:36:09.878548 Parsing instance 550\n",
      "2020/01/24 17:36:09.973929 Parsing instance 551\n",
      "2020/01/24 17:36:10.060192 Parsing instance 552\n",
      "2020/01/24 17:36:10.162101 Parsing instance 553\n",
      "2020/01/24 17:36:10.211331 Parsing instance 554\n",
      "2020/01/24 17:36:10.303174 Parsing instance 555\n",
      "2020/01/24 17:36:10.439356 Parsing instance 556\n",
      "2020/01/24 17:36:10.640381 Parsing instance 557\n",
      "2020/01/24 17:36:10.788702 Parsing instance 558\n",
      "2020/01/24 17:36:11.241895 Parsing instance 559\n",
      "2020/01/24 17:36:11.323433 Parsing instance 560\n",
      "2020/01/24 17:36:11.388094 Parsing instance 561\n",
      "2020/01/24 17:36:11.416859 Parsing instance 562\n",
      "2020/01/24 17:36:12.119872 Parsing instance 563\n",
      "2020/01/24 17:36:12.156832 Parsing instance 564\n",
      "2020/01/24 17:36:12.219056 Parsing instance 565\n",
      "2020/01/24 17:36:12.250343 Parsing instance 566\n",
      "2020/01/24 17:36:12.278904 Parsing instance 567\n",
      "2020/01/24 17:36:12.474509 Parsing instance 568\n",
      "2020/01/24 17:36:12.533243 Parsing instance 569\n",
      "2020/01/24 17:36:12.595056 Parsing instance 570\n",
      "2020/01/24 17:36:12.818787 Parsing instance 571\n",
      "2020/01/24 17:36:13.288177 Parsing instance 572\n",
      "2020/01/24 17:36:13.302769 Parsing instance 573\n",
      "2020/01/24 17:36:13.420592 Parsing instance 574\n",
      "2020/01/24 17:36:13.507387 Parsing instance 575\n",
      "2020/01/24 17:36:13.647116 Parsing instance 576\n",
      "2020/01/24 17:36:13.924950 Parsing instance 577\n",
      "2020/01/24 17:36:14.008386 Parsing instance 578\n",
      "2020/01/24 17:36:14.075701 Parsing instance 579\n",
      "2020/01/24 17:36:14.473450 Parsing instance 580\n",
      "2020/01/24 17:36:14.495952 Parsing instance 581\n",
      "2020/01/24 17:36:14.586984 Parsing instance 582\n",
      "2020/01/24 17:36:14.676814 Parsing instance 583\n",
      "2020/01/24 17:36:14.801143 Parsing instance 584\n",
      "2020/01/24 17:36:14.923805 Parsing instance 585\n",
      "2020/01/24 17:36:14.971530 Parsing instance 586\n",
      "2020/01/24 17:36:15.100201 Parsing instance 587\n",
      "2020/01/24 17:36:15.261163 Parsing instance 588\n",
      "2020/01/24 17:36:15.654175 Parsing instance 589\n",
      "2020/01/24 17:36:15.712667 Parsing instance 590\n",
      "2020/01/24 17:36:15.848305 Parsing instance 591\n",
      "2020/01/24 17:36:15.855479 Parsing instance 592\n",
      "2020/01/24 17:36:15.930868 Parsing instance 593\n",
      "2020/01/24 17:36:16.138299 Parsing instance 594\n",
      "2020/01/24 17:36:16.231576 Parsing instance 595\n",
      "2020/01/24 17:36:16.376913 Parsing instance 596\n",
      "2020/01/24 17:36:16.501761 Parsing instance 597\n",
      "2020/01/24 17:36:16.657140 Parsing instance 598\n",
      "2020/01/24 17:36:16.850305 Parsing instance 599\n",
      "2020/01/24 17:36:16.960158 Parsing instance 600\n",
      "2020/01/24 17:36:17.075810 Parsing instance 601\n",
      "2020/01/24 17:36:17.164573 Parsing instance 602\n",
      "2020/01/24 17:36:17.336577 Parsing instance 603\n",
      "2020/01/24 17:36:17.400720 Parsing instance 604\n",
      "2020/01/24 17:36:17.493584 Parsing instance 605\n",
      "2020/01/24 17:36:17.709188 Parsing instance 606\n",
      "2020/01/24 17:36:17.817245 Parsing instance 607\n",
      "2020/01/24 17:36:17.974135 Parsing instance 608\n",
      "2020/01/24 17:36:18.014534 Parsing instance 609\n",
      "2020/01/24 17:36:18.054317 Parsing instance 610\n",
      "2020/01/24 17:36:18.172810 Parsing instance 611\n",
      "2020/01/24 17:36:18.266749 Parsing instance 612\n",
      "2020/01/24 17:36:18.372387 Parsing instance 613\n",
      "2020/01/24 17:36:18.470200 Parsing instance 614\n",
      "2020/01/24 17:36:18.646548 Parsing instance 615\n",
      "2020/01/24 17:36:19.039378 Parsing instance 616\n",
      "2020/01/24 17:36:19.126340 Parsing instance 617\n",
      "2020/01/24 17:36:19.217298 Parsing instance 618\n",
      "2020/01/24 17:36:19.243317 Parsing instance 619\n",
      "2020/01/24 17:36:19.342344 Parsing instance 620\n",
      "2020/01/24 17:36:19.385911 Parsing instance 621\n",
      "2020/01/24 17:36:19.547456 Parsing instance 622\n",
      "2020/01/24 17:36:19.618983 Parsing instance 623\n",
      "2020/01/24 17:36:19.659157 Parsing instance 624\n",
      "2020/01/24 17:36:19.746482 Parsing instance 625\n",
      "2020/01/24 17:36:19.782504 Parsing instance 626\n",
      "2020/01/24 17:36:19.842212 Parsing instance 627\n",
      "2020/01/24 17:36:20.114066 Parsing instance 628\n",
      "2020/01/24 17:36:20.209928 Parsing instance 629\n",
      "2020/01/24 17:36:20.318873 Parsing instance 630\n",
      "2020/01/24 17:36:20.466239 Parsing instance 631\n",
      "2020/01/24 17:36:20.478284 Parsing instance 632\n",
      "2020/01/24 17:36:20.582047 Parsing instance 633\n",
      "2020/01/24 17:36:20.651206 Parsing instance 634\n",
      "2020/01/24 17:36:20.797356 Parsing instance 635\n",
      "2020/01/24 17:36:20.843277 Parsing instance 636\n",
      "2020/01/24 17:36:21.161604 Parsing instance 637\n",
      "2020/01/24 17:36:21.294431 Parsing instance 638\n",
      "2020/01/24 17:36:21.403609 Parsing instance 639\n",
      "2020/01/24 17:36:21.428652 Parsing instance 640\n",
      "2020/01/24 17:36:21.482137 Parsing instance 641\n",
      "2020/01/24 17:36:21.602971 Parsing instance 642\n",
      "2020/01/24 17:36:21.674951 Parsing instance 643\n",
      "2020/01/24 17:36:21.830848 Parsing instance 644\n",
      "2020/01/24 17:36:21.882595 Parsing instance 645\n",
      "2020/01/24 17:36:21.968374 Parsing instance 646\n",
      "2020/01/24 17:36:22.059781 Parsing instance 647\n",
      "2020/01/24 17:36:22.098575 Parsing instance 648\n",
      "2020/01/24 17:36:22.417369 Parsing instance 649\n",
      "2020/01/24 17:36:22.599706 Parsing instance 650\n",
      "2020/01/24 17:36:22.608340 Parsing instance 651\n",
      "2020/01/24 17:36:22.745170 Parsing instance 652\n",
      "2020/01/24 17:36:22.855714 Parsing instance 653\n",
      "2020/01/24 17:36:22.979715 Parsing instance 654\n",
      "2020/01/24 17:36:23.004803 Parsing instance 655\n",
      "2020/01/24 17:36:23.044547 Parsing instance 656\n",
      "2020/01/24 17:36:23.164501 Parsing instance 657\n",
      "2020/01/24 17:36:23.266948 Parsing instance 658\n",
      "2020/01/24 17:36:23.569198 Parsing instance 659\n",
      "2020/01/24 17:36:23.677634 Parsing instance 660\n",
      "2020/01/24 17:36:23.821419 Parsing instance 661\n",
      "2020/01/24 17:36:23.935134 Parsing instance 662\n",
      "2020/01/24 17:36:24.007363 Parsing instance 663\n",
      "2020/01/24 17:36:24.229138 Parsing instance 664\n",
      "2020/01/24 17:36:24.354706 Parsing instance 665\n",
      "2020/01/24 17:36:24.411932 Parsing instance 666\n",
      "2020/01/24 17:36:24.554069 Parsing instance 667\n",
      "2020/01/24 17:36:24.895550 Parsing instance 668\n",
      "2020/01/24 17:36:25.005745 Parsing instance 669\n",
      "2020/01/24 17:36:25.049787 Parsing instance 670\n",
      "2020/01/24 17:36:25.119197 Parsing instance 671\n",
      "2020/01/24 17:36:25.215831 Parsing instance 672\n",
      "2020/01/24 17:36:25.295607 Parsing instance 673\n",
      "2020/01/24 17:36:25.327132 Parsing instance 674\n",
      "2020/01/24 17:36:25.381470 Parsing instance 675\n",
      "2020/01/24 17:36:25.427282 Parsing instance 676\n",
      "2020/01/24 17:36:25.453483 Parsing instance 677\n",
      "2020/01/24 17:36:25.571409 Parsing instance 678\n",
      "2020/01/24 17:36:25.600222 Parsing instance 679\n",
      "2020/01/24 17:36:25.680218 Parsing instance 680\n",
      "2020/01/24 17:36:25.722109 Parsing instance 681\n",
      "2020/01/24 17:36:26.035501 Parsing instance 682\n",
      "2020/01/24 17:36:26.171828 Parsing instance 683\n",
      "2020/01/24 17:36:26.219520 Parsing instance 684\n",
      "2020/01/24 17:36:26.263266 Parsing instance 685\n",
      "2020/01/24 17:36:26.365137 Parsing instance 686\n",
      "2020/01/24 17:36:26.389156 Parsing instance 687\n",
      "2020/01/24 17:36:26.480648 Parsing instance 688\n",
      "2020/01/24 17:36:26.669136 Parsing instance 689\n",
      "2020/01/24 17:36:26.781167 Parsing instance 690\n",
      "2020/01/24 17:36:26.883169 Parsing instance 691\n",
      "2020/01/24 17:36:27.165968 Parsing instance 692\n",
      "2020/01/24 17:36:27.247245 Parsing instance 693\n",
      "2020/01/24 17:36:27.311765 Parsing instance 694\n",
      "2020/01/24 17:36:27.475518 Parsing instance 695\n",
      "2020/01/24 17:36:27.561444 Parsing instance 696\n",
      "2020/01/24 17:36:27.768281 Parsing instance 697\n",
      "2020/01/24 17:36:27.900938 Parsing instance 698\n",
      "2020/01/24 17:36:27.985168 Parsing instance 699\n",
      "2020/01/24 17:36:28.362127 Parsing instance 700\n",
      "2020/01/24 17:36:28.463399 Parsing instance 701\n",
      "2020/01/24 17:36:28.563860 Parsing instance 702\n",
      "2020/01/24 17:36:28.668427 Parsing instance 703\n",
      "2020/01/24 17:36:28.687847 Parsing instance 704\n",
      "2020/01/24 17:36:28.746159 Parsing instance 705\n",
      "2020/01/24 17:36:28.773290 PARSE Total Time: 1m22.107555142s\n",
      "2020/01/24 17:36:28.773322 Converting 706 to conll\n",
      "2020/01/24 17:36:28.773329 Writing to output file\n",
      "2020/01/24 17:36:28.853443 Wrote 706 in conll format to final_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.conll\n",
      "2020/01/24 17:36:28.853465 Writing to segmentation file\n",
      "2020/01/24 17:36:28.925040 Wrote 706 in segmentation format to final_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.seg\n",
      "2020/01/24 17:36:28.925052 Writing to mapping file\n",
      "2020/01/24 17:36:29.185011 Wrote 706 in mapping format to final_setup/plo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.51_seed.map\n",
      "2020/01/24 17:36:29.185025 Writing to gold segmentation file\n"
     ]
    }
   ],
   "source": [
    "for file in os.scandir(pruned_folder):\n",
    "    #ds, unit, arch, w_embed, seed_num, _\n",
    "    base_out = '.'.join(file.name.split('.')[:-1])\n",
    "    seg_out, map_out, conll_out = [os.path.join(yap_output_folder, base_out+suf)\n",
    "                                   for suf in ['.seg', '.map', '.conll']]\n",
    "    if not os.path.exists(seg_out):\n",
    "        !{yap_path} joint -in {file.path} -os {seg_out} -om {map_out} -oc {conll_out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input files for NCRF\n",
    "with dummy O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "txt_folder = 'final_setup/plo_pruned/txt'\n",
    "txt_map = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.scandir(yap_output_folder):\n",
    "    if file.name.endswith('conll') and file.name!='.conll':\n",
    "        ds, unit, arch, w_embed, seed_num, _ = file.name.split('.')\n",
    "        out_name = '.'.join(file.name.split('.')[:-1])+'.txt'\n",
    "        out_path = os.path.join(txt_folder, out_name)\n",
    "        if '_tok' in w_embed:\n",
    "            w_embed = w_embed.replace('_tok', '_yap')\n",
    "        else:\n",
    "            w_embed = w_embed.replace('_yap', '_tok')\n",
    "        txt_map[('char_cnn', w_embed)].append((ds, out_path))\n",
    "        with open(out_path, 'w') as of:\n",
    "            for line in open(file.path, 'r'):\n",
    "                if line=='\\n':\n",
    "                    of.write('\\n')\n",
    "                else:\n",
    "                    w = line.split('\\t')[1]\n",
    "                    of.write(w+' O\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file in os.scandir(yap_output_folder):\n",
    "    if file.name.endswith('conll') and file.name!='.conll':\n",
    "        ds, unit, arch, w_embed, seed_num, _ = file.name.split('.')\n",
    "        out_name = '.'.join(file.name.split('.')[:-1])+'.txt'\n",
    "        out_path = os.path.join(txt_folder, out_name)\n",
    "        if '_tok' in w_embed:\n",
    "            w_embed = w_embed.replace('_tok', '_yap')\n",
    "        else:\n",
    "            w_embed = w_embed.replace('_yap', '_tok')\n",
    "        txt_map[(arch, w_embed)].append((ds, out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('char_cnn',\n",
       "              'ft_oov_yap'): [('dev',\n",
       "               'final_setup/plo_pruned/txt/dev.multitok.char_lstm.ft_oov_tok.51_seed.txt'), ('test',\n",
       "               'final_setup/plo_pruned/txt/test.multitok.char_lstm.ft_oov_tok.51_seed.txt')]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs for NCRF decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'final_setup/plo_decode_output'\n",
    "decode_conf_folder = 'final_setup/plo_decode_conf'\n",
    "\n",
    "params = { 'status': 'decode' }\n",
    "\n",
    "erdf = pd.read_pickle('final_setup/plo_erdf.pkl')\n",
    "\n",
    "for i, row in erdf[(erdf.unit=='morph')].iterrows():\n",
    "    unit = row['unit']\n",
    "    for ds, set_path in txt_map[(row.arch, row.w_embed)]:\n",
    "        name = 'morph_'+ds+'_pruned'\n",
    "        row_par = params.copy()\n",
    "        row_par['load_model_dir'] = os.path.join(models_folder, row['model_file_name'])\n",
    "        row_par['dset_dir'] = os.path.join(models_folder, row['dset_file_name'])\n",
    "        row_par['decode_dir'] = os.path.join(output_folder, name+'.'+row['model_base_name']+'.bmes')\n",
    "        row_par['raw_dir'] = set_path\n",
    "        \n",
    "        conf_path = os.path.join(decode_conf_folder, name+'.'+row['model_base_name']+'.decode.conf')\n",
    "        if not os.path.exists(conf_path):\n",
    "            with open(conf_path, 'w', encoding='utf8') as of:\n",
    "                for k, v in row_par.items():\n",
    "                    of.write(k+'='+str(v)+'\\n')        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate segmentation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = spdf[spdf.set=='dev']\n",
    "test_gold = spdf[spdf.set=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "      .size().reset_index().rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "dg['ner'] = tempn\n",
    "tg = (test_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index()\n",
    "      .rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (test_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "tg['ner'] = tempn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>w_embed</th>\n",
       "      <th>model_base_name</th>\n",
       "      <th>pred_set</th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.44_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.973157</td>\n",
       "      <td>0.967470</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.44_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.971709</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.972654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.45_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.975068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.45_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.971551</td>\n",
       "      <td>0.967377</td>\n",
       "      <td>0.972115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.46_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.971867</td>\n",
       "      <td>0.962651</td>\n",
       "      <td>0.972861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        arch     w_embed                        model_base_name pred_set  \\\n",
       "0  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.44_seed      dev   \n",
       "1  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.44_seed     test   \n",
       "2  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.45_seed      dev   \n",
       "3  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.45_seed     test   \n",
       "4  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.46_seed      dev   \n",
       "\n",
       "        all       ner       non  \n",
       "0  0.973157  0.967470  0.973770  \n",
       "1  0.971709  0.964714  0.972654  \n",
       "2  0.974094  0.965060  0.975068  \n",
       "3  0.971551  0.967377  0.972115  \n",
       "4  0.971867  0.962651  0.972861  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for i, row in erdf[erdf.unit=='multitok'].iterrows():\n",
    "    dev_path = os.path.join(output_folder, \n",
    "                            'token_dev.'+row.model_base_name+'.bmes')\n",
    "    dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'dev'}\n",
    "    sc['all'] = accuracy_score(dev_bc.biose_count, dg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(dev_bc[dg.ner].biose_count, dg[dg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(dev_bc[~dg.ner].biose_count, dg[~dg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    test_path = os.path.join(output_folder, \n",
    "                             'token_test.'+row.model_base_name+'.bmes')\n",
    "    test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'test'}\n",
    "    sc['all'] = accuracy_score(test_bc.biose_count, tg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(test_bc[tg.ner].biose_count, tg[tg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(test_bc[~tg.ner].biose_count, tg[~tg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    \n",
    "acc_scores = pd.DataFrame(acc_scores)\n",
    "acc_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores.to_pickle('final_setup/plo_acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = pd.read_pickle('final_setup/plo_acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">char_lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_set</th>\n",
       "      <th>w_embed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.26</td>\n",
       "      <td>96.54</td>\n",
       "      <td>97.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.12</td>\n",
       "      <td>96.34</td>\n",
       "      <td>97.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "arch                char_lstm              \n",
       "                          all    ner    non\n",
       "pred_set w_embed                           \n",
       "dev      ft_oov_tok     97.26  96.54  97.33\n",
       "test     ft_oov_tok     97.12  96.34  97.22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = acc_scores.groupby(['pred_set','w_embed', 'arch']).mean().mul(100).round(2).unstack()\n",
    "x.columns = x.columns.reorder_levels([1,0])\n",
    "x.sort_index(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, dg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313253012048193"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[dg.ner].morpheme_count, dg[dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628619659784443"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~dg.ner].morpheme_count, dg[~dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bclm.get_token_df(bclm.read_yap_output(treebank_set='test'), fields=['upostag'])\n",
    "yt['morpheme_count'] = yt.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547507726444251"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt.morpheme_count, tg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961384820239681"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[tg.ner].morpheme_count, tg[tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626697850139426"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[~tg.ner].morpheme_count, tg[~tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_out_non_o_keep = bclm.read_yap_output(treebank_set=None, tokens_path=bclm.TREEBANK_TOKEN_PATHS['dev'], \n",
    "                                     dep_path='final_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.conll',\n",
    "                                     map_path='final_setup/plo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.51_seed.map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = bclm.read_dataframe('spmrl', subset='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_dev_regular = bclm.read_yap_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10445 correct.\n",
      "Precision: 91.41\n",
      "Recall:    92.43\n",
      "F1:        91.92\n",
      "FP ex.: [(1, 5, 'לישראל', 'NNP'), (1, 8, 'ה', 'DEF'), (2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN')]\n",
      "FN ex.: [(1, 5, 'ישראל', 'NNP'), (1, 5, 'ל', 'PREPOSITION'), (2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.41431822159986, 92.42544907530306, 91.91710300523606)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11283 predicted, 10491 correct.\n",
      "Precision: 92.98\n",
      "Recall:    92.83\n",
      "F1:        92.91\n",
      "FP ex.: [(2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN'), (5, 13, 'ה', 'DEF'), (6, 24, 'ה', 'REL')]\n",
      "FN ex.: [(2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN'), (6, 24, 'ה', 'DEF'), (8, 1, 'מרגלית', 'NNP')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.9805902685456, 92.83249269976109, 92.90648246546228)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'upostag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10541 correct.\n",
      "Precision: 92.25\n",
      "Recall:    93.27\n",
      "F1:        92.76\n",
      "FP ex.: [(1, 8, 'DEF'), (2, 11, 'BN'), (3, 4, 'NNT'), (4, 19, 'NN'), (5, 9, 'DEF')]\n",
      "FN ex.: [(1, 5, 'PREPOSITION'), (2, 11, 'VB'), (3, 4, 'NN'), (4, 19, 'RB'), (5, 9, 'NNT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.25450726413443, 93.27493142199805, 92.76191314295771)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11283 predicted, 10583 correct.\n",
      "Precision: 93.8\n",
      "Recall:    93.65\n",
      "F1:        93.72\n",
      "FP ex.: [(2, 11, 'BN'), (3, 4, 'NNT'), (5, 13, 'DEF'), (6, 24, 'REL'), (8, 1, 'NNT')]\n",
      "FN ex.: [(2, 11, 'VB'), (3, 4, 'NN'), (6, 24, 'DEF'), (8, 1, 'NNP'), (8, 17, 'VB')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.79597624745192, 93.64657994867711, 93.72121856181367)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No POS, Segmentation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10923 correct.\n",
      "Precision: 95.6\n",
      "Recall:    96.66\n",
      "F1:        96.12\n",
      "FP ex.: [(1, 5, 'לישראל'), (1, 8, 'ה'), (3, 28, 'הם'), (5, 9, 'ה'), (5, 22, 'ה')]\n",
      "FN ex.: [(1, 5, 'ישראל'), (1, 5, 'ל'), (3, 28, 'המ'), (6, 25, 'ב'), (6, 25, 'מקום')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.59775949588658, 96.65516325988851, 96.1235534826418)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11283 predicted, 10997 correct.\n",
      "Precision: 97.47\n",
      "Recall:    97.31\n",
      "F1:        97.39\n",
      "FP ex.: [(3, 28, 'הם'), (5, 13, 'ה'), (8, 9, 'ה'), (8, 17, 'ה'), (8, 17, 'פעילה')]\n",
      "FN ex.: [(3, 28, 'המ'), (8, 17, 'הפעילה'), (15, 5, 'מפם'), (17, 11, 'מחפיר'), (18, 8, 'ה')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97.46521315253035, 97.30997256879922, 97.38753099539497)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evluate Token Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/bclm/evaluations.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gold_df['upostag'] = gold_df.upostag.str.replace('_','-')\n",
      "/home/nlp/danb/bclm/evaluations.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['upostag'] = pred_df.upostag.str.replace('_','-')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.39245106083693, 92.66107920134412, 92.47467220389504)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.84276950728714, 93.06548665650764, 92.90810545294192)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.27550502090416, 93.33313796741297, 93.27243498501264)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.07232446372053, 93.42691360919001, 93.13696267394545)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.40346969874575, 93.73754542257649, 93.47466662201161)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.8264369163443, 93.94463329816746, 93.82024102572689)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Segment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = dev_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index().rename(columns={0: 'morpheme_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str  morpheme_count\n",
       "0        1         1     עשרות               1\n",
       "1        1         2     אנשים               1\n",
       "2        1         3    מגיעים               1\n",
       "3        1         4   מתאילנד               2\n",
       "4        1         5    לישראל               2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8531, 8531)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ps), len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974328918063533"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ps.biose_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835616438356164"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[(ps.biose.str.contains('-'))].biose_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734649403922574"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[~(ps.biose.str.contains('-'))].biose_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6078\n",
       "2    2143\n",
       "3     303\n",
       "4       7\n",
       "Name: morpheme_count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.morpheme_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6056\n",
       "2    2156\n",
       "3     316\n",
       "4       3\n",
       "Name: biose_count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.biose_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>במלחמת</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>שכונת</td>\n",
       "      <td>O^B-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>I-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>לנקובסקי</td>\n",
       "      <td>O^S-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>229</td>\n",
       "      <td>8</td>\n",
       "      <td>שקריסטול</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>O^B-GPE^E-GPE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>לאקספרס</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>בלין</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id token_str          biose  biose_count\n",
       "633        30         1    במלחמת  O^B-LOC^I-LOC            3\n",
       "641        30         9     שכונת        O^B-LOC            2\n",
       "2075      103        16    הארקין    B-ORG^E-ORG            2\n",
       "2212      110         6    הארקין    B-ORG^E-ORG            2\n",
       "4133      225        13     הדסון    I-ORG^E-ORG            2\n",
       "4180      227         6  לנקובסקי        O^S-PER            2\n",
       "4232      229         8  שקריסטול          S-PER            1\n",
       "4478      239        26     באיסט        O^B-GPE            2\n",
       "6254      337         1      בארץ  O^B-GPE^E-GPE            3\n",
       "6573      356        11       בשן          S-PER            1\n",
       "7198      398         7   לאקספרס    B-ORG^E-ORG            2\n",
       "7376      408         6      בלין          S-PER            1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>כברית</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>המועצות</td>\n",
       "      <td>I-GPE^E-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>במערב</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>גימי</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>קרטר</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>דה</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>מוין</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>88</td>\n",
       "      <td>11</td>\n",
       "      <td>רגיסטר</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>באנגלית</td>\n",
       "      <td>O^S-ANG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>שלום</td>\n",
       "      <td>B-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>עכשיו</td>\n",
       "      <td>E-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>גורג</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>בוש</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>O^B-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>95</td>\n",
       "      <td>23</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>95</td>\n",
       "      <td>27</td>\n",
       "      <td>המפרץ</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>בית</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>המשפט</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>הבין</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>לאומי</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>בהאג</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>המערב</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>98</td>\n",
       "      <td>36</td>\n",
       "      <td>סדאם</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "      <td>חוסיין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>טום</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>טום</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>טקי</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id  token_str          biose  biose_count\n",
       "1693       82         6      ארה\"ב          S-GPE            1\n",
       "1700       82        13      כברית        O^B-GPE            2\n",
       "1701       82        14    המועצות    I-GPE^E-GPE            2\n",
       "1705       83         3      איובה          S-GPE            1\n",
       "1712       83        10      במערב  O^B-LOC^I-LOC            3\n",
       "1713       83        11     התיכון    I-LOC^E-LOC            2\n",
       "1719       83        17       גימי          B-PER            1\n",
       "1720       83        18       קרטר          E-PER            1\n",
       "1730       83        28  לאפגניסטן        O^S-GPE            2\n",
       "1732       84         1      איובה          S-GPE            1\n",
       "1751       85        11     בארה\"ב        O^S-GPE            2\n",
       "1763       86         7     באיובה        O^S-GPE            2\n",
       "1780       87         9      במפרץ  O^B-LOC^I-LOC            3\n",
       "1781       87        10      הפרסי    I-LOC^E-LOC            2\n",
       "1791       88         9         דה          B-ORG            1\n",
       "1792       88        10       מוין          I-ORG            1\n",
       "1793       88        11     רגיסטר          E-ORG            1\n",
       "1809       89         5    באנגלית        O^S-ANG            2\n",
       "1812       89         8       שלום          B-WOA            1\n",
       "1813       89         9      עכשיו          E-WOA            1\n",
       "1826       90        11    וייטנאם          S-GPE            1\n",
       "1856       92        17       גורג          S-PER            1\n",
       "1860       92        21    וייטנאם          S-GPE            1\n",
       "1864       93         2       גורג          S-WOA            1\n",
       "1868       93         6       גורג          B-PER            1\n",
       "1869       93         7        בוש          E-PER            1\n",
       "1900       95         4       לטום        O^B-PER            2\n",
       "1901       95         5     הארקין          E-PER            1\n",
       "1919       95        23      ארה\"ב          S-GPE            1\n",
       "1923       95        27      המפרץ    B-LOC^I-LOC            2\n",
       "1924       95        28      הפרסי    I-LOC^E-LOC            2\n",
       "1933       95        37        בית          B-ORG            1\n",
       "1934       95        38      המשפט    I-ORG^I-ORG            2\n",
       "1935       95        39       הבין    I-ORG^I-ORG            2\n",
       "1936       95        40          -          I-ORG            1\n",
       "1937       95        41      לאומי          E-ORG            1\n",
       "1939       95        43       בהאג        O^S-GPE            2\n",
       "1955       97         9     בארה\"ב        O^S-GPE            2\n",
       "1964       98         2      המערב    B-LOC^I-LOC            2\n",
       "1965       98         3     התיכון    I-LOC^E-LOC            2\n",
       "1967       98         5      ארה\"ב          S-GPE            1\n",
       "1988       98        26      ארה\"ב          S-GPE            1\n",
       "1998       98        36       סדאם          B-PER            1\n",
       "1999       98        37     חוסיין          E-PER            1\n",
       "2002       99         2      במפרץ  O^B-LOC^I-LOC            3\n",
       "2003       99         3      הפרסי    I-LOC^E-LOC            2\n",
       "2009       99         9     באיובה        O^S-GPE            2\n",
       "2011      100         1        טום          S-PER            1\n",
       "2018      100         8        טום          B-PER            1\n",
       "2019      100         9        טקי          E-PER            1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count==gs.morpheme_count) & (ps.biose.str.contains('-'))].iloc[140:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag\n",
       "0        1         1     עשרות              CDT\n",
       "1        1         2     אנשים               NN\n",
       "2        1         3    מגיעים               BN\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP\n",
       "4        1         5    לישראל              NNP"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag  morpheme_count\n",
       "0        1         1     עשרות              CDT               1\n",
       "1        1         2     אנשים               NN               1\n",
       "2        1         3    מגיעים               BN               1\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP               2\n",
       "4        1         5    לישראל              NNP               1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260273972602739"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[(ps.biose.str.contains('-'))].morpheme_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629534675041661"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~(ps.biose.str.contains('-'))].morpheme_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>שצה\"ל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>כמנזר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>ביחד</td>\n",
       "      <td>PREPOSITION^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "      <td>ואד</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>אלי</td>\n",
       "      <td>IN^S_PRN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>שלמה</td>\n",
       "      <td>REL^QW</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>לשיקאגו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>לניו</td>\n",
       "      <td>BN^POS^S_PRN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>בבוסטון</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>בשיקאגו</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>בירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>בצלם</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>ואראלה</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>ואיה</td>\n",
       "      <td>CONJ^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>161</td>\n",
       "      <td>17</td>\n",
       "      <td>בלוס</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>213</td>\n",
       "      <td>8</td>\n",
       "      <td>בבלאגיו</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>לזלי</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>229</td>\n",
       "      <td>48</td>\n",
       "      <td>בראדלו</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>שקרן</td>\n",
       "      <td>NNT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>232</td>\n",
       "      <td>14</td>\n",
       "      <td>לאחד</td>\n",
       "      <td>PREPOSITION^CD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>לקרן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>245</td>\n",
       "      <td>5</td>\n",
       "      <td>למקורות</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>245</td>\n",
       "      <td>16</td>\n",
       "      <td>ברוקינגס</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>בקליפורניה</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>294</td>\n",
       "      <td>19</td>\n",
       "      <td>לסילבר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>294</td>\n",
       "      <td>26</td>\n",
       "      <td>וולד</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>323</td>\n",
       "      <td>34</td>\n",
       "      <td>מניו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>327</td>\n",
       "      <td>22</td>\n",
       "      <td>בניו</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>327</td>\n",
       "      <td>33</td>\n",
       "      <td>ויטמן</td>\n",
       "      <td>CONJ^VB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>330</td>\n",
       "      <td>13</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>בטקסס</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>370</td>\n",
       "      <td>15</td>\n",
       "      <td>ורמונט</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>376</td>\n",
       "      <td>23</td>\n",
       "      <td>ולסטון</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>378</td>\n",
       "      <td>5</td>\n",
       "      <td>במינסוטה</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>384</td>\n",
       "      <td>14</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>לסנאט</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>412</td>\n",
       "      <td>26</td>\n",
       "      <td>ובאיטליה</td>\n",
       "      <td>CONJ^PREPOSITION^DEF^NNP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>416</td>\n",
       "      <td>4</td>\n",
       "      <td>בוסקה</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>439</td>\n",
       "      <td>11</td>\n",
       "      <td>מארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>כהן</td>\n",
       "      <td>ADVERB^PRP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>455</td>\n",
       "      <td>16</td>\n",
       "      <td>לכנסת</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>496</td>\n",
       "      <td>8</td>\n",
       "      <td>ליוסי</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id   token_str                   upostag  morpheme_count\n",
       "4           1         5      לישראל                       NNP               1\n",
       "766        37         3       שצה\"ל                       NNP               1\n",
       "819        40         9       כמנזר        PREPOSITION^DEF^NN               3\n",
       "1168       56        30        ביחד            PREPOSITION^RB               2\n",
       "1182       57        12    לירושלים                       NNP               1\n",
       "1193       57        23         ואד                   CONJ^NN               2\n",
       "1199       57        29         אלי                  IN^S_PRN               2\n",
       "1222       58        12    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "1730       83        28   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "1900       95         4        לטום                       NNP               1\n",
       "2441      121         8        שלמה                    REL^QW               2\n",
       "2549      128         7     לשיקאגו                       NNP               1\n",
       "2552      128        10        לניו              BN^POS^S_PRN               3\n",
       "2564      129         9     בבוסטון       PREPOSITION^DEF^NNP               3\n",
       "2575      130        10      לישראל       PREPOSITION^DEF^NNP               3\n",
       "2630      135         2     בשיקאגו       PREPOSITION^DEF^NNP               3\n",
       "2632      135         4    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "2636      136         3    בירושלים                       NNP               1\n",
       "2746      143         2        בצלם           PREPOSITION^NNT               2\n",
       "2993      159         5      ואראלה                  CONJ^NNP               2\n",
       "3014      161        11        ואיה                   CONJ^RB               2\n",
       "3020      161        17        בלוס                        VB               1\n",
       "3884      213         8     בבלאגיו        PREPOSITION^DEF^NN               3\n",
       "4114      224        16        לזלי            PREPOSITION^NN               2\n",
       "4133      225        13       הדסון                    DEF^NN               2\n",
       "4272      229        48      בראדלו            PREPOSITION^NN               2\n",
       "4294      231         8        שקרן                       NNT               1\n",
       "4324      232        14        לאחד            PREPOSITION^CD               2\n",
       "4427      238         2        לקרן        PREPOSITION^DEF^NN               3\n",
       "4478      239        26       באיסט           PREPOSITION^NNP               2\n",
       "4604      245         5     למקורות        PREPOSITION^DEF^NN               3\n",
       "4615      245        16    ברוקינגס            PREPOSITION^NN               2\n",
       "4684      250         4   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "5228      278         1  בקליפורניה                       NNP               1\n",
       "5490      294        19      לסילבר        PREPOSITION^DEF^NN               3\n",
       "5497      294        26        וולד                  CONJ^NNP               2\n",
       "6018      323        34        מניו                       NNP               1\n",
       "6085      327        22        בניו                        NN               1\n",
       "6096      327        33       ויטמן                   CONJ^VB               2\n",
       "6149      330        13      בארה\"ב                       NNP               1\n",
       "6254      337         1        בארץ        PREPOSITION^DEF^NN               3\n",
       "6573      356        11         בשן        PREPOSITION^DEF^NN               3\n",
       "6577      357         2       בטקסס                        NN               1\n",
       "6792      370        15      ורמונט                   CONJ^NN               2\n",
       "6873      376        23      ולסטון                  CONJ^NNP               2\n",
       "6892      378         5    במינסוטה       PREPOSITION^DEF^NNP               3\n",
       "6985      384        14      בארה\"ב                        NN               1\n",
       "7083      392         5       לסנאט           PREPOSITION^NNT               2\n",
       "7464      412        26    ובאיטליה  CONJ^PREPOSITION^DEF^NNP               4\n",
       "7505      416         4       בוסקה        PREPOSITION^DEF^NN               3\n",
       "7806      439        11      מארה\"ב                        NN               1\n",
       "7913      445        15         כהן                ADVERB^PRP               2\n",
       "8048      455        16       לכנסת           PREPOSITION^NNP               2\n",
       "8492      496         8       ליוסי       PREPOSITION^DEF^NNP               3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[(ys.morpheme_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
