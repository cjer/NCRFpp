{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.034028Z",
     "start_time": "2019-03-13T07:20:22.687626Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.382406Z",
     "start_time": "2019-03-13T07:20:24.037019Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:27.996727Z",
     "start_time": "2019-03-13T07:20:24.385088Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get token data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nlp/danb')\n",
    "sys.path.append('/home/nlp/danb/NER')\n",
    "\n",
    "import bclm\n",
    "import ne_evaluate_mentions as nem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CDT</td>\n",
       "      <td>CDT</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>הנשים</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|gen=M|num=S|per=1|tense=FUTURE</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>איש</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>מ</td>\n",
       "      <td>מ</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>ל</td>\n",
       "      <td>ל</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2     form    lemma      upostag      xpostag  \\\n",
       "0    0   1    עשרות      עשר          CDT          CDT   \n",
       "1    0   1    עשרות      עשר           CD           CD   \n",
       "2    1   2    אנשים    הנשים           VB           VB   \n",
       "3    1   2    אנשים      איש           NN           NN   \n",
       "4    2   3   מגיעים     הגיע           VB           VB   \n",
       "5    2   3   מגיעים     הגיע           BN           BN   \n",
       "6    3   4        מ        מ  PREPOSITION  PREPOSITION   \n",
       "7    3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "8    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "9    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "10   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "11   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "12   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "13   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "14   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "15   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "16   4   5   תאילנד   תאילנד          NNP          NNP   \n",
       "17   5   6        ל        ל  PREPOSITION  PREPOSITION   \n",
       "18   5   8   לישראל   לישראל          NNP          NNP   \n",
       "19   5   8   לישראל   לישראל           NN           NN   \n",
       "\n",
       "                                   feats token_id  sent_id  \n",
       "0                            gen=F|num=P        1        1  \n",
       "1                            gen=F|num=P        1        1  \n",
       "2   gen=F|gen=M|num=S|per=1|tense=FUTURE        2        1  \n",
       "3                            gen=M|num=P        2        1  \n",
       "4        gen=M|num=P|per=A|tense=BEINONI        3        1  \n",
       "5                      gen=M|num=P|per=A        3        1  \n",
       "6                                      _        4        1  \n",
       "7                            gen=M|num=S        4        1  \n",
       "8                      gen=M|num=P|num=S        4        1  \n",
       "9                            gen=M|num=S        4        1  \n",
       "10                           gen=F|num=S        4        1  \n",
       "11                     gen=F|gen=M|num=S        4        1  \n",
       "12                                     _        4        1  \n",
       "13                           gen=M|num=P        4        1  \n",
       "14                           gen=F|num=S        4        1  \n",
       "15                           gen=F|num=P        4        1  \n",
       "16                           gen=F|num=S        4        1  \n",
       "17                                     _        5        1  \n",
       "18                           gen=M|num=S        5        1  \n",
       "19                     gen=M|num=P|num=S        5        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_lat = bclm.read_lattices(bclm.LATTICES_PATHS['dev'])\n",
    "dev_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>הכל</td>\n",
       "      <td>הכיל</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נושא</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>עם</td>\n",
       "      <td>עם</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עם</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=3|tense=PAST</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>הם</td>\n",
       "      <td>הם</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>gen=M|num=P|per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>הוא</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "      <td>gen=F|num=S|per=2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>את</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NNT</td>\n",
       "      <td>NNT</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>הקליטה</td>\n",
       "      <td>הקליט</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|num=S|per=3|tense=PAST</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2      form   lemma upostag xpostag  \\\n",
       "0    0   1         ה       ה     DEF     DEF   \n",
       "1    0   2         ה       ה     REL     REL   \n",
       "2    0   3       הכל    הכיל      VB      VB   \n",
       "3    1   3        כל     כול     DTT     DTT   \n",
       "4    2   3        כל     כול     DTT     DTT   \n",
       "5    3   4    נושאים     נשא      VB      VB   \n",
       "6    3   4    נושאים    נושא      NN      NN   \n",
       "7    3   4    נושאים     נשא      BN      BN   \n",
       "8    4   5        עם      עם      IN      IN   \n",
       "9    4   6       עמם    עימם      VB      VB   \n",
       "10   4   6       עמם      עם      NN      NN   \n",
       "11   4   6       עמם    עימם      VB      VB   \n",
       "12   5   6        הם      הם   S_PRN   S_PRN   \n",
       "13   6   7        את     הוא     PRP     PRP   \n",
       "14   6   7        את      את      AT      AT   \n",
       "15   7   8  כישלונות  כישלון     NNT     NNT   \n",
       "16   7   8  כישלונות  כישלון      NN      NN   \n",
       "17   8   9         ה       ה     DEF     DEF   \n",
       "18   8  10         ה       ה     REL     REL   \n",
       "19   8  11    הקליטה   הקליט      VB      VB   \n",
       "\n",
       "                                        feats token_id  sent_id  \n",
       "0                                           _        1        1  \n",
       "1                                           _        1        1  \n",
       "2          gen=M|num=S|per=2|tense=IMPERATIVE        1        1  \n",
       "3                                           _        1        1  \n",
       "4                                           _        1        1  \n",
       "5             gen=M|num=P|per=A|tense=BEINONI        2        1  \n",
       "6                                 gen=M|num=P        2        1  \n",
       "7                           gen=M|num=P|per=A        2        1  \n",
       "8                                           _        3        1  \n",
       "9          gen=M|num=S|per=2|tense=IMPERATIVE        3        1  \n",
       "10  gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3        3        1  \n",
       "11               gen=M|num=S|per=3|tense=PAST        3        1  \n",
       "12                          gen=M|num=P|per=3        3        1  \n",
       "13                          gen=F|num=S|per=2        4        1  \n",
       "14                                          _        4        1  \n",
       "15                                gen=M|num=P        5        1  \n",
       "16                                gen=M|num=P        5        1  \n",
       "17                                          _        6        1  \n",
       "18                                          _        6        1  \n",
       "19               gen=F|num=S|per=3|tense=PAST        6        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lat = bclm.read_lattices(bclm.LATTICES_PATHS['test'])\n",
    "test_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose_layer0</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>O</td>\n",
       "      <td>CDT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>O</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str biose_layer0          upostag  set\n",
       "0        1         1     עשרות            O              CDT  dev\n",
       "1        1         2     אנשים            O               NN  dev\n",
       "2        1         3    מגיעים            O               BN  dev\n",
       "3        1         4   מתאילנד      O^S-GPE  PREPOSITION^NNP  dev\n",
       "4        1         5    לישראל      O^S-GPE  PREPOSITION^NNP  dev"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped = [5438, 5444, 5445, 5446, 5448, 5449, 5450, 5451, 5453, 5459]\n",
    "spdf = bclm.read_dataframe('spmrl')\n",
    "spdf = spdf[(~spdf.sent_id.isin(dropped))]\n",
    "tokens_ner_with_upos = bclm.get_token_df(spdf, fields = ['biose_layer0', 'upostag'])\n",
    "tokens_ner_with_upos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "dev         1\n",
       "test     5439\n",
       "train     501\n",
       "Name: sent_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdf.groupby('set').sent_id.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_gold_sents =   tokens_ner_with_upos.groupby('sent_id')[['token_str', 'biose_layer0']].apply(lambda x: x.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biose_count(path, sent_id_shift=1):\n",
    "    sents = nem.read_file_sents(path, fix_multi_tag=False, sent_id_shift=sent_id_shift)\n",
    "    bc = []\n",
    "    for i, sent in sents.iteritems():\n",
    "        for j, (tok, bio) in enumerate(sent):\n",
    "            bc.append([i, j+1, tok, bio, len(bio.split('^'))])\n",
    "\n",
    "    bc = pd.DataFrame(bc, columns=['sent_id', 'token_id', 'token_str', \n",
    "                                   'biose', 'biose_count'])\n",
    "    return bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_edges(lattices, bc,\n",
    "                    non_o_only=True, keep_all_if_no_valid=True):\n",
    "    valid_edges = []\n",
    "    for (i, df), (_, biose, biose_count) in zip(lattices.groupby(['sent_id', 'token_id']), \n",
    "                                                bc[['biose', 'biose_count']].itertuples()):\n",
    "        el = df[['ID1', 'ID2']].rename(columns={'ID1': 'source', 'ID2': 'target'})\n",
    "        #min_node = [n for n,v in G.nodes(data=True) if v['since'] == 'December 2008'][0]\n",
    "\n",
    "        g = nx.from_pandas_edgelist(el, create_using=nx.DiGraph)\n",
    "        min_node = el.source.min()\n",
    "        max_node = el.target.max()\n",
    "        #print(min_node,max_node)\n",
    "        #print(biose_count)\n",
    "        if non_o_only and not '-' in biose:\n",
    "            vp = list(nx.all_simple_paths(g, min_node, max_node))\n",
    "        else:\n",
    "            vp = [path for path in nx.all_simple_paths(g, min_node, max_node, cutoff=biose_count+1) if len(path)==biose_count+1]\n",
    "        if keep_all_if_no_valid and len(vp)==0:\n",
    "             vp = nx.all_simple_paths(g, min_node, max_node)\n",
    "        for path in vp:\n",
    "            for source, target in zip(path[:-1], path[1:]):\n",
    "                valid_edges.append((i[0], i[1], source, target))\n",
    "                \n",
    "    return valid_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lattices(df, path, cols = ['ID1', 'ID2', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'token_id']):\n",
    "    with open(path, 'w', encoding='utf8') as of:\n",
    "        for _, sent in df.groupby('sent_id'):\n",
    "            for _, row in sent[cols].iterrows():\n",
    "                of.write('\\t'.join(row.astype(str).tolist())+'\\n')\n",
    "            of.write('\\n')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>arch</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>cm</th>\n",
       "      <th>acc</th>\n",
       "      <th>model_base_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.52_seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unit       arch embed_type     cm     acc  \\\n",
       "1128  multitok  char_lstm     ft_oov  Match  0.9743   \n",
       "\n",
       "                            model_base_name  \n",
       "1128  multitok.char_lstm.ft_oov_tok.52_seed  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erdf = pd.read_pickle('final_setup/ooo_erdf.pkl')\n",
    "best_multi = (erdf.loc[(erdf.unit=='multitok') \n",
    "      & (erdf\n",
    "         .groupby(['unit', 'arch', 'embed_type', 'cm'])\n",
    "         .relevant_score\n",
    "         .transform(max)==erdf.relevant_score),\n",
    "         ['unit', 'arch', 'embed_type', 'cm', 'acc', 'model_base_name']]\n",
    " .sort_values('acc', ascending=False)\n",
    ")\n",
    "best_multi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'ID1', 'ID2']\n",
    "def get_pruned_lattice(lattices, bc, non_o_only=False):\n",
    "    valid_edges = get_valid_edges(lattices, bc, non_o_only=non_o_only)\n",
    "    pruned_lat = lattices[lattices[cols]\n",
    "                         .apply(lambda x: tuple(x) in valid_edges,\n",
    "                                axis=1)]\n",
    "    return pruned_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'final_setup/ooo_decode_output'\n",
    "models_folder = 'final_setup/ooo_models'\n",
    "pruned_folder = 'final_setup/ooo_pruned/lattices'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_setup/ooo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "final_setup/ooo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n"
     ]
    }
   ],
   "source": [
    "for i, row in best_multi.iterrows():\n",
    "    pruned_dev_path =  os.path.join(pruned_folder, \n",
    "                                    'dev.'+row.model_base_name+'.lattices')\n",
    "    if not os.path.exists(pruned_dev_path):\n",
    "        print(pruned_dev_path)\n",
    "        dev_path = os.path.join(output_folder, \n",
    "                                'token_dev.'+row.model_base_name+'.bmes')\n",
    "        dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "        pdev_lat = get_pruned_lattice(dev_lat, dev_bc)\n",
    "        to_lattices(pdev_lat, pruned_dev_path)\n",
    "\n",
    "    pruned_test_path = os.path.join(pruned_folder, \n",
    "                                    'test.'+row.model_base_name+'.lattices')    \n",
    "    if not os.path.exists(pruned_test_path):\n",
    "        print(pruned_test_path)\n",
    "        test_path = os.path.join(output_folder, \n",
    "                                 'token_test.'+row.model_base_name+'.bmes')\n",
    "        test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "        ptest_lat = get_pruned_lattice(test_lat, test_bc)\n",
    "        to_lattices(ptest_lat, pruned_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run YAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_path = '/home/nlp/danb/yapproj/src/yap/yap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOPATH=/home/nlp/danb/yapproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/yapproj/src/yap/yap - invoke yap as a standalone app or as an api server\n",
      "\n",
      "Commands:\n",
      "\n",
      "    api         start api server\n",
      "    dep         runs dependency training/parsing\n",
      "    hebma       run lexicon-based morphological analyzer on raw input\n",
      "    joint       runs joint morpho-syntactic training and parsing\n",
      "    ma          run data-driven morphological analyzer on raw input\n",
      "    md          runs standalone morphological disambiguation training and parsing\n",
      "\n",
      "Use \"/home/nlp/danb/yapproj/src/yap/yap help <command>\" for more information about a command.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{yap_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_folder = 'final_setup/ooo_pruned/lattices'\n",
    "yap_output_folder = 'final_setup/ooo_pruned/yap_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/01/24 17:27:10.375153 GOMAXPROCS:\t40\n",
      "2020/01/24 17:27:10.375357 \n",
      "2020/01/24 17:27:10.401402 *** CONFIGURATION ***\n",
      "2020/01/24 17:27:10.401435 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/24 17:27:10.401504 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/24 17:27:10.401527 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/24 17:27:10.401544 Iterations:\t\t1\n",
      "2020/01/24 17:27:10.401564 Beam Size:\t\t64\n",
      "2020/01/24 17:27:10.401583 Beam Concurrent:\ttrue\n",
      "2020/01/24 17:27:10.401599 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/24 17:27:10.401623 Use Lemmas:\t\tfalse\n",
      "2020/01/24 17:27:10.401642 Use POP:\t\ttrue\n",
      "2020/01/24 17:27:10.401666 Infuse Gold Dev:\tfalse\n",
      "2020/01/24 17:27:10.401689 Limit (thousands):\t0\n",
      "2020/01/24 17:27:10.401712 Use CoNLL-U:\t\tfalse\n",
      "2020/01/24 17:27:10.401755 \n",
      "2020/01/24 17:27:10.401781 Features File:\tjointzeager.yaml\n",
      "2020/01/24 17:27:10.423623 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/24 17:27:10.424816 \n",
      "2020/01/24 17:27:10.424843 Data\n",
      "2020/01/24 17:27:10.424858 Test file  (ambig.  lattice):\tfinal_setup/ooo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:27:10.424922 Out (disamb.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.conll\n",
      "2020/01/24 17:27:10.424948 Out (segmt.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.seg\n",
      "2020/01/24 17:27:10.424969 Out (mapping.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.map\n",
      "2020/01/24 17:27:10.425750 \n",
      "2020/01/24 17:27:10.425778 Setup enumerations\n",
      "2020/01/24 17:27:10.425908 ETrans Len is 96\n",
      "2020/01/24 17:27:10.426243 \n",
      "2020/01/24 17:27:10.426297 Loading features\n",
      "2020/01/24 17:27:10.427967 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/24 17:27:10.428065 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/24 17:27:10.428167 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/24 17:27:10.428274 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/24 17:27:10.428300 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/24 17:27:10.428380 Loading POP transition dependent feature group POP\n",
      "2020/01/24 17:27:10.428429 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/24 17:27:10.428471 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/24 17:27:10.428951 \n",
      "2020/01/24 17:27:10.428989 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/24 17:27:10.429005 \n",
      "2020/01/24 17:27:10.429017 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/24 17:27:32.406847 Loaded model\n",
      "2020/01/24 17:27:32.406907 \n",
      "2020/01/24 17:27:32.406913 *** PARSING ***\n",
      "2020/01/24 17:27:32.406918 Parsing test\n",
      "2020/01/24 17:27:32.406960 Reading ambiguous lattices from final_setup/ooo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:27:32.461961 Read 500 ambiguous lattices from final_setup/ooo_pruned/lattices/dev.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:27:32.462002 Converting lattice format to internal structure\n",
      "2020/01/24 17:27:32.767349 Parsing instance 0\n",
      "2020/01/24 17:27:32.886628 Parsing instance 1\n",
      "2020/01/24 17:27:32.986413 Parsing instance 2\n",
      "2020/01/24 17:27:33.157225 Parsing instance 3\n",
      "2020/01/24 17:27:33.321423 Parsing instance 4\n",
      "2020/01/24 17:27:33.752614 Parsing instance 5\n",
      "2020/01/24 17:27:34.008266 Parsing instance 6\n",
      "2020/01/24 17:27:34.144685 Parsing instance 7\n",
      "2020/01/24 17:27:34.364159 Parsing instance 8\n",
      "2020/01/24 17:27:34.465677 Parsing instance 9\n",
      "2020/01/24 17:27:34.700877 Parsing instance 10\n",
      "2020/01/24 17:27:34.839525 Parsing instance 11\n",
      "2020/01/24 17:27:35.139029 Parsing instance 12\n",
      "2020/01/24 17:27:35.383603 Parsing instance 13\n",
      "2020/01/24 17:27:35.544360 Parsing instance 14\n",
      "2020/01/24 17:27:35.636396 Parsing instance 15\n",
      "2020/01/24 17:27:35.715822 Parsing instance 16\n",
      "2020/01/24 17:27:35.777844 Parsing instance 17\n",
      "2020/01/24 17:27:35.856503 Parsing instance 18\n",
      "2020/01/24 17:27:35.962862 Parsing instance 19\n",
      "2020/01/24 17:27:36.056534 Parsing instance 20\n",
      "2020/01/24 17:27:36.316515 Parsing instance 21\n",
      "2020/01/24 17:27:36.384201 Parsing instance 22\n",
      "2020/01/24 17:27:36.585605 Parsing instance 23\n",
      "2020/01/24 17:27:36.717176 Parsing instance 24\n",
      "2020/01/24 17:27:36.961582 Parsing instance 25\n",
      "2020/01/24 17:27:37.123496 Parsing instance 26\n",
      "2020/01/24 17:27:37.508154 Parsing instance 27\n",
      "2020/01/24 17:27:37.663954 Parsing instance 28\n",
      "2020/01/24 17:27:37.784493 Parsing instance 29\n",
      "2020/01/24 17:27:37.892532 Parsing instance 30\n",
      "2020/01/24 17:27:38.003645 Parsing instance 31\n",
      "2020/01/24 17:27:38.041117 Parsing instance 32\n",
      "2020/01/24 17:27:38.068189 Parsing instance 33\n",
      "2020/01/24 17:27:38.202390 Parsing instance 34\n",
      "2020/01/24 17:27:38.366276 Parsing instance 35\n",
      "2020/01/24 17:27:38.634418 Parsing instance 36\n",
      "2020/01/24 17:27:38.699679 Parsing instance 37\n",
      "2020/01/24 17:27:38.789852 Parsing instance 38\n",
      "2020/01/24 17:27:38.875027 Parsing instance 39\n",
      "2020/01/24 17:27:39.018967 Parsing instance 40\n",
      "2020/01/24 17:27:39.068682 Parsing instance 41\n",
      "2020/01/24 17:27:39.122501 Parsing instance 42\n",
      "2020/01/24 17:27:39.125233 Parsing instance 43\n",
      "2020/01/24 17:27:39.140059 Parsing instance 44\n",
      "2020/01/24 17:27:39.223447 Parsing instance 45\n",
      "2020/01/24 17:27:39.229346 Parsing instance 46\n",
      "2020/01/24 17:27:39.307451 Parsing instance 47\n",
      "2020/01/24 17:27:39.627706 Parsing instance 48\n",
      "2020/01/24 17:27:39.749598 Parsing instance 49\n",
      "2020/01/24 17:27:39.949515 Parsing instance 50\n",
      "2020/01/24 17:27:40.326246 Parsing instance 51\n",
      "2020/01/24 17:27:40.417197 Parsing instance 52\n",
      "2020/01/24 17:27:40.480731 Parsing instance 53\n",
      "2020/01/24 17:27:40.952368 Parsing instance 54\n",
      "2020/01/24 17:27:41.219870 Parsing instance 55\n",
      "2020/01/24 17:27:41.421853 Parsing instance 56\n",
      "2020/01/24 17:27:41.856185 Parsing instance 57\n",
      "2020/01/24 17:27:41.953024 Parsing instance 58\n",
      "2020/01/24 17:27:42.432055 Parsing instance 59\n",
      "2020/01/24 17:27:42.522262 Parsing instance 60\n",
      "2020/01/24 17:27:42.535301 Parsing instance 61\n",
      "2020/01/24 17:27:42.932164 Parsing instance 62\n",
      "2020/01/24 17:27:43.045931 Parsing instance 63\n",
      "2020/01/24 17:27:43.165930 Parsing instance 64\n",
      "2020/01/24 17:27:43.251272 Parsing instance 65\n",
      "2020/01/24 17:27:43.344844 Parsing instance 66\n",
      "2020/01/24 17:27:43.562434 Parsing instance 67\n",
      "2020/01/24 17:27:43.656326 Parsing instance 68\n",
      "2020/01/24 17:27:43.770425 Parsing instance 69\n",
      "2020/01/24 17:27:44.138843 Parsing instance 70\n",
      "2020/01/24 17:27:44.202687 Parsing instance 71\n",
      "2020/01/24 17:27:44.260110 Parsing instance 72\n",
      "2020/01/24 17:27:44.388309 Parsing instance 73\n",
      "2020/01/24 17:27:44.437021 Parsing instance 74\n",
      "2020/01/24 17:27:44.540181 Parsing instance 75\n",
      "2020/01/24 17:27:44.606156 Parsing instance 76\n",
      "2020/01/24 17:27:44.679546 Parsing instance 77\n",
      "2020/01/24 17:27:44.743104 Parsing instance 78\n",
      "2020/01/24 17:27:44.761768 Parsing instance 79\n",
      "2020/01/24 17:27:44.834975 Parsing instance 80\n",
      "2020/01/24 17:27:44.985898 Parsing instance 81\n",
      "2020/01/24 17:27:45.191945 Parsing instance 82\n",
      "2020/01/24 17:27:45.356548 Parsing instance 83\n",
      "2020/01/24 17:27:45.387747 Parsing instance 84\n",
      "2020/01/24 17:27:45.471733 Parsing instance 85\n",
      "2020/01/24 17:27:45.532841 Parsing instance 86\n",
      "2020/01/24 17:27:45.591588 Parsing instance 87\n",
      "2020/01/24 17:27:45.710776 Parsing instance 88\n",
      "2020/01/24 17:27:45.760690 Parsing instance 89\n",
      "2020/01/24 17:27:45.815244 Parsing instance 90\n",
      "2020/01/24 17:27:45.867071 Parsing instance 91\n",
      "2020/01/24 17:27:45.992041 Parsing instance 92\n",
      "2020/01/24 17:27:46.013935 Parsing instance 93\n",
      "2020/01/24 17:27:46.342180 Parsing instance 94\n",
      "2020/01/24 17:27:46.656415 Parsing instance 95\n",
      "2020/01/24 17:27:46.676760 Parsing instance 96\n",
      "2020/01/24 17:27:46.744744 Parsing instance 97\n",
      "2020/01/24 17:27:46.989423 Parsing instance 98\n",
      "2020/01/24 17:27:47.037649 Parsing instance 99\n",
      "2020/01/24 17:27:47.387234 Parsing instance 100\n",
      "2020/01/24 17:27:47.431434 Parsing instance 101\n",
      "2020/01/24 17:27:47.502720 Parsing instance 102\n",
      "2020/01/24 17:27:47.702522 Parsing instance 103\n",
      "2020/01/24 17:27:47.764217 Parsing instance 104\n",
      "2020/01/24 17:27:47.877548 Parsing instance 105\n",
      "2020/01/24 17:27:47.955225 Parsing instance 106\n",
      "2020/01/24 17:27:48.076558 Parsing instance 107\n",
      "2020/01/24 17:27:48.165953 Parsing instance 108\n",
      "2020/01/24 17:27:48.499783 Parsing instance 109\n",
      "2020/01/24 17:27:48.589538 Parsing instance 110\n",
      "2020/01/24 17:27:48.605815 Parsing instance 111\n",
      "2020/01/24 17:27:48.695538 Parsing instance 112\n",
      "2020/01/24 17:27:48.753798 Parsing instance 113\n",
      "2020/01/24 17:27:48.921974 Parsing instance 114\n",
      "2020/01/24 17:27:48.982610 Parsing instance 115\n",
      "2020/01/24 17:27:49.153807 Parsing instance 116\n",
      "2020/01/24 17:27:49.202816 Parsing instance 117\n",
      "2020/01/24 17:27:49.569298 Parsing instance 118\n",
      "2020/01/24 17:27:49.816119 Parsing instance 119\n",
      "2020/01/24 17:27:49.962707 Parsing instance 120\n",
      "2020/01/24 17:27:50.116494 Parsing instance 121\n",
      "2020/01/24 17:27:50.173300 Parsing instance 122\n",
      "2020/01/24 17:27:50.328838 Parsing instance 123\n",
      "2020/01/24 17:27:50.346892 Parsing instance 124\n",
      "2020/01/24 17:27:50.494533 Parsing instance 125\n",
      "2020/01/24 17:27:50.706755 Parsing instance 126\n",
      "2020/01/24 17:27:50.746233 Parsing instance 127\n",
      "2020/01/24 17:27:50.826797 Parsing instance 128\n",
      "2020/01/24 17:27:50.864440 Parsing instance 129\n",
      "2020/01/24 17:27:50.911765 Parsing instance 130\n",
      "2020/01/24 17:27:50.967862 Parsing instance 131\n",
      "2020/01/24 17:27:51.031806 Parsing instance 132\n",
      "2020/01/24 17:27:51.066864 Parsing instance 133\n",
      "2020/01/24 17:27:51.176921 Parsing instance 134\n",
      "2020/01/24 17:27:51.195671 Parsing instance 135\n",
      "2020/01/24 17:27:51.294031 Parsing instance 136\n",
      "2020/01/24 17:27:51.370633 Parsing instance 137\n",
      "2020/01/24 17:27:51.456673 Parsing instance 138\n",
      "2020/01/24 17:27:51.557783 Parsing instance 139\n",
      "2020/01/24 17:27:51.742968 Parsing instance 140\n",
      "2020/01/24 17:27:51.931087 Parsing instance 141\n",
      "2020/01/24 17:27:51.986357 Parsing instance 142\n",
      "2020/01/24 17:27:52.074441 Parsing instance 143\n",
      "2020/01/24 17:27:52.201326 Parsing instance 144\n",
      "2020/01/24 17:27:52.231100 Parsing instance 145\n",
      "2020/01/24 17:27:52.291504 Parsing instance 146\n",
      "2020/01/24 17:27:52.312097 Parsing instance 147\n",
      "2020/01/24 17:27:52.344967 Parsing instance 148\n",
      "2020/01/24 17:27:52.400212 Parsing instance 149\n",
      "2020/01/24 17:27:52.488171 Parsing instance 150\n",
      "2020/01/24 17:27:52.996004 Parsing instance 151\n",
      "2020/01/24 17:27:53.004533 Parsing instance 152\n",
      "2020/01/24 17:27:53.011949 Parsing instance 153\n",
      "2020/01/24 17:27:53.111130 Parsing instance 154\n",
      "2020/01/24 17:27:53.119506 Parsing instance 155\n",
      "2020/01/24 17:27:53.427805 Parsing instance 156\n",
      "2020/01/24 17:27:53.517366 Parsing instance 157\n",
      "2020/01/24 17:27:53.575358 Parsing instance 158\n",
      "2020/01/24 17:27:53.592725 Parsing instance 159\n",
      "2020/01/24 17:27:53.620492 Parsing instance 160\n",
      "2020/01/24 17:27:53.741534 Parsing instance 161\n",
      "2020/01/24 17:27:53.761584 Parsing instance 162\n",
      "2020/01/24 17:27:54.040699 Parsing instance 163\n",
      "2020/01/24 17:27:54.287942 Parsing instance 164\n",
      "2020/01/24 17:27:54.458546 Parsing instance 165\n",
      "2020/01/24 17:27:54.469002 Parsing instance 166\n",
      "2020/01/24 17:27:54.496972 Parsing instance 167\n",
      "2020/01/24 17:27:54.566688 Parsing instance 168\n",
      "2020/01/24 17:27:54.607497 Parsing instance 169\n",
      "2020/01/24 17:27:54.790943 Parsing instance 170\n",
      "2020/01/24 17:27:54.867178 Parsing instance 171\n",
      "2020/01/24 17:27:55.299104 Parsing instance 172\n",
      "2020/01/24 17:27:55.369603 Parsing instance 173\n",
      "2020/01/24 17:27:55.514722 Parsing instance 174\n",
      "2020/01/24 17:27:55.700820 Parsing instance 175\n",
      "2020/01/24 17:27:55.729592 Parsing instance 176\n",
      "2020/01/24 17:27:55.837096 Parsing instance 177\n",
      "2020/01/24 17:27:56.026457 Parsing instance 178\n",
      "2020/01/24 17:27:56.325760 Parsing instance 179\n",
      "2020/01/24 17:27:56.334976 Parsing instance 180\n",
      "2020/01/24 17:27:56.358810 Parsing instance 181\n",
      "2020/01/24 17:27:56.416899 Parsing instance 182\n",
      "2020/01/24 17:27:56.745811 Parsing instance 183\n",
      "2020/01/24 17:27:56.778639 Parsing instance 184\n",
      "2020/01/24 17:27:56.857209 Parsing instance 185\n",
      "2020/01/24 17:27:57.007654 Parsing instance 186\n",
      "2020/01/24 17:27:57.363719 Parsing instance 187\n",
      "2020/01/24 17:27:57.429549 Parsing instance 188\n",
      "2020/01/24 17:27:57.440868 Parsing instance 189\n",
      "2020/01/24 17:27:57.473497 Parsing instance 190\n",
      "2020/01/24 17:27:57.645709 Parsing instance 191\n",
      "2020/01/24 17:27:57.802415 Parsing instance 192\n",
      "2020/01/24 17:27:57.847784 Parsing instance 193\n",
      "2020/01/24 17:27:57.857172 Parsing instance 194\n",
      "2020/01/24 17:27:57.873983 Parsing instance 195\n",
      "2020/01/24 17:27:57.997329 Parsing instance 196\n",
      "2020/01/24 17:27:58.072833 Parsing instance 197\n",
      "2020/01/24 17:27:58.129687 Parsing instance 198\n",
      "2020/01/24 17:27:58.463437 Parsing instance 199\n",
      "2020/01/24 17:27:58.481554 Parsing instance 200\n",
      "2020/01/24 17:27:58.612351 Parsing instance 201\n",
      "2020/01/24 17:27:58.644801 Parsing instance 202\n",
      "2020/01/24 17:27:58.718888 Parsing instance 203\n",
      "2020/01/24 17:27:58.747257 Parsing instance 204\n",
      "2020/01/24 17:27:58.865857 Parsing instance 205\n",
      "2020/01/24 17:27:58.875241 Parsing instance 206\n",
      "2020/01/24 17:27:58.884687 Parsing instance 207\n",
      "2020/01/24 17:27:58.942653 Parsing instance 208\n",
      "2020/01/24 17:27:59.092176 Parsing instance 209\n",
      "2020/01/24 17:27:59.171019 Parsing instance 210\n",
      "2020/01/24 17:27:59.477379 Parsing instance 211\n",
      "2020/01/24 17:27:59.649344 Parsing instance 212\n",
      "2020/01/24 17:27:59.761005 Parsing instance 213\n",
      "2020/01/24 17:27:59.828404 Parsing instance 214\n",
      "2020/01/24 17:27:59.916814 Parsing instance 215\n",
      "2020/01/24 17:28:00.114433 Parsing instance 216\n",
      "2020/01/24 17:28:00.123789 Parsing instance 217\n",
      "2020/01/24 17:28:00.168408 Parsing instance 218\n",
      "2020/01/24 17:28:00.255147 Parsing instance 219\n",
      "2020/01/24 17:28:00.731720 Parsing instance 220\n",
      "2020/01/24 17:28:00.886330 Parsing instance 221\n",
      "2020/01/24 17:28:00.961855 Parsing instance 222\n",
      "2020/01/24 17:28:01.012660 Parsing instance 223\n",
      "2020/01/24 17:28:01.117201 Parsing instance 224\n",
      "2020/01/24 17:28:01.370586 Parsing instance 225\n",
      "2020/01/24 17:28:01.446551 Parsing instance 226\n",
      "2020/01/24 17:28:01.509059 Parsing instance 227\n",
      "2020/01/24 17:28:01.973261 Parsing instance 228\n",
      "2020/01/24 17:28:02.524664 Parsing instance 229\n",
      "2020/01/24 17:28:02.532208 Parsing instance 230\n",
      "2020/01/24 17:28:02.879479 Parsing instance 231\n",
      "2020/01/24 17:28:02.990419 Parsing instance 232\n",
      "2020/01/24 17:28:03.035349 Parsing instance 233\n",
      "2020/01/24 17:28:03.136815 Parsing instance 234\n",
      "2020/01/24 17:28:03.247957 Parsing instance 235\n",
      "2020/01/24 17:28:03.354792 Parsing instance 236\n",
      "2020/01/24 17:28:03.439653 Parsing instance 237\n",
      "2020/01/24 17:28:03.580882 Parsing instance 238\n",
      "2020/01/24 17:28:03.997836 Parsing instance 239\n",
      "2020/01/24 17:28:04.357288 Parsing instance 240\n",
      "2020/01/24 17:28:04.450695 Parsing instance 241\n",
      "2020/01/24 17:28:04.518351 Parsing instance 242\n",
      "2020/01/24 17:28:04.597040 Parsing instance 243\n",
      "2020/01/24 17:28:04.665212 Parsing instance 244\n",
      "2020/01/24 17:28:04.808191 Parsing instance 245\n",
      "2020/01/24 17:28:04.817743 Parsing instance 246\n",
      "2020/01/24 17:28:04.844063 Parsing instance 247\n",
      "2020/01/24 17:28:05.098279 Parsing instance 248\n",
      "2020/01/24 17:28:05.322331 Parsing instance 249\n",
      "2020/01/24 17:28:05.367692 Parsing instance 250\n",
      "2020/01/24 17:28:05.459488 Parsing instance 251\n",
      "2020/01/24 17:28:05.561300 Parsing instance 252\n",
      "2020/01/24 17:28:05.657787 Parsing instance 253\n",
      "2020/01/24 17:28:05.666631 Parsing instance 254\n",
      "2020/01/24 17:28:05.689126 Parsing instance 255\n",
      "2020/01/24 17:28:05.807913 Parsing instance 256\n",
      "2020/01/24 17:28:05.917831 Parsing instance 257\n",
      "2020/01/24 17:28:06.262210 Parsing instance 258\n",
      "2020/01/24 17:28:06.513306 Parsing instance 259\n",
      "2020/01/24 17:28:06.534670 Parsing instance 260\n",
      "2020/01/24 17:28:06.717789 Parsing instance 261\n",
      "2020/01/24 17:28:06.834374 Parsing instance 262\n",
      "2020/01/24 17:28:06.970215 Parsing instance 263\n",
      "2020/01/24 17:28:07.517374 Parsing instance 264\n",
      "2020/01/24 17:28:07.522686 Parsing instance 265\n",
      "2020/01/24 17:28:07.650779 Parsing instance 266\n",
      "2020/01/24 17:28:07.688203 Parsing instance 267\n",
      "2020/01/24 17:28:07.757289 Parsing instance 268\n",
      "2020/01/24 17:28:07.871214 Parsing instance 269\n",
      "2020/01/24 17:28:07.947932 Parsing instance 270\n",
      "2020/01/24 17:28:08.286029 Parsing instance 271\n",
      "2020/01/24 17:28:08.436867 Parsing instance 272\n",
      "2020/01/24 17:28:08.522414 Parsing instance 273\n",
      "2020/01/24 17:28:08.566900 Parsing instance 274\n",
      "2020/01/24 17:28:08.792910 Parsing instance 275\n",
      "2020/01/24 17:28:08.871951 Parsing instance 276\n",
      "2020/01/24 17:28:08.930028 Parsing instance 277\n",
      "2020/01/24 17:28:09.152795 Parsing instance 278\n",
      "2020/01/24 17:28:09.248207 Parsing instance 279\n",
      "2020/01/24 17:28:09.533723 Parsing instance 280\n",
      "2020/01/24 17:28:09.693383 Parsing instance 281\n",
      "2020/01/24 17:28:09.830536 Parsing instance 282\n",
      "2020/01/24 17:28:09.867534 Parsing instance 283\n",
      "2020/01/24 17:28:09.950531 Parsing instance 284\n",
      "2020/01/24 17:28:09.992521 Parsing instance 285\n",
      "2020/01/24 17:28:10.073805 Parsing instance 286\n",
      "2020/01/24 17:28:10.125174 Parsing instance 287\n",
      "2020/01/24 17:28:10.178464 Parsing instance 288\n",
      "2020/01/24 17:28:10.303947 Parsing instance 289\n",
      "2020/01/24 17:28:10.317283 Parsing instance 290\n",
      "2020/01/24 17:28:10.338600 Parsing instance 291\n",
      "2020/01/24 17:28:10.382570 Parsing instance 292\n",
      "2020/01/24 17:28:10.405540 Parsing instance 293\n",
      "2020/01/24 17:28:10.766063 Parsing instance 294\n",
      "2020/01/24 17:28:10.841557 Parsing instance 295\n",
      "2020/01/24 17:28:10.866719 Parsing instance 296\n",
      "2020/01/24 17:28:10.955961 Parsing instance 297\n",
      "2020/01/24 17:28:11.036856 Parsing instance 298\n",
      "2020/01/24 17:28:11.077159 Parsing instance 299\n",
      "2020/01/24 17:28:11.170660 Parsing instance 300\n",
      "2020/01/24 17:28:11.199669 Parsing instance 301\n",
      "2020/01/24 17:28:11.324660 Parsing instance 302\n",
      "2020/01/24 17:28:11.377236 Parsing instance 303\n",
      "2020/01/24 17:28:11.404053 Parsing instance 304\n",
      "2020/01/24 17:28:11.538958 Parsing instance 305\n",
      "2020/01/24 17:28:12.390065 Parsing instance 306\n",
      "2020/01/24 17:28:12.533094 Parsing instance 307\n",
      "2020/01/24 17:28:12.620911 Parsing instance 308\n",
      "2020/01/24 17:28:12.929807 Parsing instance 309\n",
      "2020/01/24 17:28:13.095321 Parsing instance 310\n",
      "2020/01/24 17:28:13.152493 Parsing instance 311\n",
      "2020/01/24 17:28:13.183573 Parsing instance 312\n",
      "2020/01/24 17:28:13.220101 Parsing instance 313\n",
      "2020/01/24 17:28:13.262803 Parsing instance 314\n",
      "2020/01/24 17:28:13.323168 Parsing instance 315\n",
      "2020/01/24 17:28:13.388746 Parsing instance 316\n",
      "2020/01/24 17:28:13.433965 Parsing instance 317\n",
      "2020/01/24 17:28:13.512730 Parsing instance 318\n",
      "2020/01/24 17:28:13.579460 Parsing instance 319\n",
      "2020/01/24 17:28:13.832817 Parsing instance 320\n",
      "2020/01/24 17:28:13.862608 Parsing instance 321\n",
      "2020/01/24 17:28:13.882138 Parsing instance 322\n",
      "2020/01/24 17:28:14.464794 Parsing instance 323\n",
      "2020/01/24 17:28:14.523052 Parsing instance 324\n",
      "2020/01/24 17:28:14.572049 Parsing instance 325\n",
      "2020/01/24 17:28:14.598876 Parsing instance 326\n",
      "2020/01/24 17:28:14.806725 Parsing instance 327\n",
      "2020/01/24 17:28:14.918496 Parsing instance 328\n",
      "2020/01/24 17:28:15.025924 Parsing instance 329\n",
      "2020/01/24 17:28:15.390150 Parsing instance 330\n",
      "2020/01/24 17:28:15.506851 Parsing instance 331\n",
      "2020/01/24 17:28:15.552126 Parsing instance 332\n",
      "2020/01/24 17:28:15.645972 Parsing instance 333\n",
      "2020/01/24 17:28:15.745570 Parsing instance 334\n",
      "2020/01/24 17:28:15.774084 Parsing instance 335\n",
      "2020/01/24 17:28:15.827836 Parsing instance 336\n",
      "2020/01/24 17:28:15.945804 Parsing instance 337\n",
      "2020/01/24 17:28:16.059820 Parsing instance 338\n",
      "2020/01/24 17:28:16.119128 Parsing instance 339\n",
      "2020/01/24 17:28:16.167120 Parsing instance 340\n",
      "2020/01/24 17:28:16.212445 Parsing instance 341\n",
      "2020/01/24 17:28:16.508865 Parsing instance 342\n",
      "2020/01/24 17:28:16.540962 Parsing instance 343\n",
      "2020/01/24 17:28:16.598596 Parsing instance 344\n",
      "2020/01/24 17:28:16.671817 Parsing instance 345\n",
      "2020/01/24 17:28:16.817842 Parsing instance 346\n",
      "2020/01/24 17:28:16.906048 Parsing instance 347\n",
      "2020/01/24 17:28:16.992490 Parsing instance 348\n",
      "2020/01/24 17:28:17.029965 Parsing instance 349\n",
      "2020/01/24 17:28:17.167546 Parsing instance 350\n",
      "2020/01/24 17:28:17.336300 Parsing instance 351\n",
      "2020/01/24 17:28:17.704403 Parsing instance 352\n",
      "2020/01/24 17:28:17.724839 Parsing instance 353\n",
      "2020/01/24 17:28:17.833581 Parsing instance 354\n",
      "2020/01/24 17:28:17.854434 Parsing instance 355\n",
      "2020/01/24 17:28:17.927048 Parsing instance 356\n",
      "2020/01/24 17:28:18.019976 Parsing instance 357\n",
      "2020/01/24 17:28:18.113910 Parsing instance 358\n",
      "2020/01/24 17:28:18.135507 Parsing instance 359\n",
      "2020/01/24 17:28:18.225163 Parsing instance 360\n",
      "2020/01/24 17:28:18.275469 Parsing instance 361\n",
      "2020/01/24 17:28:18.343821 Parsing instance 362\n",
      "2020/01/24 17:28:18.446449 Parsing instance 363\n",
      "2020/01/24 17:28:18.738701 Parsing instance 364\n",
      "2020/01/24 17:28:18.753040 Parsing instance 365\n",
      "2020/01/24 17:28:18.762121 Parsing instance 366\n",
      "2020/01/24 17:28:18.877874 Parsing instance 367\n",
      "2020/01/24 17:28:19.031799 Parsing instance 368\n",
      "2020/01/24 17:28:19.099330 Parsing instance 369\n",
      "2020/01/24 17:28:19.215893 Parsing instance 370\n",
      "2020/01/24 17:28:19.261321 Parsing instance 371\n",
      "2020/01/24 17:28:19.320258 Parsing instance 372\n",
      "2020/01/24 17:28:19.357916 Parsing instance 373\n",
      "2020/01/24 17:28:19.382855 Parsing instance 374\n",
      "2020/01/24 17:28:19.433576 Parsing instance 375\n",
      "2020/01/24 17:28:19.550959 Parsing instance 376\n",
      "2020/01/24 17:28:19.608551 Parsing instance 377\n",
      "2020/01/24 17:28:19.902406 Parsing instance 378\n",
      "2020/01/24 17:28:19.982819 Parsing instance 379\n",
      "2020/01/24 17:28:20.015816 Parsing instance 380\n",
      "2020/01/24 17:28:20.031647 Parsing instance 381\n",
      "2020/01/24 17:28:20.143280 Parsing instance 382\n",
      "2020/01/24 17:28:20.199905 Parsing instance 383\n",
      "2020/01/24 17:28:20.283641 Parsing instance 384\n",
      "2020/01/24 17:28:20.325832 Parsing instance 385\n",
      "2020/01/24 17:28:20.344553 Parsing instance 386\n",
      "2020/01/24 17:28:20.424276 Parsing instance 387\n",
      "2020/01/24 17:28:20.567986 Parsing instance 388\n",
      "2020/01/24 17:28:20.594005 Parsing instance 389\n",
      "2020/01/24 17:28:20.636350 Parsing instance 390\n",
      "2020/01/24 17:28:20.701150 Parsing instance 391\n",
      "2020/01/24 17:28:20.763214 Parsing instance 392\n",
      "2020/01/24 17:28:21.104892 Parsing instance 393\n",
      "2020/01/24 17:28:21.193678 Parsing instance 394\n",
      "2020/01/24 17:28:21.311677 Parsing instance 395\n",
      "2020/01/24 17:28:21.421746 Parsing instance 396\n",
      "2020/01/24 17:28:21.506400 Parsing instance 397\n",
      "2020/01/24 17:28:21.665591 Parsing instance 398\n",
      "2020/01/24 17:28:21.688132 Parsing instance 399\n",
      "2020/01/24 17:28:21.796514 Parsing instance 400\n",
      "2020/01/24 17:28:21.947621 Parsing instance 401\n",
      "2020/01/24 17:28:22.264417 Parsing instance 402\n",
      "2020/01/24 17:28:22.317280 Parsing instance 403\n",
      "2020/01/24 17:28:22.375075 Parsing instance 404\n",
      "2020/01/24 17:28:22.472559 Parsing instance 405\n",
      "2020/01/24 17:28:22.520146 Parsing instance 406\n",
      "2020/01/24 17:28:22.568046 Parsing instance 407\n",
      "2020/01/24 17:28:22.635768 Parsing instance 408\n",
      "2020/01/24 17:28:22.869566 Parsing instance 409\n",
      "2020/01/24 17:28:22.883911 Parsing instance 410\n",
      "2020/01/24 17:28:22.931165 Parsing instance 411\n",
      "2020/01/24 17:28:23.302640 Parsing instance 412\n",
      "2020/01/24 17:28:23.353018 Parsing instance 413\n",
      "2020/01/24 17:28:23.420868 Parsing instance 414\n",
      "2020/01/24 17:28:23.444483 Parsing instance 415\n",
      "2020/01/24 17:28:23.484480 Parsing instance 416\n",
      "2020/01/24 17:28:23.703288 Parsing instance 417\n",
      "2020/01/24 17:28:23.743363 Parsing instance 418\n",
      "2020/01/24 17:28:23.786782 Parsing instance 419\n",
      "2020/01/24 17:28:23.859140 Parsing instance 420\n",
      "2020/01/24 17:28:23.886208 Parsing instance 421\n",
      "2020/01/24 17:28:24.014766 Parsing instance 422\n",
      "2020/01/24 17:28:24.023204 Parsing instance 423\n",
      "2020/01/24 17:28:24.043563 Parsing instance 424\n",
      "2020/01/24 17:28:24.069483 Parsing instance 425\n",
      "2020/01/24 17:28:24.114627 Parsing instance 426\n",
      "2020/01/24 17:28:24.159279 Parsing instance 427\n",
      "2020/01/24 17:28:24.512339 Parsing instance 428\n",
      "2020/01/24 17:28:24.677707 Parsing instance 429\n",
      "2020/01/24 17:28:24.810785 Parsing instance 430\n",
      "2020/01/24 17:28:24.855532 Parsing instance 431\n",
      "2020/01/24 17:28:24.926638 Parsing instance 432\n",
      "2020/01/24 17:28:24.972265 Parsing instance 433\n",
      "2020/01/24 17:28:24.999927 Parsing instance 434\n",
      "2020/01/24 17:28:25.022222 Parsing instance 435\n",
      "2020/01/24 17:28:25.051083 Parsing instance 436\n",
      "2020/01/24 17:28:25.106592 Parsing instance 437\n",
      "2020/01/24 17:28:25.127674 Parsing instance 438\n",
      "2020/01/24 17:28:25.187013 Parsing instance 439\n",
      "2020/01/24 17:28:25.246254 Parsing instance 440\n",
      "2020/01/24 17:28:25.287968 Parsing instance 441\n",
      "2020/01/24 17:28:25.679848 Parsing instance 442\n",
      "2020/01/24 17:28:25.784228 Parsing instance 443\n",
      "2020/01/24 17:28:25.864117 Parsing instance 444\n",
      "2020/01/24 17:28:26.000542 Parsing instance 445\n",
      "2020/01/24 17:28:26.050709 Parsing instance 446\n",
      "2020/01/24 17:28:26.068478 Parsing instance 447\n",
      "2020/01/24 17:28:26.157193 Parsing instance 448\n",
      "2020/01/24 17:28:26.353569 Parsing instance 449\n",
      "2020/01/24 17:28:26.371389 Parsing instance 450\n",
      "2020/01/24 17:28:26.397784 Parsing instance 451\n",
      "2020/01/24 17:28:26.671211 Parsing instance 452\n",
      "2020/01/24 17:28:26.752691 Parsing instance 453\n",
      "2020/01/24 17:28:26.780856 Parsing instance 454\n",
      "2020/01/24 17:28:26.975286 Parsing instance 455\n",
      "2020/01/24 17:28:26.985569 Parsing instance 456\n",
      "2020/01/24 17:28:26.992773 Parsing instance 457\n",
      "2020/01/24 17:28:27.010438 Parsing instance 458\n",
      "2020/01/24 17:28:27.068453 Parsing instance 459\n",
      "2020/01/24 17:28:27.148806 Parsing instance 460\n",
      "2020/01/24 17:28:27.156466 Parsing instance 461\n",
      "2020/01/24 17:28:27.185762 Parsing instance 462\n",
      "2020/01/24 17:28:27.369463 Parsing instance 463\n",
      "2020/01/24 17:28:27.421805 Parsing instance 464\n",
      "2020/01/24 17:28:27.456734 Parsing instance 465\n",
      "2020/01/24 17:28:27.504275 Parsing instance 466\n",
      "2020/01/24 17:28:27.562871 Parsing instance 467\n",
      "2020/01/24 17:28:27.580386 Parsing instance 468\n",
      "2020/01/24 17:28:27.643923 Parsing instance 469\n",
      "2020/01/24 17:28:27.991176 Parsing instance 470\n",
      "2020/01/24 17:28:28.035607 Parsing instance 471\n",
      "2020/01/24 17:28:28.105004 Parsing instance 472\n",
      "2020/01/24 17:28:28.118336 Parsing instance 473\n",
      "2020/01/24 17:28:28.165112 Parsing instance 474\n",
      "2020/01/24 17:28:28.222476 Parsing instance 475\n",
      "2020/01/24 17:28:28.245536 Parsing instance 476\n",
      "2020/01/24 17:28:28.263403 Parsing instance 477\n",
      "2020/01/24 17:28:28.284670 Parsing instance 478\n",
      "2020/01/24 17:28:28.350848 Parsing instance 479\n",
      "2020/01/24 17:28:28.366142 Parsing instance 480\n",
      "2020/01/24 17:28:28.386138 Parsing instance 481\n",
      "2020/01/24 17:28:28.422553 Parsing instance 482\n",
      "2020/01/24 17:28:28.446721 Parsing instance 483\n",
      "2020/01/24 17:28:28.507959 Parsing instance 484\n",
      "2020/01/24 17:28:28.558002 Parsing instance 485\n",
      "2020/01/24 17:28:28.599522 Parsing instance 486\n",
      "2020/01/24 17:28:28.682751 Parsing instance 487\n",
      "2020/01/24 17:28:28.772821 Parsing instance 488\n",
      "2020/01/24 17:28:28.990518 Parsing instance 489\n",
      "2020/01/24 17:28:29.070915 Parsing instance 490\n",
      "2020/01/24 17:28:29.112717 Parsing instance 491\n",
      "2020/01/24 17:28:29.206296 Parsing instance 492\n",
      "2020/01/24 17:28:29.286099 Parsing instance 493\n",
      "2020/01/24 17:28:29.337981 Parsing instance 494\n",
      "2020/01/24 17:28:29.353074 Parsing instance 495\n",
      "2020/01/24 17:28:29.403155 Parsing instance 496\n",
      "2020/01/24 17:28:29.495551 Parsing instance 497\n",
      "2020/01/24 17:28:29.533200 Parsing instance 498\n",
      "2020/01/24 17:28:29.545092 Parsing instance 499\n",
      "2020/01/24 17:28:29.557839 PARSE Total Time: 56.790486183s\n",
      "2020/01/24 17:28:29.557868 Converting 500 to conll\n",
      "2020/01/24 17:28:29.557874 Writing to output file\n",
      "2020/01/24 17:28:29.606017 Wrote 500 in conll format to final_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.conll\n",
      "2020/01/24 17:28:29.606041 Writing to segmentation file\n",
      "2020/01/24 17:28:29.657245 Wrote 500 in segmentation format to final_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.seg\n",
      "2020/01/24 17:28:29.657285 Writing to mapping file\n",
      "2020/01/24 17:28:29.926746 Wrote 500 in mapping format to final_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.map\n",
      "2020/01/24 17:28:29.926786 Writing to gold segmentation file\n",
      "2020/01/24 17:28:30.453860 GOMAXPROCS:\t40\n",
      "2020/01/24 17:28:30.454041 \n",
      "2020/01/24 17:28:30.454796 *** CONFIGURATION ***\n",
      "2020/01/24 17:28:30.454826 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/24 17:28:30.454880 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/24 17:28:30.454908 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/24 17:28:30.454926 Iterations:\t\t1\n",
      "2020/01/24 17:28:30.454946 Beam Size:\t\t64\n",
      "2020/01/24 17:28:30.454967 Beam Concurrent:\ttrue\n",
      "2020/01/24 17:28:30.454984 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/24 17:28:30.455001 Use Lemmas:\t\tfalse\n",
      "2020/01/24 17:28:30.455021 Use POP:\t\ttrue\n",
      "2020/01/24 17:28:30.455047 Infuse Gold Dev:\tfalse\n",
      "2020/01/24 17:28:30.455072 Limit (thousands):\t0\n",
      "2020/01/24 17:28:30.455111 Use CoNLL-U:\t\tfalse\n",
      "2020/01/24 17:28:30.455153 \n",
      "2020/01/24 17:28:30.455181 Features File:\tjointzeager.yaml\n",
      "2020/01/24 17:28:30.455890 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/24 17:28:30.456205 \n",
      "2020/01/24 17:28:30.456229 Data\n",
      "2020/01/24 17:28:30.456246 Test file  (ambig.  lattice):\tfinal_setup/ooo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:28:30.456941 Out (disamb.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.conll\n",
      "2020/01/24 17:28:30.456982 Out (segmt.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.seg\n",
      "2020/01/24 17:28:30.457014 Out (mapping.) file:\t\t\tfinal_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.map\n",
      "2020/01/24 17:28:30.457637 \n",
      "2020/01/24 17:28:30.457660 Setup enumerations\n",
      "2020/01/24 17:28:30.457794 ETrans Len is 96\n",
      "2020/01/24 17:28:30.458053 \n",
      "2020/01/24 17:28:30.458074 Loading features\n",
      "2020/01/24 17:28:30.459863 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/24 17:28:30.459969 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/24 17:28:30.460097 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/24 17:28:30.460180 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/24 17:28:30.460209 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/24 17:28:30.460308 Loading POP transition dependent feature group POP\n",
      "2020/01/24 17:28:30.460343 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/24 17:28:30.460380 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/24 17:28:30.460904 \n",
      "2020/01/24 17:28:30.460949 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/24 17:28:30.460969 \n",
      "2020/01/24 17:28:30.460984 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/24 17:28:52.415016 Loaded model\n",
      "2020/01/24 17:28:52.415067 \n",
      "2020/01/24 17:28:52.415072 *** PARSING ***\n",
      "2020/01/24 17:28:52.415077 Parsing test\n",
      "2020/01/24 17:28:52.415101 Reading ambiguous lattices from final_setup/ooo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:28:52.503391 Read 706 ambiguous lattices from final_setup/ooo_pruned/lattices/test.multitok.char_lstm.ft_oov_tok.52_seed.lattices\n",
      "2020/01/24 17:28:52.503421 Converting lattice format to internal structure\n",
      "2020/01/24 17:28:52.967877 Parsing instance 0\n",
      "2020/01/24 17:28:53.206633 Parsing instance 1\n",
      "2020/01/24 17:28:53.313534 Parsing instance 2\n",
      "2020/01/24 17:28:53.378167 Parsing instance 3\n",
      "2020/01/24 17:28:53.477299 Parsing instance 4\n",
      "2020/01/24 17:28:53.535483 Parsing instance 5\n",
      "2020/01/24 17:28:53.877558 Parsing instance 6\n",
      "2020/01/24 17:28:53.985640 Parsing instance 7\n",
      "2020/01/24 17:28:54.044220 Parsing instance 8\n",
      "2020/01/24 17:28:54.059512 Parsing instance 9\n",
      "2020/01/24 17:28:54.105258 Parsing instance 10\n",
      "2020/01/24 17:28:54.212003 Parsing instance 11\n",
      "2020/01/24 17:28:54.287173 Parsing instance 12\n",
      "2020/01/24 17:28:54.397561 Parsing instance 13\n",
      "2020/01/24 17:28:54.440142 Parsing instance 14\n",
      "2020/01/24 17:28:54.490992 Parsing instance 15\n",
      "2020/01/24 17:28:54.548104 Parsing instance 16\n",
      "2020/01/24 17:28:54.695603 Parsing instance 17\n",
      "2020/01/24 17:28:55.033366 Parsing instance 18\n",
      "2020/01/24 17:28:55.154084 Parsing instance 19\n",
      "2020/01/24 17:28:55.312034 Parsing instance 20\n",
      "2020/01/24 17:28:55.330718 Parsing instance 21\n",
      "2020/01/24 17:28:55.346604 Parsing instance 22\n",
      "2020/01/24 17:28:55.367168 Parsing instance 23\n",
      "2020/01/24 17:28:55.555632 Parsing instance 24\n",
      "2020/01/24 17:28:55.648754 Parsing instance 25\n",
      "2020/01/24 17:28:55.697216 Parsing instance 26\n",
      "2020/01/24 17:28:55.749077 Parsing instance 27\n",
      "2020/01/24 17:28:55.875641 Parsing instance 28\n",
      "2020/01/24 17:28:56.057555 Parsing instance 29\n",
      "2020/01/24 17:28:56.197996 Parsing instance 30\n",
      "2020/01/24 17:28:56.308301 Parsing instance 31\n",
      "2020/01/24 17:28:56.359205 Parsing instance 32\n",
      "2020/01/24 17:28:56.551417 Parsing instance 33\n",
      "2020/01/24 17:28:56.618235 Parsing instance 34\n",
      "2020/01/24 17:28:56.742983 Parsing instance 35\n",
      "2020/01/24 17:28:56.935828 Parsing instance 36\n",
      "2020/01/24 17:28:56.973656 Parsing instance 37\n",
      "2020/01/24 17:28:57.044769 Parsing instance 38\n",
      "2020/01/24 17:28:57.053014 Parsing instance 39\n",
      "2020/01/24 17:28:57.418256 Parsing instance 40\n",
      "2020/01/24 17:28:57.478089 Parsing instance 41\n",
      "2020/01/24 17:28:57.518025 Parsing instance 42\n",
      "2020/01/24 17:28:57.636056 Parsing instance 43\n",
      "2020/01/24 17:28:57.776883 Parsing instance 44\n",
      "2020/01/24 17:28:57.879869 Parsing instance 45\n",
      "2020/01/24 17:28:58.098131 Parsing instance 46\n",
      "2020/01/24 17:28:58.114112 Parsing instance 47\n",
      "2020/01/24 17:28:58.460121 Parsing instance 48\n",
      "2020/01/24 17:28:58.541595 Parsing instance 49\n",
      "2020/01/24 17:28:58.604114 Parsing instance 50\n",
      "2020/01/24 17:28:58.788683 Parsing instance 51\n",
      "2020/01/24 17:28:58.873054 Parsing instance 52\n",
      "2020/01/24 17:28:58.918328 Parsing instance 53\n",
      "2020/01/24 17:28:58.933539 Parsing instance 54\n",
      "2020/01/24 17:28:59.011513 Parsing instance 55\n",
      "2020/01/24 17:28:59.192529 Parsing instance 56\n",
      "2020/01/24 17:28:59.276903 Parsing instance 57\n",
      "2020/01/24 17:28:59.577648 Parsing instance 58\n",
      "2020/01/24 17:28:59.623234 Parsing instance 59\n",
      "2020/01/24 17:28:59.760265 Parsing instance 60\n",
      "2020/01/24 17:28:59.884523 Parsing instance 61\n",
      "2020/01/24 17:28:59.914751 Parsing instance 62\n",
      "2020/01/24 17:28:59.950970 Parsing instance 63\n",
      "2020/01/24 17:29:00.002560 Parsing instance 64\n",
      "2020/01/24 17:29:00.096698 Parsing instance 65\n",
      "2020/01/24 17:29:00.203317 Parsing instance 66\n",
      "2020/01/24 17:29:00.302359 Parsing instance 67\n",
      "2020/01/24 17:29:00.352915 Parsing instance 68\n",
      "2020/01/24 17:29:00.656849 Parsing instance 69\n",
      "2020/01/24 17:29:00.775816 Parsing instance 70\n",
      "2020/01/24 17:29:00.832735 Parsing instance 71\n",
      "2020/01/24 17:29:00.911654 Parsing instance 72\n",
      "2020/01/24 17:29:00.959722 Parsing instance 73\n",
      "2020/01/24 17:29:01.063537 Parsing instance 74\n",
      "2020/01/24 17:29:01.131954 Parsing instance 75\n",
      "2020/01/24 17:29:01.283779 Parsing instance 76\n",
      "2020/01/24 17:29:01.406636 Parsing instance 77\n",
      "2020/01/24 17:29:01.458940 Parsing instance 78\n",
      "2020/01/24 17:29:01.502870 Parsing instance 79\n",
      "2020/01/24 17:29:01.793360 Parsing instance 80\n",
      "2020/01/24 17:29:01.902510 Parsing instance 81\n",
      "2020/01/24 17:29:02.000815 Parsing instance 82\n",
      "2020/01/24 17:29:02.077634 Parsing instance 83\n",
      "2020/01/24 17:29:02.188971 Parsing instance 84\n",
      "2020/01/24 17:29:02.275755 Parsing instance 85\n",
      "2020/01/24 17:29:02.368775 Parsing instance 86\n",
      "2020/01/24 17:29:02.505400 Parsing instance 87\n",
      "2020/01/24 17:29:02.611952 Parsing instance 88\n",
      "2020/01/24 17:29:02.910563 Parsing instance 89\n",
      "2020/01/24 17:29:03.062773 Parsing instance 90\n",
      "2020/01/24 17:29:03.165319 Parsing instance 91\n",
      "2020/01/24 17:29:03.232138 Parsing instance 92\n",
      "2020/01/24 17:29:03.293907 Parsing instance 93\n",
      "2020/01/24 17:29:03.319833 Parsing instance 94\n",
      "2020/01/24 17:29:03.544221 Parsing instance 95\n",
      "2020/01/24 17:29:03.664559 Parsing instance 96\n",
      "2020/01/24 17:29:03.856240 Parsing instance 97\n",
      "2020/01/24 17:29:04.074609 Parsing instance 98\n",
      "2020/01/24 17:29:04.106209 Parsing instance 99\n",
      "2020/01/24 17:29:04.215876 Parsing instance 100\n",
      "2020/01/24 17:29:04.274766 Parsing instance 101\n",
      "2020/01/24 17:29:04.401649 Parsing instance 102\n",
      "2020/01/24 17:29:04.607159 Parsing instance 103\n",
      "2020/01/24 17:29:04.661580 Parsing instance 104\n",
      "2020/01/24 17:29:04.781580 Parsing instance 105\n",
      "2020/01/24 17:29:04.862296 Parsing instance 106\n",
      "2020/01/24 17:29:05.151625 Parsing instance 107\n",
      "2020/01/24 17:29:05.258048 Parsing instance 108\n",
      "2020/01/24 17:29:05.366196 Parsing instance 109\n",
      "2020/01/24 17:29:05.434383 Parsing instance 110\n",
      "2020/01/24 17:29:05.495334 Parsing instance 111\n",
      "2020/01/24 17:29:05.539469 Parsing instance 112\n",
      "2020/01/24 17:29:05.580426 Parsing instance 113\n",
      "2020/01/24 17:29:05.712451 Parsing instance 114\n",
      "2020/01/24 17:29:05.790937 Parsing instance 115\n",
      "2020/01/24 17:29:06.231358 Parsing instance 116\n",
      "2020/01/24 17:29:06.376392 Parsing instance 117\n",
      "2020/01/24 17:29:06.438366 Parsing instance 118\n",
      "2020/01/24 17:29:06.600437 Parsing instance 119\n",
      "2020/01/24 17:29:06.669205 Parsing instance 120\n",
      "2020/01/24 17:29:06.679464 Parsing instance 121\n",
      "2020/01/24 17:29:06.761620 Parsing instance 122\n",
      "2020/01/24 17:29:06.951806 Parsing instance 123\n",
      "2020/01/24 17:29:07.088008 Parsing instance 124\n",
      "2020/01/24 17:29:07.524524 Parsing instance 125\n",
      "2020/01/24 17:29:07.580399 Parsing instance 126\n",
      "2020/01/24 17:29:07.607672 Parsing instance 127\n",
      "2020/01/24 17:29:07.711076 Parsing instance 128\n",
      "2020/01/24 17:29:07.855140 Parsing instance 129\n",
      "2020/01/24 17:29:07.980063 Parsing instance 130\n",
      "2020/01/24 17:29:08.092208 Parsing instance 131\n",
      "2020/01/24 17:29:08.511763 Parsing instance 132\n",
      "2020/01/24 17:29:08.698618 Parsing instance 133\n",
      "2020/01/24 17:29:08.729635 Parsing instance 134\n",
      "2020/01/24 17:29:08.895563 Parsing instance 135\n",
      "2020/01/24 17:29:08.958798 Parsing instance 136\n",
      "2020/01/24 17:29:09.044691 Parsing instance 137\n",
      "2020/01/24 17:29:09.056094 Parsing instance 138\n",
      "2020/01/24 17:29:09.153351 Parsing instance 139\n",
      "2020/01/24 17:29:09.163986 Parsing instance 140\n",
      "2020/01/24 17:29:09.232867 Parsing instance 141\n",
      "2020/01/24 17:29:09.700152 Parsing instance 142\n",
      "2020/01/24 17:29:09.880239 Parsing instance 143\n",
      "2020/01/24 17:29:09.965756 Parsing instance 144\n",
      "2020/01/24 17:29:10.041353 Parsing instance 145\n",
      "2020/01/24 17:29:10.138637 Parsing instance 146\n",
      "2020/01/24 17:29:10.158460 Parsing instance 147\n",
      "2020/01/24 17:29:10.541822 Parsing instance 148\n",
      "2020/01/24 17:29:10.688611 Parsing instance 149\n",
      "2020/01/24 17:29:10.775163 Parsing instance 150\n",
      "2020/01/24 17:29:10.843485 Parsing instance 151\n",
      "2020/01/24 17:29:10.995582 Parsing instance 152\n",
      "2020/01/24 17:29:11.124883 Parsing instance 153\n",
      "2020/01/24 17:29:11.228481 Parsing instance 154\n",
      "2020/01/24 17:29:11.696704 Parsing instance 155\n",
      "2020/01/24 17:29:11.757948 Parsing instance 156\n",
      "2020/01/24 17:29:11.935230 Parsing instance 157\n",
      "2020/01/24 17:29:11.980913 Parsing instance 158\n",
      "2020/01/24 17:29:12.068851 Parsing instance 159\n",
      "2020/01/24 17:29:12.088543 Parsing instance 160\n",
      "2020/01/24 17:29:12.300084 Parsing instance 161\n",
      "2020/01/24 17:29:12.381285 Parsing instance 162\n",
      "2020/01/24 17:29:12.895403 Parsing instance 163\n",
      "2020/01/24 17:29:12.977629 Parsing instance 164\n",
      "2020/01/24 17:29:13.000426 Parsing instance 165\n",
      "2020/01/24 17:29:13.057695 Parsing instance 166\n",
      "2020/01/24 17:29:13.228606 Parsing instance 167\n",
      "2020/01/24 17:29:13.307230 Parsing instance 168\n",
      "2020/01/24 17:29:13.357446 Parsing instance 169\n",
      "2020/01/24 17:29:13.427834 Parsing instance 170\n",
      "2020/01/24 17:29:13.543827 Parsing instance 171\n",
      "2020/01/24 17:29:13.605621 Parsing instance 172\n",
      "2020/01/24 17:29:13.768454 Parsing instance 173\n",
      "2020/01/24 17:29:13.951085 Parsing instance 174\n",
      "2020/01/24 17:29:14.027959 Parsing instance 175\n",
      "2020/01/24 17:29:14.055528 Parsing instance 176\n",
      "2020/01/24 17:29:14.082216 Parsing instance 177\n",
      "2020/01/24 17:29:14.107626 Parsing instance 178\n",
      "2020/01/24 17:29:14.189916 Parsing instance 179\n",
      "2020/01/24 17:29:14.214113 Parsing instance 180\n",
      "2020/01/24 17:29:14.261164 Parsing instance 181\n",
      "2020/01/24 17:29:14.279735 Parsing instance 182\n",
      "2020/01/24 17:29:14.296966 Parsing instance 183\n",
      "2020/01/24 17:29:14.466651 Parsing instance 184\n",
      "2020/01/24 17:29:14.564649 Parsing instance 185\n",
      "2020/01/24 17:29:14.610336 Parsing instance 186\n",
      "2020/01/24 17:29:14.675515 Parsing instance 187\n",
      "2020/01/24 17:29:14.805248 Parsing instance 188\n",
      "2020/01/24 17:29:14.912449 Parsing instance 189\n",
      "2020/01/24 17:29:15.054469 Parsing instance 190\n",
      "2020/01/24 17:29:15.084599 Parsing instance 191\n",
      "2020/01/24 17:29:15.089621 Parsing instance 192\n",
      "2020/01/24 17:29:15.091693 Parsing instance 193\n",
      "2020/01/24 17:29:15.118351 Parsing instance 194\n",
      "2020/01/24 17:29:15.256399 Parsing instance 195\n",
      "2020/01/24 17:29:15.286176 Parsing instance 196\n",
      "2020/01/24 17:29:15.355112 Parsing instance 197\n",
      "2020/01/24 17:29:15.368772 Parsing instance 198\n",
      "2020/01/24 17:29:15.500406 Parsing instance 199\n",
      "2020/01/24 17:29:15.558840 Parsing instance 200\n",
      "2020/01/24 17:29:15.742784 Parsing instance 201\n",
      "2020/01/24 17:29:15.757271 Parsing instance 202\n",
      "2020/01/24 17:29:15.829106 Parsing instance 203\n",
      "2020/01/24 17:29:15.854961 Parsing instance 204\n",
      "2020/01/24 17:29:15.898625 Parsing instance 205\n",
      "2020/01/24 17:29:15.999619 Parsing instance 206\n",
      "2020/01/24 17:29:16.368176 Parsing instance 207\n",
      "2020/01/24 17:29:16.512582 Parsing instance 208\n",
      "2020/01/24 17:29:16.608080 Parsing instance 209\n",
      "2020/01/24 17:29:16.702574 Parsing instance 210\n",
      "2020/01/24 17:29:16.744551 Parsing instance 211\n",
      "2020/01/24 17:29:16.892965 Parsing instance 212\n",
      "2020/01/24 17:29:17.000775 Parsing instance 213\n",
      "2020/01/24 17:29:17.043819 Parsing instance 214\n",
      "2020/01/24 17:29:17.285365 Parsing instance 215\n",
      "2020/01/24 17:29:17.611365 Parsing instance 216\n",
      "2020/01/24 17:29:17.652549 Parsing instance 217\n",
      "2020/01/24 17:29:17.702571 Parsing instance 218\n",
      "2020/01/24 17:29:17.760568 Parsing instance 219\n",
      "2020/01/24 17:29:17.811888 Parsing instance 220\n",
      "2020/01/24 17:29:17.828754 Parsing instance 221\n",
      "2020/01/24 17:29:17.987028 Parsing instance 222\n",
      "2020/01/24 17:29:18.049569 Parsing instance 223\n",
      "2020/01/24 17:29:18.155254 Parsing instance 224\n",
      "2020/01/24 17:29:18.505321 Parsing instance 225\n",
      "2020/01/24 17:29:18.589889 Parsing instance 226\n",
      "2020/01/24 17:29:18.700110 Parsing instance 227\n",
      "2020/01/24 17:29:18.842990 Parsing instance 228\n",
      "2020/01/24 17:29:18.868305 Parsing instance 229\n",
      "2020/01/24 17:29:18.981643 Parsing instance 230\n",
      "2020/01/24 17:29:19.057525 Parsing instance 231\n",
      "2020/01/24 17:29:19.115554 Parsing instance 232\n",
      "2020/01/24 17:29:19.137577 Parsing instance 233\n",
      "2020/01/24 17:29:19.158676 Parsing instance 234\n",
      "2020/01/24 17:29:19.210110 Parsing instance 235\n",
      "2020/01/24 17:29:19.271953 Parsing instance 236\n",
      "2020/01/24 17:29:19.465269 Parsing instance 237\n",
      "2020/01/24 17:29:19.629175 Parsing instance 238\n",
      "2020/01/24 17:29:19.685857 Parsing instance 239\n",
      "2020/01/24 17:29:19.725591 Parsing instance 240\n",
      "2020/01/24 17:29:19.737447 Parsing instance 241\n",
      "2020/01/24 17:29:19.768806 Parsing instance 242\n",
      "2020/01/24 17:29:19.823624 Parsing instance 243\n",
      "2020/01/24 17:29:19.876727 Parsing instance 244\n",
      "2020/01/24 17:29:19.905707 Parsing instance 245\n",
      "2020/01/24 17:29:20.016174 Parsing instance 246\n",
      "2020/01/24 17:29:20.085939 Parsing instance 247\n",
      "2020/01/24 17:29:20.123775 Parsing instance 248\n",
      "2020/01/24 17:29:20.208938 Parsing instance 249\n",
      "2020/01/24 17:29:20.254243 Parsing instance 250\n",
      "2020/01/24 17:29:20.262668 Parsing instance 251\n",
      "2020/01/24 17:29:20.304266 Parsing instance 252\n",
      "2020/01/24 17:29:20.354517 Parsing instance 253\n",
      "2020/01/24 17:29:20.376542 Parsing instance 254\n",
      "2020/01/24 17:29:20.449052 Parsing instance 255\n",
      "2020/01/24 17:29:20.702613 Parsing instance 256\n",
      "2020/01/24 17:29:20.789532 Parsing instance 257\n",
      "2020/01/24 17:29:20.883918 Parsing instance 258\n",
      "2020/01/24 17:29:20.901713 Parsing instance 259\n",
      "2020/01/24 17:29:20.958538 Parsing instance 260\n",
      "2020/01/24 17:29:21.042640 Parsing instance 261\n",
      "2020/01/24 17:29:21.086175 Parsing instance 262\n",
      "2020/01/24 17:29:21.160369 Parsing instance 263\n",
      "2020/01/24 17:29:21.203309 Parsing instance 264\n",
      "2020/01/24 17:29:21.274339 Parsing instance 265\n",
      "2020/01/24 17:29:21.358618 Parsing instance 266\n",
      "2020/01/24 17:29:21.569318 Parsing instance 267\n",
      "2020/01/24 17:29:21.997170 Parsing instance 268\n",
      "2020/01/24 17:29:22.202351 Parsing instance 269\n",
      "2020/01/24 17:29:22.246780 Parsing instance 270\n",
      "2020/01/24 17:29:22.313943 Parsing instance 271\n",
      "2020/01/24 17:29:22.343611 Parsing instance 272\n",
      "2020/01/24 17:29:22.431123 Parsing instance 273\n",
      "2020/01/24 17:29:22.486447 Parsing instance 274\n",
      "2020/01/24 17:29:22.536921 Parsing instance 275\n",
      "2020/01/24 17:29:22.565378 Parsing instance 276\n",
      "2020/01/24 17:29:22.586218 Parsing instance 277\n",
      "2020/01/24 17:29:22.637887 Parsing instance 278\n",
      "2020/01/24 17:29:22.707825 Parsing instance 279\n",
      "2020/01/24 17:29:23.005593 Parsing instance 280\n",
      "2020/01/24 17:29:23.088987 Parsing instance 281\n",
      "2020/01/24 17:29:23.156040 Parsing instance 282\n",
      "2020/01/24 17:29:23.196221 Parsing instance 283\n",
      "2020/01/24 17:29:23.310395 Parsing instance 284\n",
      "2020/01/24 17:29:23.368815 Parsing instance 285\n",
      "2020/01/24 17:29:23.421146 Parsing instance 286\n",
      "2020/01/24 17:29:23.468645 Parsing instance 287\n",
      "2020/01/24 17:29:23.529827 Parsing instance 288\n",
      "2020/01/24 17:29:23.624127 Parsing instance 289\n",
      "2020/01/24 17:29:23.667207 Parsing instance 290\n",
      "2020/01/24 17:29:23.742877 Parsing instance 291\n",
      "2020/01/24 17:29:23.819929 Parsing instance 292\n",
      "2020/01/24 17:29:24.228820 Parsing instance 293\n",
      "2020/01/24 17:29:24.414766 Parsing instance 294\n",
      "2020/01/24 17:29:24.440205 Parsing instance 295\n",
      "2020/01/24 17:29:24.498468 Parsing instance 296\n",
      "2020/01/24 17:29:24.555936 Parsing instance 297\n",
      "2020/01/24 17:29:24.585451 Parsing instance 298\n",
      "2020/01/24 17:29:24.669612 Parsing instance 299\n",
      "2020/01/24 17:29:24.744498 Parsing instance 300\n",
      "2020/01/24 17:29:24.772111 Parsing instance 301\n",
      "2020/01/24 17:29:24.909576 Parsing instance 302\n",
      "2020/01/24 17:29:24.972828 Parsing instance 303\n",
      "2020/01/24 17:29:25.265369 Parsing instance 304\n",
      "2020/01/24 17:29:25.366517 Parsing instance 305\n",
      "2020/01/24 17:29:25.436237 Parsing instance 306\n",
      "2020/01/24 17:29:25.471530 Parsing instance 307\n",
      "2020/01/24 17:29:25.520847 Parsing instance 308\n",
      "2020/01/24 17:29:25.551517 Parsing instance 309\n",
      "2020/01/24 17:29:25.654115 Parsing instance 310\n",
      "2020/01/24 17:29:25.686098 Parsing instance 311\n",
      "2020/01/24 17:29:25.697748 Parsing instance 312\n",
      "2020/01/24 17:29:25.758613 Parsing instance 313\n",
      "2020/01/24 17:29:25.772769 Parsing instance 314\n",
      "2020/01/24 17:29:25.850386 Parsing instance 315\n",
      "2020/01/24 17:29:25.852736 Parsing instance 316\n",
      "2020/01/24 17:29:25.886032 Parsing instance 317\n",
      "2020/01/24 17:29:26.002338 Parsing instance 318\n",
      "2020/01/24 17:29:26.385579 Parsing instance 319\n",
      "2020/01/24 17:29:26.458813 Parsing instance 320\n",
      "2020/01/24 17:29:26.567218 Parsing instance 321\n",
      "2020/01/24 17:29:26.633366 Parsing instance 322\n",
      "2020/01/24 17:29:26.667530 Parsing instance 323\n",
      "2020/01/24 17:29:26.827436 Parsing instance 324\n",
      "2020/01/24 17:29:27.012819 Parsing instance 325\n",
      "2020/01/24 17:29:27.126786 Parsing instance 326\n",
      "2020/01/24 17:29:27.589025 Parsing instance 327\n",
      "2020/01/24 17:29:27.766943 Parsing instance 328\n",
      "2020/01/24 17:29:27.814650 Parsing instance 329\n",
      "2020/01/24 17:29:27.998106 Parsing instance 330\n",
      "2020/01/24 17:29:28.026222 Parsing instance 331\n",
      "2020/01/24 17:29:28.073147 Parsing instance 332\n",
      "2020/01/24 17:29:28.191813 Parsing instance 333\n",
      "2020/01/24 17:29:28.640775 Parsing instance 334\n",
      "2020/01/24 17:29:28.662101 Parsing instance 335\n",
      "2020/01/24 17:29:28.760303 Parsing instance 336\n",
      "2020/01/24 17:29:28.840758 Parsing instance 337\n",
      "2020/01/24 17:29:28.892095 Parsing instance 338\n",
      "2020/01/24 17:29:28.919457 Parsing instance 339\n",
      "2020/01/24 17:29:28.977334 Parsing instance 340\n",
      "2020/01/24 17:29:29.005702 Parsing instance 341\n",
      "2020/01/24 17:29:29.040046 Parsing instance 342\n",
      "2020/01/24 17:29:29.230793 Parsing instance 343\n",
      "2020/01/24 17:29:29.311988 Parsing instance 344\n",
      "2020/01/24 17:29:29.329459 Parsing instance 345\n",
      "2020/01/24 17:29:29.357210 Parsing instance 346\n",
      "2020/01/24 17:29:29.442482 Parsing instance 347\n",
      "2020/01/24 17:29:29.468174 Parsing instance 348\n",
      "2020/01/24 17:29:29.500462 Parsing instance 349\n",
      "2020/01/24 17:29:29.515445 Parsing instance 350\n",
      "2020/01/24 17:29:29.818875 Parsing instance 351\n",
      "2020/01/24 17:29:29.873413 Parsing instance 352\n",
      "2020/01/24 17:29:29.953060 Parsing instance 353\n",
      "2020/01/24 17:29:29.974595 Parsing instance 354\n",
      "2020/01/24 17:29:29.997042 Parsing instance 355\n",
      "2020/01/24 17:29:30.014167 Parsing instance 356\n",
      "2020/01/24 17:29:30.031059 Parsing instance 357\n",
      "2020/01/24 17:29:30.119068 Parsing instance 358\n",
      "2020/01/24 17:29:30.221375 Parsing instance 359\n",
      "2020/01/24 17:29:30.331152 Parsing instance 360\n",
      "2020/01/24 17:29:30.486874 Parsing instance 361\n",
      "2020/01/24 17:29:30.543044 Parsing instance 362\n",
      "2020/01/24 17:29:30.593179 Parsing instance 363\n",
      "2020/01/24 17:29:30.843779 Parsing instance 364\n",
      "2020/01/24 17:29:31.029419 Parsing instance 365\n",
      "2020/01/24 17:29:31.089048 Parsing instance 366\n",
      "2020/01/24 17:29:31.125710 Parsing instance 367\n",
      "2020/01/24 17:29:31.154059 Parsing instance 368\n",
      "2020/01/24 17:29:31.253582 Parsing instance 369\n",
      "2020/01/24 17:29:31.416981 Parsing instance 370\n",
      "2020/01/24 17:29:31.486318 Parsing instance 371\n",
      "2020/01/24 17:29:31.555442 Parsing instance 372\n",
      "2020/01/24 17:29:31.594715 Parsing instance 373\n",
      "2020/01/24 17:29:31.701773 Parsing instance 374\n",
      "2020/01/24 17:29:31.832976 Parsing instance 375\n",
      "2020/01/24 17:29:32.084966 Parsing instance 376\n",
      "2020/01/24 17:29:32.255977 Parsing instance 377\n",
      "2020/01/24 17:29:32.364894 Parsing instance 378\n",
      "2020/01/24 17:29:32.475816 Parsing instance 379\n",
      "2020/01/24 17:29:32.832319 Parsing instance 380\n",
      "2020/01/24 17:29:33.365733 Parsing instance 381\n",
      "2020/01/24 17:29:33.429881 Parsing instance 382\n",
      "2020/01/24 17:29:33.580466 Parsing instance 383\n",
      "2020/01/24 17:29:33.670405 Parsing instance 384\n",
      "2020/01/24 17:29:33.834606 Parsing instance 385\n",
      "2020/01/24 17:29:33.909488 Parsing instance 386\n",
      "2020/01/24 17:29:34.481523 Parsing instance 387\n",
      "2020/01/24 17:29:34.607604 Parsing instance 388\n",
      "2020/01/24 17:29:35.112720 Parsing instance 389\n",
      "2020/01/24 17:29:35.420058 Parsing instance 390\n",
      "2020/01/24 17:29:35.592561 Parsing instance 391\n",
      "2020/01/24 17:29:35.692454 Parsing instance 392\n",
      "2020/01/24 17:29:35.868835 Parsing instance 393\n",
      "2020/01/24 17:29:35.982690 Parsing instance 394\n",
      "2020/01/24 17:29:36.042827 Parsing instance 395\n",
      "2020/01/24 17:29:36.177036 Parsing instance 396\n",
      "2020/01/24 17:29:36.687109 Parsing instance 397\n",
      "2020/01/24 17:29:36.706400 Parsing instance 398\n",
      "2020/01/24 17:29:36.783102 Parsing instance 399\n",
      "2020/01/24 17:29:36.904570 Parsing instance 400\n",
      "2020/01/24 17:29:36.931055 Parsing instance 401\n",
      "2020/01/24 17:29:37.061714 Parsing instance 402\n",
      "2020/01/24 17:29:37.199057 Parsing instance 403\n",
      "2020/01/24 17:29:37.239125 Parsing instance 404\n",
      "2020/01/24 17:29:37.327103 Parsing instance 405\n",
      "2020/01/24 17:29:37.447125 Parsing instance 406\n",
      "2020/01/24 17:29:37.628648 Parsing instance 407\n",
      "2020/01/24 17:29:37.837308 Parsing instance 408\n",
      "2020/01/24 17:29:37.956182 Parsing instance 409\n",
      "2020/01/24 17:29:38.053440 Parsing instance 410\n",
      "2020/01/24 17:29:38.131109 Parsing instance 411\n",
      "2020/01/24 17:29:38.339696 Parsing instance 412\n",
      "2020/01/24 17:29:38.406386 Parsing instance 413\n",
      "2020/01/24 17:29:38.458715 Parsing instance 414\n",
      "2020/01/24 17:29:38.670450 Parsing instance 415\n",
      "2020/01/24 17:29:38.777494 Parsing instance 416\n",
      "2020/01/24 17:29:38.845413 Parsing instance 417\n",
      "2020/01/24 17:29:38.954563 Parsing instance 418\n",
      "2020/01/24 17:29:39.012384 Parsing instance 419\n",
      "2020/01/24 17:29:39.038056 Parsing instance 420\n",
      "2020/01/24 17:29:39.075827 Parsing instance 421\n",
      "2020/01/24 17:29:39.223790 Parsing instance 422\n",
      "2020/01/24 17:29:39.251177 Parsing instance 423\n",
      "2020/01/24 17:29:39.415259 Parsing instance 424\n",
      "2020/01/24 17:29:39.493094 Parsing instance 425\n",
      "2020/01/24 17:29:39.539363 Parsing instance 426\n",
      "2020/01/24 17:29:39.634222 Parsing instance 427\n",
      "2020/01/24 17:29:39.947686 Parsing instance 428\n",
      "2020/01/24 17:29:40.041014 Parsing instance 429\n",
      "2020/01/24 17:29:40.172591 Parsing instance 430\n",
      "2020/01/24 17:29:40.207019 Parsing instance 431\n",
      "2020/01/24 17:29:40.238470 Parsing instance 432\n",
      "2020/01/24 17:29:40.302295 Parsing instance 433\n",
      "2020/01/24 17:29:40.372908 Parsing instance 434\n",
      "2020/01/24 17:29:40.408596 Parsing instance 435\n",
      "2020/01/24 17:29:40.542831 Parsing instance 436\n",
      "2020/01/24 17:29:40.715329 Parsing instance 437\n",
      "2020/01/24 17:29:40.761510 Parsing instance 438\n",
      "2020/01/24 17:29:40.857799 Parsing instance 439\n",
      "2020/01/24 17:29:41.124583 Parsing instance 440\n",
      "2020/01/24 17:29:41.229504 Parsing instance 441\n",
      "2020/01/24 17:29:41.352187 Parsing instance 442\n",
      "2020/01/24 17:29:41.702429 Parsing instance 443\n",
      "2020/01/24 17:29:41.883957 Parsing instance 444\n",
      "2020/01/24 17:29:41.964269 Parsing instance 445\n",
      "2020/01/24 17:29:42.323942 Parsing instance 446\n",
      "2020/01/24 17:29:42.527516 Parsing instance 447\n",
      "2020/01/24 17:29:42.600993 Parsing instance 448\n",
      "2020/01/24 17:29:42.700956 Parsing instance 449\n",
      "2020/01/24 17:29:42.722963 Parsing instance 450\n",
      "2020/01/24 17:29:42.858691 Parsing instance 451\n",
      "2020/01/24 17:29:42.970197 Parsing instance 452\n",
      "2020/01/24 17:29:43.007812 Parsing instance 453\n",
      "2020/01/24 17:29:43.115870 Parsing instance 454\n",
      "2020/01/24 17:29:43.504813 Parsing instance 455\n",
      "2020/01/24 17:29:43.671846 Parsing instance 456\n",
      "2020/01/24 17:29:43.841060 Parsing instance 457\n",
      "2020/01/24 17:29:43.907744 Parsing instance 458\n",
      "2020/01/24 17:29:44.008036 Parsing instance 459\n",
      "2020/01/24 17:29:44.063328 Parsing instance 460\n",
      "2020/01/24 17:29:44.178376 Parsing instance 461\n",
      "2020/01/24 17:29:44.320043 Parsing instance 462\n",
      "2020/01/24 17:29:44.847606 Parsing instance 463\n",
      "2020/01/24 17:29:45.099553 Parsing instance 464\n",
      "2020/01/24 17:29:45.179934 Parsing instance 465\n",
      "2020/01/24 17:29:45.703203 Parsing instance 466\n",
      "2020/01/24 17:29:45.764421 Parsing instance 467\n",
      "2020/01/24 17:29:45.970165 Parsing instance 468\n",
      "2020/01/24 17:29:46.124213 Parsing instance 469\n",
      "2020/01/24 17:29:46.221957 Parsing instance 470\n",
      "2020/01/24 17:29:46.248468 Parsing instance 471\n",
      "2020/01/24 17:29:46.611449 Parsing instance 472\n",
      "2020/01/24 17:29:46.891321 Parsing instance 473\n",
      "2020/01/24 17:29:47.036550 Parsing instance 474\n",
      "2020/01/24 17:29:47.234082 Parsing instance 475\n",
      "2020/01/24 17:29:47.484373 Parsing instance 476\n",
      "2020/01/24 17:29:47.542797 Parsing instance 477\n",
      "2020/01/24 17:29:47.909915 Parsing instance 478\n",
      "2020/01/24 17:29:47.990154 Parsing instance 479\n",
      "2020/01/24 17:29:48.106406 Parsing instance 480\n",
      "2020/01/24 17:29:48.335913 Parsing instance 481\n",
      "2020/01/24 17:29:48.390825 Parsing instance 482\n",
      "2020/01/24 17:29:48.546384 Parsing instance 483\n",
      "2020/01/24 17:29:48.884023 Parsing instance 484\n",
      "2020/01/24 17:29:49.043376 Parsing instance 485\n",
      "2020/01/24 17:29:49.104487 Parsing instance 486\n",
      "2020/01/24 17:29:49.204751 Parsing instance 487\n",
      "2020/01/24 17:29:49.271825 Parsing instance 488\n",
      "2020/01/24 17:29:49.368385 Parsing instance 489\n",
      "2020/01/24 17:29:49.401387 Parsing instance 490\n",
      "2020/01/24 17:29:49.483518 Parsing instance 491\n",
      "2020/01/24 17:29:49.596091 Parsing instance 492\n",
      "2020/01/24 17:29:49.705667 Parsing instance 493\n",
      "2020/01/24 17:29:49.814270 Parsing instance 494\n",
      "2020/01/24 17:29:49.889720 Parsing instance 495\n",
      "2020/01/24 17:29:50.244390 Parsing instance 496\n",
      "2020/01/24 17:29:50.361193 Parsing instance 497\n",
      "2020/01/24 17:29:50.542207 Parsing instance 498\n",
      "2020/01/24 17:29:50.595821 Parsing instance 499\n",
      "2020/01/24 17:29:50.666020 Parsing instance 500\n",
      "2020/01/24 17:29:50.736175 Parsing instance 501\n",
      "2020/01/24 17:29:50.855976 Parsing instance 502\n",
      "2020/01/24 17:29:50.978556 Parsing instance 503\n",
      "2020/01/24 17:29:51.129172 Parsing instance 504\n",
      "2020/01/24 17:29:51.405386 Parsing instance 505\n",
      "2020/01/24 17:29:51.553505 Parsing instance 506\n",
      "2020/01/24 17:29:51.650694 Parsing instance 507\n",
      "2020/01/24 17:29:51.721343 Parsing instance 508\n",
      "2020/01/24 17:29:51.798194 Parsing instance 509\n",
      "2020/01/24 17:29:51.842871 Parsing instance 510\n",
      "2020/01/24 17:29:51.894686 Parsing instance 511\n",
      "2020/01/24 17:29:51.934199 Parsing instance 512\n",
      "2020/01/24 17:29:52.059588 Parsing instance 513\n",
      "2020/01/24 17:29:52.094054 Parsing instance 514\n",
      "2020/01/24 17:29:52.206873 Parsing instance 515\n",
      "2020/01/24 17:29:52.224991 Parsing instance 516\n",
      "2020/01/24 17:29:52.274123 Parsing instance 517\n",
      "2020/01/24 17:29:52.664783 Parsing instance 518\n",
      "2020/01/24 17:29:52.806746 Parsing instance 519\n",
      "2020/01/24 17:29:52.858269 Parsing instance 520\n",
      "2020/01/24 17:29:52.911872 Parsing instance 521\n",
      "2020/01/24 17:29:52.939278 Parsing instance 522\n",
      "2020/01/24 17:29:52.978479 Parsing instance 523\n",
      "2020/01/24 17:29:53.114408 Parsing instance 524\n",
      "2020/01/24 17:29:53.718263 Parsing instance 525\n",
      "2020/01/24 17:29:53.805858 Parsing instance 526\n",
      "2020/01/24 17:29:53.891993 Parsing instance 527\n",
      "2020/01/24 17:29:54.034706 Parsing instance 528\n",
      "2020/01/24 17:29:54.129357 Parsing instance 529\n",
      "2020/01/24 17:29:54.287047 Parsing instance 530\n",
      "2020/01/24 17:29:54.327278 Parsing instance 531\n",
      "2020/01/24 17:29:54.388178 Parsing instance 532\n",
      "2020/01/24 17:29:54.431977 Parsing instance 533\n",
      "2020/01/24 17:29:54.505712 Parsing instance 534\n",
      "2020/01/24 17:29:54.530426 Parsing instance 535\n",
      "2020/01/24 17:29:54.636110 Parsing instance 536\n",
      "2020/01/24 17:29:54.675970 Parsing instance 537\n",
      "2020/01/24 17:29:55.000980 Parsing instance 538\n",
      "2020/01/24 17:29:55.340542 Parsing instance 539\n",
      "2020/01/24 17:29:55.640966 Parsing instance 540\n",
      "2020/01/24 17:29:56.079245 Parsing instance 541\n",
      "2020/01/24 17:29:56.445339 Parsing instance 542\n",
      "2020/01/24 17:29:56.626206 Parsing instance 543\n",
      "2020/01/24 17:29:56.736731 Parsing instance 544\n",
      "2020/01/24 17:29:56.793707 Parsing instance 545\n",
      "2020/01/24 17:29:57.197530 Parsing instance 546\n",
      "2020/01/24 17:29:57.354165 Parsing instance 547\n",
      "2020/01/24 17:29:57.468698 Parsing instance 548\n",
      "2020/01/24 17:29:57.523488 Parsing instance 549\n",
      "2020/01/24 17:29:57.579288 Parsing instance 550\n",
      "2020/01/24 17:29:57.654595 Parsing instance 551\n",
      "2020/01/24 17:29:57.742486 Parsing instance 552\n",
      "2020/01/24 17:29:57.846818 Parsing instance 553\n",
      "2020/01/24 17:29:57.905164 Parsing instance 554\n",
      "2020/01/24 17:29:58.005567 Parsing instance 555\n",
      "2020/01/24 17:29:58.147441 Parsing instance 556\n",
      "2020/01/24 17:29:58.573345 Parsing instance 557\n",
      "2020/01/24 17:29:58.690624 Parsing instance 558\n",
      "2020/01/24 17:29:58.984313 Parsing instance 559\n",
      "2020/01/24 17:29:59.068302 Parsing instance 560\n",
      "2020/01/24 17:29:59.136806 Parsing instance 561\n",
      "2020/01/24 17:29:59.168856 Parsing instance 562\n",
      "2020/01/24 17:29:59.874846 Parsing instance 563\n",
      "2020/01/24 17:29:59.912092 Parsing instance 564\n",
      "2020/01/24 17:29:59.979747 Parsing instance 565\n",
      "2020/01/24 17:30:00.017878 Parsing instance 566\n",
      "2020/01/24 17:30:00.050282 Parsing instance 567\n",
      "2020/01/24 17:30:00.260803 Parsing instance 568\n",
      "2020/01/24 17:30:00.316566 Parsing instance 569\n",
      "2020/01/24 17:30:00.384020 Parsing instance 570\n",
      "2020/01/24 17:30:00.850619 Parsing instance 571\n",
      "2020/01/24 17:30:01.145230 Parsing instance 572\n",
      "2020/01/24 17:30:01.160055 Parsing instance 573\n",
      "2020/01/24 17:30:01.245413 Parsing instance 574\n",
      "2020/01/24 17:30:01.330921 Parsing instance 575\n",
      "2020/01/24 17:30:01.478530 Parsing instance 576\n",
      "2020/01/24 17:30:01.984904 Parsing instance 577\n",
      "2020/01/24 17:30:02.089349 Parsing instance 578\n",
      "2020/01/24 17:30:02.159329 Parsing instance 579\n",
      "2020/01/24 17:30:02.366298 Parsing instance 580\n",
      "2020/01/24 17:30:02.391685 Parsing instance 581\n",
      "2020/01/24 17:30:02.490268 Parsing instance 582\n",
      "2020/01/24 17:30:02.583692 Parsing instance 583\n",
      "2020/01/24 17:30:02.711375 Parsing instance 584\n",
      "2020/01/24 17:30:02.837708 Parsing instance 585\n",
      "2020/01/24 17:30:02.883754 Parsing instance 586\n",
      "2020/01/24 17:30:03.267042 Parsing instance 587\n",
      "2020/01/24 17:30:03.432003 Parsing instance 588\n",
      "2020/01/24 17:30:03.586546 Parsing instance 589\n",
      "2020/01/24 17:30:03.644275 Parsing instance 590\n",
      "2020/01/24 17:30:03.782424 Parsing instance 591\n",
      "2020/01/24 17:30:03.790552 Parsing instance 592\n",
      "2020/01/24 17:30:03.869128 Parsing instance 593\n",
      "2020/01/24 17:30:04.093886 Parsing instance 594\n",
      "2020/01/24 17:30:04.405395 Parsing instance 595\n",
      "2020/01/24 17:30:04.551300 Parsing instance 596\n",
      "2020/01/24 17:30:04.607431 Parsing instance 597\n",
      "2020/01/24 17:30:04.626317 Parsing instance 598\n",
      "2020/01/24 17:30:04.809007 Parsing instance 599\n",
      "2020/01/24 17:30:04.916917 Parsing instance 600\n",
      "2020/01/24 17:30:05.043386 Parsing instance 601\n",
      "2020/01/24 17:30:05.128236 Parsing instance 602\n",
      "2020/01/24 17:30:05.517455 Parsing instance 603\n",
      "2020/01/24 17:30:05.583171 Parsing instance 604\n",
      "2020/01/24 17:30:05.677423 Parsing instance 605\n",
      "2020/01/24 17:30:05.764518 Parsing instance 606\n",
      "2020/01/24 17:30:05.785801 Parsing instance 607\n",
      "2020/01/24 17:30:05.939675 Parsing instance 608\n",
      "2020/01/24 17:30:05.984100 Parsing instance 609\n",
      "2020/01/24 17:30:06.030614 Parsing instance 610\n",
      "2020/01/24 17:30:06.153589 Parsing instance 611\n",
      "2020/01/24 17:30:06.253464 Parsing instance 612\n",
      "2020/01/24 17:30:06.363125 Parsing instance 613\n",
      "2020/01/24 17:30:06.642366 Parsing instance 614\n",
      "2020/01/24 17:30:06.912660 Parsing instance 615\n",
      "2020/01/24 17:30:07.077604 Parsing instance 616\n",
      "2020/01/24 17:30:07.163938 Parsing instance 617\n",
      "2020/01/24 17:30:07.253882 Parsing instance 618\n",
      "2020/01/24 17:30:07.283107 Parsing instance 619\n",
      "2020/01/24 17:30:07.385024 Parsing instance 620\n",
      "2020/01/24 17:30:07.431277 Parsing instance 621\n",
      "2020/01/24 17:30:07.599101 Parsing instance 622\n",
      "2020/01/24 17:30:07.891069 Parsing instance 623\n",
      "2020/01/24 17:30:07.938742 Parsing instance 624\n",
      "2020/01/24 17:30:08.029351 Parsing instance 625\n",
      "2020/01/24 17:30:08.066147 Parsing instance 626\n",
      "2020/01/24 17:30:08.126901 Parsing instance 627\n",
      "2020/01/24 17:30:08.199173 Parsing instance 628\n",
      "2020/01/24 17:30:08.252183 Parsing instance 629\n",
      "2020/01/24 17:30:08.360353 Parsing instance 630\n",
      "2020/01/24 17:30:08.513798 Parsing instance 631\n",
      "2020/01/24 17:30:08.527547 Parsing instance 632\n",
      "2020/01/24 17:30:08.633490 Parsing instance 633\n",
      "2020/01/24 17:30:08.706794 Parsing instance 634\n",
      "2020/01/24 17:30:09.083640 Parsing instance 635\n",
      "2020/01/24 17:30:09.137379 Parsing instance 636\n",
      "2020/01/24 17:30:09.390866 Parsing instance 637\n",
      "2020/01/24 17:30:09.422270 Parsing instance 638\n",
      "2020/01/24 17:30:09.509955 Parsing instance 639\n",
      "2020/01/24 17:30:09.536109 Parsing instance 640\n",
      "2020/01/24 17:30:09.592056 Parsing instance 641\n",
      "2020/01/24 17:30:09.720482 Parsing instance 642\n",
      "2020/01/24 17:30:09.794306 Parsing instance 643\n",
      "2020/01/24 17:30:09.960980 Parsing instance 644\n",
      "2020/01/24 17:30:10.016065 Parsing instance 645\n",
      "2020/01/24 17:30:10.326037 Parsing instance 646\n",
      "2020/01/24 17:30:10.422735 Parsing instance 647\n",
      "2020/01/24 17:30:10.469043 Parsing instance 648\n",
      "2020/01/24 17:30:10.586708 Parsing instance 649\n",
      "2020/01/24 17:30:10.763660 Parsing instance 650\n",
      "2020/01/24 17:30:10.771472 Parsing instance 651\n",
      "2020/01/24 17:30:10.900795 Parsing instance 652\n",
      "2020/01/24 17:30:11.015610 Parsing instance 653\n",
      "2020/01/24 17:30:11.140330 Parsing instance 654\n",
      "2020/01/24 17:30:11.171403 Parsing instance 655\n",
      "2020/01/24 17:30:11.444127 Parsing instance 656\n",
      "2020/01/24 17:30:11.567427 Parsing instance 657\n",
      "2020/01/24 17:30:11.663415 Parsing instance 658\n",
      "2020/01/24 17:30:11.754059 Parsing instance 659\n",
      "2020/01/24 17:30:11.831764 Parsing instance 660\n",
      "2020/01/24 17:30:11.978052 Parsing instance 661\n",
      "2020/01/24 17:30:12.088810 Parsing instance 662\n",
      "2020/01/24 17:30:12.158933 Parsing instance 663\n",
      "2020/01/24 17:30:12.600515 Parsing instance 664\n",
      "2020/01/24 17:30:12.792789 Parsing instance 665\n",
      "2020/01/24 17:30:12.849335 Parsing instance 666\n",
      "2020/01/24 17:30:12.952479 Parsing instance 667\n",
      "2020/01/24 17:30:13.046190 Parsing instance 668\n",
      "2020/01/24 17:30:13.140295 Parsing instance 669\n",
      "2020/01/24 17:30:13.180738 Parsing instance 670\n",
      "2020/01/24 17:30:13.255273 Parsing instance 671\n",
      "2020/01/24 17:30:13.353086 Parsing instance 672\n",
      "2020/01/24 17:30:13.439964 Parsing instance 673\n",
      "2020/01/24 17:30:13.472542 Parsing instance 674\n",
      "2020/01/24 17:30:13.524561 Parsing instance 675\n",
      "2020/01/24 17:30:13.574138 Parsing instance 676\n",
      "2020/01/24 17:30:13.771535 Parsing instance 677\n",
      "2020/01/24 17:30:13.960492 Parsing instance 678\n",
      "2020/01/24 17:30:13.990906 Parsing instance 679\n",
      "2020/01/24 17:30:14.070177 Parsing instance 680\n",
      "2020/01/24 17:30:14.109311 Parsing instance 681\n",
      "2020/01/24 17:30:14.202419 Parsing instance 682\n",
      "2020/01/24 17:30:14.337702 Parsing instance 683\n",
      "2020/01/24 17:30:14.387002 Parsing instance 684\n",
      "2020/01/24 17:30:14.434674 Parsing instance 685\n",
      "2020/01/24 17:30:14.535190 Parsing instance 686\n",
      "2020/01/24 17:30:14.558931 Parsing instance 687\n",
      "2020/01/24 17:30:14.647744 Parsing instance 688\n",
      "2020/01/24 17:30:15.055761 Parsing instance 689\n",
      "2020/01/24 17:30:15.173176 Parsing instance 690\n",
      "2020/01/24 17:30:15.277265 Parsing instance 691\n",
      "2020/01/24 17:30:15.344982 Parsing instance 692\n",
      "2020/01/24 17:30:15.421487 Parsing instance 693\n",
      "2020/01/24 17:30:15.487854 Parsing instance 694\n",
      "2020/01/24 17:30:15.645234 Parsing instance 695\n",
      "2020/01/24 17:30:15.731029 Parsing instance 696\n",
      "2020/01/24 17:30:16.117068 Parsing instance 697\n",
      "2020/01/24 17:30:16.296995 Parsing instance 698\n",
      "2020/01/24 17:30:16.381923 Parsing instance 699\n",
      "2020/01/24 17:30:16.548821 Parsing instance 700\n",
      "2020/01/24 17:30:16.641347 Parsing instance 701\n",
      "2020/01/24 17:30:16.746761 Parsing instance 702\n",
      "2020/01/24 17:30:16.857859 Parsing instance 703\n",
      "2020/01/24 17:30:16.877101 Parsing instance 704\n",
      "2020/01/24 17:30:16.936055 Parsing instance 705\n",
      "2020/01/24 17:30:16.964593 PARSE Total Time: 1m23.996712969s\n",
      "2020/01/24 17:30:16.964625 Converting 706 to conll\n",
      "2020/01/24 17:30:16.964632 Writing to output file\n",
      "2020/01/24 17:30:17.033121 Wrote 706 in conll format to final_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.conll\n",
      "2020/01/24 17:30:17.033172 Writing to segmentation file\n",
      "2020/01/24 17:30:17.104914 Wrote 706 in segmentation format to final_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.seg\n",
      "2020/01/24 17:30:17.104927 Writing to mapping file\n",
      "2020/01/24 17:30:17.489422 Wrote 706 in mapping format to final_setup/ooo_pruned/yap_output/test.multitok.char_lstm.ft_oov_tok.52_seed.map\n",
      "2020/01/24 17:30:17.489437 Writing to gold segmentation file\n"
     ]
    }
   ],
   "source": [
    "for file in os.scandir(pruned_folder):\n",
    "    #ds, unit, arch, w_embed, seed_num, _\n",
    "    base_out = '.'.join(file.name.split('.')[:-1])\n",
    "    seg_out, map_out, conll_out = [os.path.join(yap_output_folder, base_out+suf)\n",
    "                                   for suf in ['.seg', '.map', '.conll']]\n",
    "    if not os.path.exists(seg_out):\n",
    "        !{yap_path} joint -in {file.path} -os {seg_out} -om {map_out} -oc {conll_out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input files for NCRF\n",
    "with dummy O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "txt_folder = 'final_setup/ooo_pruned/txt'\n",
    "txt_map = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.scandir(yap_output_folder):\n",
    "    if file.name.endswith('conll') and file.name!='.conll':\n",
    "        ds, unit, arch, w_embed, seed_num, _ = file.name.split('.')\n",
    "        out_name = '.'.join(file.name.split('.')[:-1])+'.txt'\n",
    "        out_path = os.path.join(txt_folder, out_name)\n",
    "        if '_tok' in w_embed:\n",
    "            w_embed = w_embed.replace('_tok', '_yap')\n",
    "        else:\n",
    "            w_embed = w_embed.replace('_yap', '_tok')\n",
    "        txt_map[(arch, w_embed)].append((ds, out_path))\n",
    "        with open(out_path, 'w') as of:\n",
    "            for line in open(file.path, 'r'):\n",
    "                if line=='\\n':\n",
    "                    of.write('\\n')\n",
    "                else:\n",
    "                    w = line.split('\\t')[1]\n",
    "                    of.write(w+' O\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.scandir(yap_output_folder):\n",
    "    if file.name.endswith('conll') and file.name!='.conll':\n",
    "        ds, unit, arch, w_embed, seed_num, _ = file.name.split('.')\n",
    "        out_name = '.'.join(file.name.split('.')[:-1])+'.txt'\n",
    "        out_path = os.path.join(txt_folder, out_name)\n",
    "        if '_tok' in w_embed:\n",
    "            w_embed = w_embed.replace('_tok', '_yap')\n",
    "        else:\n",
    "            w_embed = w_embed.replace('_yap', '_tok')\n",
    "        txt_map[(arch, w_embed)].append((ds, out_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs for NCRF decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'final_setup/ooo_decode_output'\n",
    "decode_conf_folder = 'final_setup/ooo_decode_conf'\n",
    "\n",
    "params = { 'status': 'decode' }\n",
    "\n",
    "erdf = pd.read_pickle('final_setup/ooo_erdf.pkl')\n",
    "\n",
    "for i, row in erdf[(erdf.unit=='morph')].iterrows():\n",
    "    unit = row['unit']\n",
    "    for ds, set_path in txt_map[(row.arch, row.w_embed)]:\n",
    "        name = 'morph_'+ds+'_pruned'\n",
    "        row_par = params.copy()\n",
    "        row_par['load_model_dir'] = os.path.join(models_folder, row['model_file_name'])\n",
    "        row_par['dset_dir'] = os.path.join(models_folder, row['dset_file_name'])\n",
    "        row_par['decode_dir'] = os.path.join(output_folder, name+'.'+row['model_base_name']+'.bmes')\n",
    "        row_par['raw_dir'] = set_path\n",
    "        \n",
    "        conf_path = os.path.join(decode_conf_folder, name+'.'+row['model_base_name']+'.decode.conf')\n",
    "        if not os.path.exists(conf_path):\n",
    "            with open(conf_path, 'w', encoding='utf8') as of:\n",
    "                for k, v in row_par.items():\n",
    "                    of.write(k+'='+str(v)+'\\n')        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate segmentation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = spdf[spdf.set=='dev']\n",
    "test_gold = spdf[spdf.set=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "      .size().reset_index().rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "dg['ner'] = tempn\n",
    "tg = (test_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index()\n",
    "      .rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (test_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "tg['ner'] = tempn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>w_embed</th>\n",
       "      <th>model_base_name</th>\n",
       "      <th>pred_set</th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.45_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.973626</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.974679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.45_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.964048</td>\n",
       "      <td>0.974274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.50_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.973860</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.974808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.50_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.960719</td>\n",
       "      <td>0.974633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov_tok</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.44_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.973274</td>\n",
       "      <td>0.960241</td>\n",
       "      <td>0.974679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        arch     w_embed                        model_base_name pred_set  \\\n",
       "0  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.45_seed      dev   \n",
       "1  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.45_seed     test   \n",
       "2  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.50_seed      dev   \n",
       "3  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.50_seed     test   \n",
       "4  char_lstm  ft_oov_tok  multitok.char_lstm.ft_oov_tok.44_seed      dev   \n",
       "\n",
       "        all       ner       non  \n",
       "0  0.973626  0.963855  0.974679  \n",
       "1  0.973057  0.964048  0.974274  \n",
       "2  0.973860  0.965060  0.974808  \n",
       "3  0.972977  0.960719  0.974633  \n",
       "4  0.973274  0.960241  0.974679  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for i, row in erdf[erdf.unit=='multitok'].iterrows():\n",
    "    dev_path = os.path.join(output_folder, \n",
    "                            'token_dev.'+row.model_base_name+'.bmes')\n",
    "    dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'dev'}\n",
    "    sc['all'] = accuracy_score(dev_bc.biose_count, dg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(dev_bc[dg.ner].biose_count, dg[dg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(dev_bc[~dg.ner].biose_count, dg[~dg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    test_path = os.path.join(output_folder, \n",
    "                             'token_test.'+row.model_base_name+'.bmes')\n",
    "    test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'test'}\n",
    "    sc['all'] = accuracy_score(test_bc.biose_count, tg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(test_bc[tg.ner].biose_count, tg[tg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(test_bc[~tg.ner].biose_count, tg[~tg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    \n",
    "acc_scores = pd.DataFrame(acc_scores)\n",
    "acc_scores.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_scores.to_pickle('final_setup/ooo_acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = pd.read_pickle('final_setup/ooo_acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">char_lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_set</th>\n",
       "      <th>w_embed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.35</td>\n",
       "      <td>96.41</td>\n",
       "      <td>97.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.30</td>\n",
       "      <td>96.43</td>\n",
       "      <td>97.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "arch                char_lstm              \n",
       "                          all    ner    non\n",
       "pred_set w_embed                           \n",
       "dev      ft_oov_tok     97.35  96.41  97.45\n",
       "test     ft_oov_tok     97.30  96.43  97.41"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = acc_scores.groupby(['pred_set','w_embed', 'arch']).mean().mul(100).round(2).unstack()\n",
    "x.columns = x.columns.reorder_levels([1,0])\n",
    "x.sort_index(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, dg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313253012048193"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[dg.ner].morpheme_count, dg[dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628619659784443"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~dg.ner].morpheme_count, dg[~dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bclm.get_token_df(bclm.read_yap_output(treebank_set='test'), fields=['upostag'])\n",
    "yt['morpheme_count'] = yt.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547507726444251"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt.morpheme_count, tg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961384820239681"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[tg.ner].morpheme_count, tg[tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626697850139426"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[~tg.ner].morpheme_count, tg[~tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_out_non_o_keep = bclm.read_yap_output(treebank_set=None, tokens_path=bclm.TREEBANK_TOKEN_PATHS['dev'], \n",
    "                                     dep_path='final_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.conll',\n",
    "                                     map_path='final_setup/ooo_pruned/yap_output/dev.multitok.char_lstm.ft_oov_tok.52_seed.map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = bclm.read_dataframe('spmrl', subset='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_dev_regular = bclm.read_yap_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10445 correct.\n",
      "Precision: 91.41\n",
      "Recall:    92.43\n",
      "F1:        91.92\n",
      "FP ex.: [(1, 5, 'לישראל', 'NNP'), (1, 8, 'ה', 'DEF'), (2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN')]\n",
      "FN ex.: [(1, 5, 'ישראל', 'NNP'), (1, 5, 'ל', 'PREPOSITION'), (2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.41431822159986, 92.42544907530306, 91.91710300523606)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11292 predicted, 10517 correct.\n",
      "Precision: 93.14\n",
      "Recall:    93.06\n",
      "F1:        93.1\n",
      "FP ex.: [(2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN'), (4, 1, 'מצד', 'IN'), (5, 13, 'ה', 'DEF')]\n",
      "FN ex.: [(2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN'), (4, 1, 'מ', 'PREPOSITION'), (4, 1, 'צד', 'NN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.13673397095289, 93.0625608353243, 93.09963262957554)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'upostag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10541 correct.\n",
      "Precision: 92.25\n",
      "Recall:    93.27\n",
      "F1:        92.76\n",
      "FP ex.: [(1, 8, 'DEF'), (2, 11, 'BN'), (3, 4, 'NNT'), (4, 19, 'NN'), (5, 9, 'DEF')]\n",
      "FN ex.: [(1, 5, 'PREPOSITION'), (2, 11, 'VB'), (3, 4, 'NN'), (4, 19, 'RB'), (5, 9, 'NNT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.25450726413443, 93.27493142199805, 92.76191314295771)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11292 predicted, 10603 correct.\n",
      "Precision: 93.9\n",
      "Recall:    93.82\n",
      "F1:        93.86\n",
      "FP ex.: [(2, 11, 'BN'), (3, 4, 'NNT'), (4, 1, 'IN'), (5, 13, 'DEF'), (6, 24, 'REL')]\n",
      "FN ex.: [(2, 11, 'VB'), (3, 4, 'NN'), (4, 1, 'NN'), (4, 1, 'PREPOSITION'), (6, 24, 'DEF')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.89833510449876, 93.8235554375719, 93.86093037666534)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No POS, Segmentation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10923 correct.\n",
      "Precision: 95.6\n",
      "Recall:    96.66\n",
      "F1:        96.12\n",
      "FP ex.: [(1, 5, 'לישראל'), (1, 8, 'ה'), (3, 28, 'הם'), (5, 9, 'ה'), (5, 22, 'ה')]\n",
      "FN ex.: [(1, 5, 'ישראל'), (1, 5, 'ל'), (3, 28, 'המ'), (6, 25, 'ב'), (6, 25, 'מקום')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.59775949588658, 96.65516325988851, 96.1235534826418)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11292 predicted, 11022 correct.\n",
      "Precision: 97.61\n",
      "Recall:    97.53\n",
      "F1:        97.57\n",
      "FP ex.: [(3, 28, 'הם'), (4, 1, 'מצד'), (5, 13, 'ה'), (8, 9, 'ה'), (8, 17, 'ה')]\n",
      "FN ex.: [(3, 28, 'המ'), (4, 1, 'מ'), (4, 1, 'צד'), (8, 17, 'הפעילה'), (15, 5, 'מפם')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97.60892667375133, 97.53119192991771, 97.57004381888196)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evluate Token Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/bclm/evaluations.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gold_df['upostag'] = gold_df.upostag.str.replace('_','-')\n",
      "/home/nlp/danb/bclm/evaluations.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['upostag'] = pred_df.upostag.str.replace('_','-')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.39245106083693, 92.66107920134412, 92.47467220389504)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.84276950728714, 93.06548665650764, 92.90810545294192)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.27550502090416, 93.33313796741297, 93.27243498501264)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.07232446372053, 93.42691360919001, 93.13696267394545)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.40346969874575, 93.73754542257649, 93.47466662201161)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.8264369163443, 93.94463329816746, 93.82024102572689)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Segment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = dev_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index().rename(columns={0: 'morpheme_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str  morpheme_count\n",
       "0        1         1     עשרות               1\n",
       "1        1         2     אנשים               1\n",
       "2        1         3    מגיעים               1\n",
       "3        1         4   מתאילנד               2\n",
       "4        1         5    לישראל               2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8531, 8531)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ps), len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974328918063533"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ps.biose_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835616438356164"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[(ps.biose.str.contains('-'))].biose_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734649403922574"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[~(ps.biose.str.contains('-'))].biose_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6078\n",
       "2    2143\n",
       "3     303\n",
       "4       7\n",
       "Name: morpheme_count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.morpheme_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6056\n",
       "2    2156\n",
       "3     316\n",
       "4       3\n",
       "Name: biose_count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.biose_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>במלחמת</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>שכונת</td>\n",
       "      <td>O^B-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>I-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>לנקובסקי</td>\n",
       "      <td>O^S-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>229</td>\n",
       "      <td>8</td>\n",
       "      <td>שקריסטול</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>O^B-GPE^E-GPE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>לאקספרס</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>בלין</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id token_str          biose  biose_count\n",
       "633        30         1    במלחמת  O^B-LOC^I-LOC            3\n",
       "641        30         9     שכונת        O^B-LOC            2\n",
       "2075      103        16    הארקין    B-ORG^E-ORG            2\n",
       "2212      110         6    הארקין    B-ORG^E-ORG            2\n",
       "4133      225        13     הדסון    I-ORG^E-ORG            2\n",
       "4180      227         6  לנקובסקי        O^S-PER            2\n",
       "4232      229         8  שקריסטול          S-PER            1\n",
       "4478      239        26     באיסט        O^B-GPE            2\n",
       "6254      337         1      בארץ  O^B-GPE^E-GPE            3\n",
       "6573      356        11       בשן          S-PER            1\n",
       "7198      398         7   לאקספרס    B-ORG^E-ORG            2\n",
       "7376      408         6      בלין          S-PER            1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>כברית</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>המועצות</td>\n",
       "      <td>I-GPE^E-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>במערב</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>גימי</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>קרטר</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>דה</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>מוין</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>88</td>\n",
       "      <td>11</td>\n",
       "      <td>רגיסטר</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>באנגלית</td>\n",
       "      <td>O^S-ANG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>שלום</td>\n",
       "      <td>B-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>עכשיו</td>\n",
       "      <td>E-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>גורג</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>בוש</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>O^B-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>95</td>\n",
       "      <td>23</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>95</td>\n",
       "      <td>27</td>\n",
       "      <td>המפרץ</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>בית</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>המשפט</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>הבין</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>לאומי</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>בהאג</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>המערב</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>98</td>\n",
       "      <td>36</td>\n",
       "      <td>סדאם</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "      <td>חוסיין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>טום</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>טום</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>טקי</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id  token_str          biose  biose_count\n",
       "1693       82         6      ארה\"ב          S-GPE            1\n",
       "1700       82        13      כברית        O^B-GPE            2\n",
       "1701       82        14    המועצות    I-GPE^E-GPE            2\n",
       "1705       83         3      איובה          S-GPE            1\n",
       "1712       83        10      במערב  O^B-LOC^I-LOC            3\n",
       "1713       83        11     התיכון    I-LOC^E-LOC            2\n",
       "1719       83        17       גימי          B-PER            1\n",
       "1720       83        18       קרטר          E-PER            1\n",
       "1730       83        28  לאפגניסטן        O^S-GPE            2\n",
       "1732       84         1      איובה          S-GPE            1\n",
       "1751       85        11     בארה\"ב        O^S-GPE            2\n",
       "1763       86         7     באיובה        O^S-GPE            2\n",
       "1780       87         9      במפרץ  O^B-LOC^I-LOC            3\n",
       "1781       87        10      הפרסי    I-LOC^E-LOC            2\n",
       "1791       88         9         דה          B-ORG            1\n",
       "1792       88        10       מוין          I-ORG            1\n",
       "1793       88        11     רגיסטר          E-ORG            1\n",
       "1809       89         5    באנגלית        O^S-ANG            2\n",
       "1812       89         8       שלום          B-WOA            1\n",
       "1813       89         9      עכשיו          E-WOA            1\n",
       "1826       90        11    וייטנאם          S-GPE            1\n",
       "1856       92        17       גורג          S-PER            1\n",
       "1860       92        21    וייטנאם          S-GPE            1\n",
       "1864       93         2       גורג          S-WOA            1\n",
       "1868       93         6       גורג          B-PER            1\n",
       "1869       93         7        בוש          E-PER            1\n",
       "1900       95         4       לטום        O^B-PER            2\n",
       "1901       95         5     הארקין          E-PER            1\n",
       "1919       95        23      ארה\"ב          S-GPE            1\n",
       "1923       95        27      המפרץ    B-LOC^I-LOC            2\n",
       "1924       95        28      הפרסי    I-LOC^E-LOC            2\n",
       "1933       95        37        בית          B-ORG            1\n",
       "1934       95        38      המשפט    I-ORG^I-ORG            2\n",
       "1935       95        39       הבין    I-ORG^I-ORG            2\n",
       "1936       95        40          -          I-ORG            1\n",
       "1937       95        41      לאומי          E-ORG            1\n",
       "1939       95        43       בהאג        O^S-GPE            2\n",
       "1955       97         9     בארה\"ב        O^S-GPE            2\n",
       "1964       98         2      המערב    B-LOC^I-LOC            2\n",
       "1965       98         3     התיכון    I-LOC^E-LOC            2\n",
       "1967       98         5      ארה\"ב          S-GPE            1\n",
       "1988       98        26      ארה\"ב          S-GPE            1\n",
       "1998       98        36       סדאם          B-PER            1\n",
       "1999       98        37     חוסיין          E-PER            1\n",
       "2002       99         2      במפרץ  O^B-LOC^I-LOC            3\n",
       "2003       99         3      הפרסי    I-LOC^E-LOC            2\n",
       "2009       99         9     באיובה        O^S-GPE            2\n",
       "2011      100         1        טום          S-PER            1\n",
       "2018      100         8        טום          B-PER            1\n",
       "2019      100         9        טקי          E-PER            1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count==gs.morpheme_count) & (ps.biose.str.contains('-'))].iloc[140:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag\n",
       "0        1         1     עשרות              CDT\n",
       "1        1         2     אנשים               NN\n",
       "2        1         3    מגיעים               BN\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP\n",
       "4        1         5    לישראל              NNP"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag  morpheme_count\n",
       "0        1         1     עשרות              CDT               1\n",
       "1        1         2     אנשים               NN               1\n",
       "2        1         3    מגיעים               BN               1\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP               2\n",
       "4        1         5    לישראל              NNP               1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260273972602739"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[(ps.biose.str.contains('-'))].morpheme_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629534675041661"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~(ps.biose.str.contains('-'))].morpheme_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>שצה\"ל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>כמנזר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>ביחד</td>\n",
       "      <td>PREPOSITION^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "      <td>ואד</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>אלי</td>\n",
       "      <td>IN^S_PRN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>שלמה</td>\n",
       "      <td>REL^QW</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>לשיקאגו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>לניו</td>\n",
       "      <td>BN^POS^S_PRN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>בבוסטון</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>בשיקאגו</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>בירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>בצלם</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>ואראלה</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>ואיה</td>\n",
       "      <td>CONJ^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>161</td>\n",
       "      <td>17</td>\n",
       "      <td>בלוס</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>213</td>\n",
       "      <td>8</td>\n",
       "      <td>בבלאגיו</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>לזלי</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>229</td>\n",
       "      <td>48</td>\n",
       "      <td>בראדלו</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>שקרן</td>\n",
       "      <td>NNT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>232</td>\n",
       "      <td>14</td>\n",
       "      <td>לאחד</td>\n",
       "      <td>PREPOSITION^CD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>לקרן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>245</td>\n",
       "      <td>5</td>\n",
       "      <td>למקורות</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>245</td>\n",
       "      <td>16</td>\n",
       "      <td>ברוקינגס</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>בקליפורניה</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>294</td>\n",
       "      <td>19</td>\n",
       "      <td>לסילבר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>294</td>\n",
       "      <td>26</td>\n",
       "      <td>וולד</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>323</td>\n",
       "      <td>34</td>\n",
       "      <td>מניו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>327</td>\n",
       "      <td>22</td>\n",
       "      <td>בניו</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>327</td>\n",
       "      <td>33</td>\n",
       "      <td>ויטמן</td>\n",
       "      <td>CONJ^VB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>330</td>\n",
       "      <td>13</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>בטקסס</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>370</td>\n",
       "      <td>15</td>\n",
       "      <td>ורמונט</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>376</td>\n",
       "      <td>23</td>\n",
       "      <td>ולסטון</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>378</td>\n",
       "      <td>5</td>\n",
       "      <td>במינסוטה</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>384</td>\n",
       "      <td>14</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>לסנאט</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>412</td>\n",
       "      <td>26</td>\n",
       "      <td>ובאיטליה</td>\n",
       "      <td>CONJ^PREPOSITION^DEF^NNP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>416</td>\n",
       "      <td>4</td>\n",
       "      <td>בוסקה</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>439</td>\n",
       "      <td>11</td>\n",
       "      <td>מארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>כהן</td>\n",
       "      <td>ADVERB^PRP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>455</td>\n",
       "      <td>16</td>\n",
       "      <td>לכנסת</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>496</td>\n",
       "      <td>8</td>\n",
       "      <td>ליוסי</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id   token_str                   upostag  morpheme_count\n",
       "4           1         5      לישראל                       NNP               1\n",
       "766        37         3       שצה\"ל                       NNP               1\n",
       "819        40         9       כמנזר        PREPOSITION^DEF^NN               3\n",
       "1168       56        30        ביחד            PREPOSITION^RB               2\n",
       "1182       57        12    לירושלים                       NNP               1\n",
       "1193       57        23         ואד                   CONJ^NN               2\n",
       "1199       57        29         אלי                  IN^S_PRN               2\n",
       "1222       58        12    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "1730       83        28   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "1900       95         4        לטום                       NNP               1\n",
       "2441      121         8        שלמה                    REL^QW               2\n",
       "2549      128         7     לשיקאגו                       NNP               1\n",
       "2552      128        10        לניו              BN^POS^S_PRN               3\n",
       "2564      129         9     בבוסטון       PREPOSITION^DEF^NNP               3\n",
       "2575      130        10      לישראל       PREPOSITION^DEF^NNP               3\n",
       "2630      135         2     בשיקאגו       PREPOSITION^DEF^NNP               3\n",
       "2632      135         4    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "2636      136         3    בירושלים                       NNP               1\n",
       "2746      143         2        בצלם           PREPOSITION^NNT               2\n",
       "2993      159         5      ואראלה                  CONJ^NNP               2\n",
       "3014      161        11        ואיה                   CONJ^RB               2\n",
       "3020      161        17        בלוס                        VB               1\n",
       "3884      213         8     בבלאגיו        PREPOSITION^DEF^NN               3\n",
       "4114      224        16        לזלי            PREPOSITION^NN               2\n",
       "4133      225        13       הדסון                    DEF^NN               2\n",
       "4272      229        48      בראדלו            PREPOSITION^NN               2\n",
       "4294      231         8        שקרן                       NNT               1\n",
       "4324      232        14        לאחד            PREPOSITION^CD               2\n",
       "4427      238         2        לקרן        PREPOSITION^DEF^NN               3\n",
       "4478      239        26       באיסט           PREPOSITION^NNP               2\n",
       "4604      245         5     למקורות        PREPOSITION^DEF^NN               3\n",
       "4615      245        16    ברוקינגס            PREPOSITION^NN               2\n",
       "4684      250         4   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "5228      278         1  בקליפורניה                       NNP               1\n",
       "5490      294        19      לסילבר        PREPOSITION^DEF^NN               3\n",
       "5497      294        26        וולד                  CONJ^NNP               2\n",
       "6018      323        34        מניו                       NNP               1\n",
       "6085      327        22        בניו                        NN               1\n",
       "6096      327        33       ויטמן                   CONJ^VB               2\n",
       "6149      330        13      בארה\"ב                       NNP               1\n",
       "6254      337         1        בארץ        PREPOSITION^DEF^NN               3\n",
       "6573      356        11         בשן        PREPOSITION^DEF^NN               3\n",
       "6577      357         2       בטקסס                        NN               1\n",
       "6792      370        15      ורמונט                   CONJ^NN               2\n",
       "6873      376        23      ולסטון                  CONJ^NNP               2\n",
       "6892      378         5    במינסוטה       PREPOSITION^DEF^NNP               3\n",
       "6985      384        14      בארה\"ב                        NN               1\n",
       "7083      392         5       לסנאט           PREPOSITION^NNT               2\n",
       "7464      412        26    ובאיטליה  CONJ^PREPOSITION^DEF^NNP               4\n",
       "7505      416         4       בוסקה        PREPOSITION^DEF^NN               3\n",
       "7806      439        11      מארה\"ב                        NN               1\n",
       "7913      445        15         כהן                ADVERB^PRP               2\n",
       "8048      455        16       לכנסת           PREPOSITION^NNP               2\n",
       "8492      496         8       ליוסי       PREPOSITION^DEF^NNP               3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[(ys.morpheme_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
