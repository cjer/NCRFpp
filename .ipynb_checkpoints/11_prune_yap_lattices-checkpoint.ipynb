{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.034028Z",
     "start_time": "2019-03-13T07:20:22.687626Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:24.382406Z",
     "start_time": "2019-03-13T07:20:24.037019Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T07:20:27.996727Z",
     "start_time": "2019-03-13T07:20:24.385088Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get token data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nlp/danb')\n",
    "sys.path.append('/home/nlp/danb/NER')\n",
    "\n",
    "import bclm\n",
    "import ne_evaluate_mentions as nem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CDT</td>\n",
       "      <td>CDT</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>עשר</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>הנשים</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|gen=M|num=S|per=1|tense=FUTURE</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>איש</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>הגיע</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>מ</td>\n",
       "      <td>מ</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|gen=M|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=F|num=P</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>תאילנד</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=F|num=S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>ל</td>\n",
       "      <td>ל</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>PREPOSITION</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>gen=M|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P|num=S</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2     form    lemma      upostag      xpostag  \\\n",
       "0    0   1    עשרות      עשר          CDT          CDT   \n",
       "1    0   1    עשרות      עשר           CD           CD   \n",
       "2    1   2    אנשים    הנשים           VB           VB   \n",
       "3    1   2    אנשים      איש           NN           NN   \n",
       "4    2   3   מגיעים     הגיע           VB           VB   \n",
       "5    2   3   מגיעים     הגיע           BN           BN   \n",
       "6    3   4        מ        מ  PREPOSITION  PREPOSITION   \n",
       "7    3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "8    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "9    3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "10   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "11   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "12   3   5  מתאילנד  מתאילנד          NNP          NNP   \n",
       "13   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "14   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "15   3   5  מתאילנד  מתאילנד           NN           NN   \n",
       "16   4   5   תאילנד   תאילנד          NNP          NNP   \n",
       "17   5   6        ל        ל  PREPOSITION  PREPOSITION   \n",
       "18   5   8   לישראל   לישראל          NNP          NNP   \n",
       "19   5   8   לישראל   לישראל           NN           NN   \n",
       "\n",
       "                                   feats token_id  sent_id  \n",
       "0                            gen=F|num=P        1        1  \n",
       "1                            gen=F|num=P        1        1  \n",
       "2   gen=F|gen=M|num=S|per=1|tense=FUTURE        2        1  \n",
       "3                            gen=M|num=P        2        1  \n",
       "4        gen=M|num=P|per=A|tense=BEINONI        3        1  \n",
       "5                      gen=M|num=P|per=A        3        1  \n",
       "6                                      _        4        1  \n",
       "7                            gen=M|num=S        4        1  \n",
       "8                      gen=M|num=P|num=S        4        1  \n",
       "9                            gen=M|num=S        4        1  \n",
       "10                           gen=F|num=S        4        1  \n",
       "11                     gen=F|gen=M|num=S        4        1  \n",
       "12                                     _        4        1  \n",
       "13                           gen=M|num=P        4        1  \n",
       "14                           gen=F|num=S        4        1  \n",
       "15                           gen=F|num=P        4        1  \n",
       "16                           gen=F|num=S        4        1  \n",
       "17                                     _        5        1  \n",
       "18                           gen=M|num=S        5        1  \n",
       "19                     gen=M|num=P|num=S        5        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_lat = bclm.read_lattices(bclm.LATTICES_PATHS['dev'])\n",
    "dev_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>feats</th>\n",
       "      <th>token_id</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>הכל</td>\n",
       "      <td>הכיל</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>כל</td>\n",
       "      <td>כול</td>\n",
       "      <td>DTT</td>\n",
       "      <td>DTT</td>\n",
       "      <td>_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=P|per=A|tense=BEINONI</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נושא</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>נושאים</td>\n",
       "      <td>נשא</td>\n",
       "      <td>BN</td>\n",
       "      <td>BN</td>\n",
       "      <td>gen=M|num=P|per=A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>עם</td>\n",
       "      <td>עם</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=2|tense=IMPERATIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עם</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>עמם</td>\n",
       "      <td>עימם</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=M|num=S|per=3|tense=PAST</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>הם</td>\n",
       "      <td>הם</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>S_PRN</td>\n",
       "      <td>gen=M|num=P|per=3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>הוא</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "      <td>gen=F|num=S|per=2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>את</td>\n",
       "      <td>את</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NNT</td>\n",
       "      <td>NNT</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>כישלונות</td>\n",
       "      <td>כישלון</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>gen=M|num=P</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>DEF</td>\n",
       "      <td>DEF</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>ה</td>\n",
       "      <td>ה</td>\n",
       "      <td>REL</td>\n",
       "      <td>REL</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>הקליטה</td>\n",
       "      <td>הקליט</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>gen=F|num=S|per=3|tense=PAST</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1 ID2      form   lemma upostag xpostag  \\\n",
       "0    0   1         ה       ה     DEF     DEF   \n",
       "1    0   2         ה       ה     REL     REL   \n",
       "2    0   3       הכל    הכיל      VB      VB   \n",
       "3    1   3        כל     כול     DTT     DTT   \n",
       "4    2   3        כל     כול     DTT     DTT   \n",
       "5    3   4    נושאים     נשא      VB      VB   \n",
       "6    3   4    נושאים    נושא      NN      NN   \n",
       "7    3   4    נושאים     נשא      BN      BN   \n",
       "8    4   5        עם      עם      IN      IN   \n",
       "9    4   6       עמם    עימם      VB      VB   \n",
       "10   4   6       עמם      עם      NN      NN   \n",
       "11   4   6       עמם    עימם      VB      VB   \n",
       "12   5   6        הם      הם   S_PRN   S_PRN   \n",
       "13   6   7        את     הוא     PRP     PRP   \n",
       "14   6   7        את      את      AT      AT   \n",
       "15   7   8  כישלונות  כישלון     NNT     NNT   \n",
       "16   7   8  כישלונות  כישלון      NN      NN   \n",
       "17   8   9         ה       ה     DEF     DEF   \n",
       "18   8  10         ה       ה     REL     REL   \n",
       "19   8  11    הקליטה   הקליט      VB      VB   \n",
       "\n",
       "                                        feats token_id  sent_id  \n",
       "0                                           _        1        1  \n",
       "1                                           _        1        1  \n",
       "2          gen=M|num=S|per=2|tense=IMPERATIVE        1        1  \n",
       "3                                           _        1        1  \n",
       "4                                           _        1        1  \n",
       "5             gen=M|num=P|per=A|tense=BEINONI        2        1  \n",
       "6                                 gen=M|num=P        2        1  \n",
       "7                           gen=M|num=P|per=A        2        1  \n",
       "8                                           _        3        1  \n",
       "9          gen=M|num=S|per=2|tense=IMPERATIVE        3        1  \n",
       "10  gen=M|num=S|suf_gen=M|suf_num=P|suf_per=3        3        1  \n",
       "11               gen=M|num=S|per=3|tense=PAST        3        1  \n",
       "12                          gen=M|num=P|per=3        3        1  \n",
       "13                          gen=F|num=S|per=2        4        1  \n",
       "14                                          _        4        1  \n",
       "15                                gen=M|num=P        5        1  \n",
       "16                                gen=M|num=P        5        1  \n",
       "17                                          _        6        1  \n",
       "18                                          _        6        1  \n",
       "19               gen=F|num=S|per=3|tense=PAST        6        1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lat = bclm.read_lattices(bclm.LATTICES_PATHS['test'])\n",
    "test_lat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose_layer0</th>\n",
       "      <th>upostag</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>O</td>\n",
       "      <td>CDT</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>O</td>\n",
       "      <td>BN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str biose_layer0          upostag  set\n",
       "0        1         1     עשרות            O              CDT  dev\n",
       "1        1         2     אנשים            O               NN  dev\n",
       "2        1         3    מגיעים            O               BN  dev\n",
       "3        1         4   מתאילנד      O^S-GPE  PREPOSITION^NNP  dev\n",
       "4        1         5    לישראל      O^S-GPE  PREPOSITION^NNP  dev"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped = [5438, 5444, 5445, 5446, 5448, 5449, 5450, 5451, 5453, 5459]\n",
    "spdf = bclm.read_dataframe('spmrl')\n",
    "spdf = spdf[(~spdf.sent_id.isin(dropped))]\n",
    "tokens_ner_with_upos = bclm.get_token_df(spdf, fields = ['biose_layer0', 'upostag'])\n",
    "tokens_ner_with_upos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "dev         1\n",
       "test     5439\n",
       "train     501\n",
       "Name: sent_id, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdf.groupby('set').sent_id.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_gold_sents =   tokens_ner_with_upos.groupby('sent_id')[['token_str', 'biose_layer0']].apply(lambda x: x.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biose_count(path, sent_id_shift=1):\n",
    "    sents = nem.read_file_sents(path, fix_multi_tag=False, sent_id_shift=sent_id_shift)\n",
    "    bc = []\n",
    "    for i, sent in sents.iteritems():\n",
    "        for j, (tok, bio) in enumerate(sent):\n",
    "            bc.append([i, j+1, tok, bio, len(bio.split('^'))])\n",
    "\n",
    "    bc = pd.DataFrame(bc, columns=['sent_id', 'token_id', 'token_str', \n",
    "                                   'biose', 'biose_count'])\n",
    "    return bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str    biose  biose_count\n",
       "0        1         1     עשרות        O            1\n",
       "1        1         2     אנשים        O            1\n",
       "2        1         3    מגיעים        O            1\n",
       "3        1         4   מתאילנד  O^S-GPE            2\n",
       "4        1         5    לישראל  O^S-GPE            2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = get_biose_count('final_setup/decode_output/token_dev.'\\\n",
    "                      'multitok.char_cnn.ft_oov_tok.53_seed.bmes', \n",
    "                     sent_id_shift=1)\n",
    "ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = get_biose_count('final_setup/decode_output/token_test.'\\\n",
    "                      'multitok.char_cnn.ft_oov_tok.53_seed.bmes', \n",
    "                     sent_id_shift=5439)\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_edges(lattices, bc,\n",
    "                    non_o_only=True, keep_all_if_no_valid=True):\n",
    "    valid_edges = []\n",
    "    for (i, df), (_, biose, biose_count) in zip(lattices.groupby(['sent_id', 'token_id']), \n",
    "                                                bc[['biose', 'biose_count']].itertuples()):\n",
    "        el = df[['ID1', 'ID2']].rename(columns={'ID1': 'source', 'ID2': 'target'})\n",
    "        #min_node = [n for n,v in G.nodes(data=True) if v['since'] == 'December 2008'][0]\n",
    "\n",
    "        g = nx.from_pandas_edgelist(el, create_using=nx.DiGraph)\n",
    "        min_node = el.source.min()\n",
    "        max_node = el.target.max()\n",
    "        #print(min_node,max_node)\n",
    "        #print(biose_count)\n",
    "        if non_o_only and not '-' in biose:\n",
    "            vp = list(nx.all_simple_paths(g, min_node, max_node))\n",
    "        else:\n",
    "            vp = [path for path in nx.all_simple_paths(g, min_node, max_node, cutoff=biose_count+1) if len(path)==biose_count+1]\n",
    "        if keep_all_if_no_valid and len(vp)==0:\n",
    "             vp = nx.all_simple_paths(g, min_node, max_node)\n",
    "        for path in vp:\n",
    "            for source, target in zip(path[:-1], path[1:]):\n",
    "                valid_edges.append((i[0], i[1], source, target))\n",
    "                \n",
    "    return valid_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_edges_non_o_keep = get_valid_edges(dev_lat, ps, keep_all_if_no_valid=True)\n",
    "valid_edges_all_keep = get_valid_edges(dev_lat, ps, non_o_only=False, keep_all_if_no_valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23901, 13473)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_edges_non_o_keep), len(valid_edges_all_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22742,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_lat.groupby(cols).size().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_edges = pd.DataFrame(valid_edges, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_lat_non_o_keep = dev_lat[dev_lat[cols].apply(lambda x: tuple(x) in valid_edges_non_o_keep, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_lat_all_keep = dev_lat[dev_lat[cols].apply(lambda x: tuple(x) in valid_edges_all_keep, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59758, 56822, 28842)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_lat), len(pruned_lat_non_o_keep), len(pruned_lat_all_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lattices(df, path, cols = ['ID1', 'ID2', 'form', 'lemma', 'upostag', 'xpostag', 'feats', 'token_id']):\n",
    "    with open(path, 'w', encoding='utf8') as of:\n",
    "        for _, sent in df.groupby('sent_id'):\n",
    "            for _, row in sent[cols].iterrows():\n",
    "                of.write('\\t'.join(row.astype(str).tolist())+'\\n')\n",
    "            of.write('\\n')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_lattices(pruned_lat_non_o_keep, 'final_setup/pruned/dev_pruned_non_o_keep.lattices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_lattices(pruned_lat_all_keep, 'final_setup/pruned/dev_pruned_all_keep.lattices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>arch</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>cm</th>\n",
       "      <th>acc</th>\n",
       "      <th>model_base_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116275</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_cnn</td>\n",
       "      <td>ft_oov</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>multitok.char_cnn.ft_oov_tok.53_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft_oov</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>multitok.char_lstm.ft_oov_tok.45_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108393</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_cnn</td>\n",
       "      <td>ft</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>multitok.char_cnn.ft_tok.51_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99319</th>\n",
       "      <td>multitok</td>\n",
       "      <td>char_lstm</td>\n",
       "      <td>ft</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>multitok.char_lstm.ft_tok.49_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42667</th>\n",
       "      <td>multitok</td>\n",
       "      <td>no_char</td>\n",
       "      <td>ft_oov</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>multitok.no_char.ft_oov_tok.46_seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            unit       arch embed_type     cm     acc  \\\n",
       "116275  multitok   char_cnn     ft_oov  Match  0.9440   \n",
       "9890    multitok  char_lstm     ft_oov  Match  0.9437   \n",
       "108393  multitok   char_cnn         ft  Match  0.9410   \n",
       "99319   multitok  char_lstm         ft  Match  0.9403   \n",
       "42667   multitok    no_char     ft_oov  Match  0.9373   \n",
       "\n",
       "                              model_base_name  \n",
       "116275   multitok.char_cnn.ft_oov_tok.53_seed  \n",
       "9890    multitok.char_lstm.ft_oov_tok.45_seed  \n",
       "108393       multitok.char_cnn.ft_tok.51_seed  \n",
       "99319       multitok.char_lstm.ft_tok.49_seed  \n",
       "42667     multitok.no_char.ft_oov_tok.46_seed  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erdf = pd.read_pickle('final_setup/erdf.pkl')\n",
    "best_multi = (erdf.loc[(erdf.unit=='multitok') \n",
    "      & (erdf\n",
    "         .groupby(['unit', 'arch', 'embed_type', 'cm'])\n",
    "         .relevant_score\n",
    "         .transform(max)==erdf.relevant_score),\n",
    "         ['unit', 'arch', 'embed_type', 'cm', 'acc', 'model_base_name']]\n",
    " .sort_values('acc', ascending=False)\n",
    ")\n",
    "best_multi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'ID1', 'ID2']\n",
    "def get_pruned_lattice(lattices, bc, non_o_only=False):\n",
    "    valid_edges = get_valid_edges(lattices, bc, non_o_only=non_o_only)\n",
    "    pruned_lat = lattices[lattices[cols]\n",
    "                         .apply(lambda x: tuple(x) in valid_edges,\n",
    "                                axis=1)]\n",
    "    return pruned_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_setup/pruned/lattices/dev.multitok.char_cnn.ft_tok.51_seed.lattices\n",
      "final_setup/pruned/lattices/test.multitok.char_cnn.ft_tok.51_seed.lattices\n",
      "final_setup/pruned/lattices/dev.multitok.char_lstm.ft_tok.49_seed.lattices\n",
      "final_setup/pruned/lattices/test.multitok.char_lstm.ft_tok.49_seed.lattices\n",
      "final_setup/pruned/lattices/dev.multitok.no_char.ft_oov_tok.46_seed.lattices\n"
     ]
    }
   ],
   "source": [
    "output_folder = 'final_setup/decode_output'\n",
    "models_folder = 'final_setup/models'\n",
    "pruned_folder = 'final_setup/pruned/lattices'\n",
    "    \n",
    "for i, row in best_multi.iterrows():\n",
    "    pruned_dev_path =  os.path.join(pruned_folder, \n",
    "                                    'dev.'+row.model_base_name+'.lattices')\n",
    "    if not os.path.exists(pruned_dev_path):\n",
    "        print(pruned_dev_path)\n",
    "        dev_path = os.path.join(output_folder, \n",
    "                                'token_dev.'+row.model_base_name+'.bmes')\n",
    "        dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "        pdev_lat = get_pruned_lattice(dev_lat, dev_bc)\n",
    "        to_lattices(pdev_lat, pruned_dev_path)\n",
    "\n",
    "    pruned_test_path = os.path.join(pruned_folder, \n",
    "                                    'test.'+row.model_base_name+'.lattices')    \n",
    "    if not os.path.exists(pruned_test_path):\n",
    "        print(pruned_test_path)\n",
    "        test_path = os.path.join(output_folder, \n",
    "                                 'token_test.'+row.model_base_name+'.bmes')\n",
    "        test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "        ptest_lat = get_pruned_lattice(test_lat, test_bc)\n",
    "        to_lattices(ptest_lat, pruned_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run YAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_path = '/home/nlp/danb/yapproj/src/yap/yap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOPATH=/home/nlp/danb/yapproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/yapproj/src/yap/yap - invoke yap as a standalone app or as an api server\n",
      "\n",
      "Commands:\n",
      "\n",
      "    api         start api server\n",
      "    dep         runs dependency training/parsing\n",
      "    hebma       run lexicon-based morphological analyzer on raw input\n",
      "    joint       runs joint morpho-syntactic training and parsing\n",
      "    ma          run data-driven morphological analyzer on raw input\n",
      "    md          runs standalone morphological disambiguation training and parsing\n",
      "\n",
      "Use \"/home/nlp/danb/yapproj/src/yap/yap help <command>\" for more information about a command.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{yap_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/01/13 18:37:57.128507 GOMAXPROCS:\t40\n",
      "2020/01/13 18:37:57.128672 \n",
      "2020/01/13 18:37:57.129368 *** CONFIGURATION ***\n",
      "2020/01/13 18:37:57.129395 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/13 18:37:57.129421 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/13 18:37:57.129442 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/13 18:37:57.129483 Iterations:\t\t1\n",
      "2020/01/13 18:37:57.129506 Beam Size:\t\t64\n",
      "2020/01/13 18:37:57.129526 Beam Concurrent:\ttrue\n",
      "2020/01/13 18:37:57.129543 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/13 18:37:57.129560 Use Lemmas:\t\tfalse\n",
      "2020/01/13 18:37:57.129580 Use POP:\t\ttrue\n",
      "2020/01/13 18:37:57.129601 Infuse Gold Dev:\tfalse\n",
      "2020/01/13 18:37:57.129617 Limit (thousands):\t0\n",
      "2020/01/13 18:37:57.129634 Use CoNLL-U:\t\tfalse\n",
      "2020/01/13 18:37:57.129653 \n",
      "2020/01/13 18:37:57.129664 Features File:\tjointzeager.yaml\n",
      "2020/01/13 18:37:57.130468 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/13 18:37:57.130849 \n",
      "2020/01/13 18:37:57.130871 Data\n",
      "2020/01/13 18:37:57.130884 Test file  (ambig.  lattice):\tfinal_setup/pruned/lattices/test.multitok.no_char.no_word.46_seed.lattices\n",
      "2020/01/13 18:37:57.130924 Out (disamb.) file:\t\t\tfinal_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.conll\n",
      "2020/01/13 18:37:57.130949 Out (segmt.) file:\t\t\tfinal_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.seg\n",
      "2020/01/13 18:37:57.130973 Out (mapping.) file:\t\t\tfinal_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.map\n",
      "2020/01/13 18:37:57.131672 \n",
      "2020/01/13 18:37:57.131694 Setup enumerations\n",
      "2020/01/13 18:37:57.131798 ETrans Len is 96\n",
      "2020/01/13 18:37:57.132766 \n",
      "2020/01/13 18:37:57.132787 Loading features\n",
      "2020/01/13 18:37:57.134496 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/13 18:37:57.134570 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/13 18:37:57.134655 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/13 18:37:57.134711 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/13 18:37:57.134737 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/13 18:37:57.134808 Loading POP transition dependent feature group POP\n",
      "2020/01/13 18:37:57.134837 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/13 18:37:57.134863 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/13 18:37:57.135183 \n",
      "2020/01/13 18:37:57.135216 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/13 18:37:57.135231 \n",
      "2020/01/13 18:37:57.135244 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/13 18:38:16.053317 Loaded model\n",
      "2020/01/13 18:38:16.053363 \n",
      "2020/01/13 18:38:16.053368 *** PARSING ***\n",
      "2020/01/13 18:38:16.053395 Parsing test\n",
      "2020/01/13 18:38:16.053428 Reading ambiguous lattices from final_setup/pruned/lattices/test.multitok.no_char.no_word.46_seed.lattices\n",
      "2020/01/13 18:38:16.142332 Read 706 ambiguous lattices from final_setup/pruned/lattices/test.multitok.no_char.no_word.46_seed.lattices\n",
      "2020/01/13 18:38:16.142364 Converting lattice format to internal structure\n",
      "2020/01/13 18:38:16.670515 Parsing instance 0\n",
      "2020/01/13 18:38:16.882598 Parsing instance 1\n",
      "2020/01/13 18:38:16.995385 Parsing instance 2\n",
      "2020/01/13 18:38:17.057459 Parsing instance 3\n",
      "2020/01/13 18:38:17.159611 Parsing instance 4\n",
      "2020/01/13 18:38:17.224332 Parsing instance 5\n",
      "2020/01/13 18:38:17.585028 Parsing instance 6\n",
      "2020/01/13 18:38:17.711266 Parsing instance 7\n",
      "2020/01/13 18:38:17.768993 Parsing instance 8\n",
      "2020/01/13 18:38:17.785195 Parsing instance 9\n",
      "2020/01/13 18:38:17.823626 Parsing instance 10\n",
      "2020/01/13 18:38:17.918841 Parsing instance 11\n",
      "2020/01/13 18:38:17.998053 Parsing instance 12\n",
      "2020/01/13 18:38:18.104616 Parsing instance 13\n",
      "2020/01/13 18:38:18.146862 Parsing instance 14\n",
      "2020/01/13 18:38:18.218855 Parsing instance 15\n",
      "2020/01/13 18:38:18.301634 Parsing instance 16\n",
      "2020/01/13 18:38:18.477111 Parsing instance 17\n",
      "2020/01/13 18:38:18.774407 Parsing instance 18\n",
      "2020/01/13 18:38:18.958382 Parsing instance 19\n",
      "2020/01/13 18:38:19.133119 Parsing instance 20\n",
      "2020/01/13 18:38:19.152537 Parsing instance 21\n",
      "2020/01/13 18:38:19.170924 Parsing instance 22\n",
      "2020/01/13 18:38:19.197275 Parsing instance 23\n",
      "2020/01/13 18:38:19.387230 Parsing instance 24\n",
      "2020/01/13 18:38:19.473012 Parsing instance 25\n",
      "2020/01/13 18:38:19.524153 Parsing instance 26\n",
      "2020/01/13 18:38:19.594088 Parsing instance 27\n",
      "2020/01/13 18:38:19.766341 Parsing instance 28\n",
      "2020/01/13 18:38:19.878825 Parsing instance 29\n",
      "2020/01/13 18:38:20.113177 Parsing instance 30\n",
      "2020/01/13 18:38:20.172575 Parsing instance 31\n",
      "2020/01/13 18:38:20.217239 Parsing instance 32\n",
      "2020/01/13 18:38:20.390396 Parsing instance 33\n",
      "2020/01/13 18:38:20.453997 Parsing instance 34\n",
      "2020/01/13 18:38:20.584933 Parsing instance 35\n",
      "2020/01/13 18:38:20.805210 Parsing instance 36\n",
      "2020/01/13 18:38:20.842905 Parsing instance 37\n",
      "2020/01/13 18:38:20.920778 Parsing instance 38\n",
      "2020/01/13 18:38:20.928291 Parsing instance 39\n",
      "2020/01/13 18:38:21.288115 Parsing instance 40\n",
      "2020/01/13 18:38:21.356537 Parsing instance 41\n",
      "2020/01/13 18:38:21.398540 Parsing instance 42\n",
      "2020/01/13 18:38:21.518690 Parsing instance 43\n",
      "2020/01/13 18:38:21.652081 Parsing instance 44\n",
      "2020/01/13 18:38:21.735867 Parsing instance 45\n",
      "2020/01/13 18:38:21.999880 Parsing instance 46\n",
      "2020/01/13 18:38:22.013431 Parsing instance 47\n",
      "2020/01/13 18:38:22.198935 Parsing instance 48\n",
      "2020/01/13 18:38:22.422666 Parsing instance 49\n",
      "2020/01/13 18:38:22.484392 Parsing instance 50\n",
      "2020/01/13 18:38:22.657972 Parsing instance 51\n",
      "2020/01/13 18:38:22.724949 Parsing instance 52\n",
      "2020/01/13 18:38:22.767052 Parsing instance 53\n",
      "2020/01/13 18:38:22.781686 Parsing instance 54\n",
      "2020/01/13 18:38:22.854034 Parsing instance 55\n",
      "2020/01/13 18:38:23.030169 Parsing instance 56\n",
      "2020/01/13 18:38:23.112443 Parsing instance 57\n",
      "2020/01/13 18:38:23.202717 Parsing instance 58\n",
      "2020/01/13 18:38:23.373874 Parsing instance 59\n",
      "2020/01/13 18:38:23.600506 Parsing instance 60\n",
      "2020/01/13 18:38:23.721785 Parsing instance 61\n",
      "2020/01/13 18:38:23.749950 Parsing instance 62\n",
      "2020/01/13 18:38:23.812616 Parsing instance 63\n",
      "2020/01/13 18:38:23.861790 Parsing instance 64\n",
      "2020/01/13 18:38:23.943474 Parsing instance 65\n",
      "2020/01/13 18:38:24.040018 Parsing instance 66\n",
      "2020/01/13 18:38:24.138521 Parsing instance 67\n",
      "2020/01/13 18:38:24.191261 Parsing instance 68\n",
      "2020/01/13 18:38:24.272567 Parsing instance 69\n",
      "2020/01/13 18:38:24.368325 Parsing instance 70\n",
      "2020/01/13 18:38:24.590275 Parsing instance 71\n",
      "2020/01/13 18:38:24.731046 Parsing instance 72\n",
      "2020/01/13 18:38:24.777891 Parsing instance 73\n",
      "2020/01/13 18:38:24.875033 Parsing instance 74\n",
      "2020/01/13 18:38:24.930806 Parsing instance 75\n",
      "2020/01/13 18:38:25.066632 Parsing instance 76\n",
      "2020/01/13 18:38:25.165016 Parsing instance 77\n",
      "2020/01/13 18:38:25.212660 Parsing instance 78\n",
      "2020/01/13 18:38:25.248695 Parsing instance 79\n",
      "2020/01/13 18:38:25.323671 Parsing instance 80\n",
      "2020/01/13 18:38:25.400838 Parsing instance 81\n",
      "2020/01/13 18:38:25.571403 Parsing instance 82\n",
      "2020/01/13 18:38:25.810972 Parsing instance 83\n",
      "2020/01/13 18:38:25.922052 Parsing instance 84\n",
      "2020/01/13 18:38:26.007391 Parsing instance 85\n",
      "2020/01/13 18:38:26.084299 Parsing instance 86\n",
      "2020/01/13 18:38:26.216444 Parsing instance 87\n",
      "2020/01/13 18:38:26.338567 Parsing instance 88\n",
      "2020/01/13 18:38:26.417011 Parsing instance 89\n",
      "2020/01/13 18:38:26.551170 Parsing instance 90\n",
      "2020/01/13 18:38:26.869916 Parsing instance 91\n",
      "2020/01/13 18:38:26.996811 Parsing instance 92\n",
      "2020/01/13 18:38:27.058663 Parsing instance 93\n",
      "2020/01/13 18:38:27.084050 Parsing instance 94\n",
      "2020/01/13 18:38:27.299286 Parsing instance 95\n",
      "2020/01/13 18:38:27.411362 Parsing instance 96\n",
      "2020/01/13 18:38:27.509279 Parsing instance 97\n",
      "2020/01/13 18:38:27.580940 Parsing instance 98\n",
      "2020/01/13 18:38:27.612708 Parsing instance 99\n",
      "2020/01/13 18:38:27.712812 Parsing instance 100\n",
      "2020/01/13 18:38:27.947531 Parsing instance 101\n",
      "2020/01/13 18:38:28.050074 Parsing instance 102\n",
      "2020/01/13 18:38:28.271659 Parsing instance 103\n",
      "2020/01/13 18:38:28.324020 Parsing instance 104\n",
      "2020/01/13 18:38:28.470206 Parsing instance 105\n",
      "2020/01/13 18:38:28.556917 Parsing instance 106\n",
      "2020/01/13 18:38:28.630055 Parsing instance 107\n",
      "2020/01/13 18:38:28.725123 Parsing instance 108\n",
      "2020/01/13 18:38:29.012523 Parsing instance 109\n",
      "2020/01/13 18:38:29.084477 Parsing instance 110\n",
      "2020/01/13 18:38:29.142900 Parsing instance 111\n",
      "2020/01/13 18:38:29.187453 Parsing instance 112\n",
      "2020/01/13 18:38:29.230759 Parsing instance 113\n",
      "2020/01/13 18:38:29.371589 Parsing instance 114\n",
      "2020/01/13 18:38:29.451381 Parsing instance 115\n",
      "2020/01/13 18:38:29.657470 Parsing instance 116\n",
      "2020/01/13 18:38:29.784744 Parsing instance 117\n",
      "2020/01/13 18:38:29.843195 Parsing instance 118\n",
      "2020/01/13 18:38:30.193904 Parsing instance 119\n",
      "2020/01/13 18:38:30.262137 Parsing instance 120\n",
      "2020/01/13 18:38:30.272332 Parsing instance 121\n",
      "2020/01/13 18:38:30.345111 Parsing instance 122\n",
      "2020/01/13 18:38:30.506621 Parsing instance 123\n",
      "2020/01/13 18:38:30.624165 Parsing instance 124\n",
      "2020/01/13 18:38:30.845795 Parsing instance 125\n",
      "2020/01/13 18:38:30.962062 Parsing instance 126\n",
      "2020/01/13 18:38:31.112065 Parsing instance 127\n",
      "2020/01/13 18:38:31.214679 Parsing instance 128\n",
      "2020/01/13 18:38:31.356731 Parsing instance 129\n",
      "2020/01/13 18:38:31.482496 Parsing instance 130\n",
      "2020/01/13 18:38:31.579930 Parsing instance 131\n",
      "2020/01/13 18:38:31.784270 Parsing instance 132\n",
      "2020/01/13 18:38:32.011420 Parsing instance 133\n",
      "2020/01/13 18:38:32.176418 Parsing instance 134\n",
      "2020/01/13 18:38:32.339861 Parsing instance 135\n",
      "2020/01/13 18:38:32.401637 Parsing instance 136\n",
      "2020/01/13 18:38:32.488955 Parsing instance 137\n",
      "2020/01/13 18:38:32.498466 Parsing instance 138\n",
      "2020/01/13 18:38:32.597014 Parsing instance 139\n",
      "2020/01/13 18:38:32.617724 Parsing instance 140\n",
      "2020/01/13 18:38:32.693410 Parsing instance 141\n",
      "2020/01/13 18:38:32.930973 Parsing instance 142\n",
      "2020/01/13 18:38:33.296546 Parsing instance 143\n",
      "2020/01/13 18:38:33.372457 Parsing instance 144\n",
      "2020/01/13 18:38:33.445324 Parsing instance 145\n",
      "2020/01/13 18:38:33.530536 Parsing instance 146\n",
      "2020/01/13 18:38:33.552291 Parsing instance 147\n",
      "2020/01/13 18:38:33.775285 Parsing instance 148\n",
      "2020/01/13 18:38:33.868131 Parsing instance 149\n",
      "2020/01/13 18:38:33.951684 Parsing instance 150\n",
      "2020/01/13 18:38:34.019389 Parsing instance 151\n",
      "2020/01/13 18:38:34.384911 Parsing instance 152\n",
      "2020/01/13 18:38:34.505520 Parsing instance 153\n",
      "2020/01/13 18:38:34.612795 Parsing instance 154\n",
      "2020/01/13 18:38:34.881471 Parsing instance 155\n",
      "2020/01/13 18:38:34.939403 Parsing instance 156\n",
      "2020/01/13 18:38:35.314097 Parsing instance 157\n",
      "2020/01/13 18:38:35.359647 Parsing instance 158\n",
      "2020/01/13 18:38:35.478119 Parsing instance 159\n",
      "2020/01/13 18:38:35.496996 Parsing instance 160\n",
      "2020/01/13 18:38:35.704401 Parsing instance 161\n",
      "2020/01/13 18:38:35.780803 Parsing instance 162\n",
      "2020/01/13 18:38:36.025736 Parsing instance 163\n",
      "2020/01/13 18:38:36.103226 Parsing instance 164\n",
      "2020/01/13 18:38:36.127894 Parsing instance 165\n",
      "2020/01/13 18:38:36.363290 Parsing instance 166\n",
      "2020/01/13 18:38:36.525657 Parsing instance 167\n",
      "2020/01/13 18:38:36.584584 Parsing instance 168\n",
      "2020/01/13 18:38:36.631520 Parsing instance 169\n",
      "2020/01/13 18:38:36.693180 Parsing instance 170\n",
      "2020/01/13 18:38:36.801383 Parsing instance 171\n",
      "2020/01/13 18:38:36.857255 Parsing instance 172\n",
      "2020/01/13 18:38:36.924904 Parsing instance 173\n",
      "2020/01/13 18:38:36.964924 Parsing instance 174\n",
      "2020/01/13 18:38:37.019054 Parsing instance 175\n",
      "2020/01/13 18:38:37.046312 Parsing instance 176\n",
      "2020/01/13 18:38:37.065492 Parsing instance 177\n",
      "2020/01/13 18:38:37.083152 Parsing instance 178\n",
      "2020/01/13 18:38:37.154912 Parsing instance 179\n",
      "2020/01/13 18:38:37.251536 Parsing instance 180\n",
      "2020/01/13 18:38:37.410530 Parsing instance 181\n",
      "2020/01/13 18:38:37.430458 Parsing instance 182\n",
      "2020/01/13 18:38:37.443408 Parsing instance 183\n",
      "2020/01/13 18:38:37.595549 Parsing instance 184\n",
      "2020/01/13 18:38:37.682541 Parsing instance 185\n",
      "2020/01/13 18:38:37.730996 Parsing instance 186\n",
      "2020/01/13 18:38:37.794575 Parsing instance 187\n",
      "2020/01/13 18:38:37.918037 Parsing instance 188\n",
      "2020/01/13 18:38:37.932965 Parsing instance 189\n",
      "2020/01/13 18:38:37.953060 Parsing instance 190\n",
      "2020/01/13 18:38:37.979367 Parsing instance 191\n",
      "2020/01/13 18:38:37.984229 Parsing instance 192\n",
      "2020/01/13 18:38:37.986533 Parsing instance 193\n",
      "2020/01/13 18:38:38.009143 Parsing instance 194\n",
      "2020/01/13 18:38:38.111840 Parsing instance 195\n",
      "2020/01/13 18:38:38.142223 Parsing instance 196\n",
      "2020/01/13 18:38:38.310602 Parsing instance 197\n",
      "2020/01/13 18:38:38.401015 Parsing instance 198\n",
      "2020/01/13 18:38:38.538193 Parsing instance 199\n",
      "2020/01/13 18:38:38.576985 Parsing instance 200\n",
      "2020/01/13 18:38:38.745371 Parsing instance 201\n",
      "2020/01/13 18:38:38.758716 Parsing instance 202\n",
      "2020/01/13 18:38:38.826463 Parsing instance 203\n",
      "2020/01/13 18:38:38.851229 Parsing instance 204\n",
      "2020/01/13 18:38:38.896680 Parsing instance 205\n",
      "2020/01/13 18:38:38.929806 Parsing instance 206\n",
      "2020/01/13 18:38:39.111918 Parsing instance 207\n",
      "2020/01/13 18:38:39.386272 Parsing instance 208\n",
      "2020/01/13 18:38:39.559670 Parsing instance 209\n",
      "2020/01/13 18:38:39.641036 Parsing instance 210\n",
      "2020/01/13 18:38:39.677364 Parsing instance 211\n",
      "2020/01/13 18:38:39.809087 Parsing instance 212\n",
      "2020/01/13 18:38:39.913149 Parsing instance 213\n",
      "2020/01/13 18:38:39.951841 Parsing instance 214\n",
      "2020/01/13 18:38:39.989207 Parsing instance 215\n",
      "2020/01/13 18:38:40.238922 Parsing instance 216\n",
      "2020/01/13 18:38:40.282682 Parsing instance 217\n",
      "2020/01/13 18:38:40.530734 Parsing instance 218\n",
      "2020/01/13 18:38:40.582276 Parsing instance 219\n",
      "2020/01/13 18:38:40.633771 Parsing instance 220\n",
      "2020/01/13 18:38:40.651219 Parsing instance 221\n",
      "2020/01/13 18:38:40.790046 Parsing instance 222\n",
      "2020/01/13 18:38:40.854559 Parsing instance 223\n",
      "2020/01/13 18:38:40.961115 Parsing instance 224\n",
      "2020/01/13 18:38:41.095844 Parsing instance 225\n",
      "2020/01/13 18:38:41.177019 Parsing instance 226\n",
      "2020/01/13 18:38:41.269275 Parsing instance 227\n",
      "2020/01/13 18:38:41.523031 Parsing instance 228\n",
      "2020/01/13 18:38:41.624515 Parsing instance 229\n",
      "2020/01/13 18:38:41.744845 Parsing instance 230\n",
      "2020/01/13 18:38:41.810756 Parsing instance 231\n",
      "2020/01/13 18:38:41.868938 Parsing instance 232\n",
      "2020/01/13 18:38:41.891329 Parsing instance 233\n",
      "2020/01/13 18:38:41.905999 Parsing instance 234\n",
      "2020/01/13 18:38:41.953999 Parsing instance 235\n",
      "2020/01/13 18:38:42.000466 Parsing instance 236\n",
      "2020/01/13 18:38:42.070574 Parsing instance 237\n",
      "2020/01/13 18:38:42.117337 Parsing instance 238\n",
      "2020/01/13 18:38:42.168382 Parsing instance 239\n",
      "2020/01/13 18:38:42.210819 Parsing instance 240\n",
      "2020/01/13 18:38:42.229572 Parsing instance 241\n",
      "2020/01/13 18:38:42.258863 Parsing instance 242\n",
      "2020/01/13 18:38:42.310048 Parsing instance 243\n",
      "2020/01/13 18:38:42.367087 Parsing instance 244\n",
      "2020/01/13 18:38:42.392282 Parsing instance 245\n",
      "2020/01/13 18:38:42.502212 Parsing instance 246\n",
      "2020/01/13 18:38:42.768182 Parsing instance 247\n",
      "2020/01/13 18:38:42.800479 Parsing instance 248\n",
      "2020/01/13 18:38:42.906838 Parsing instance 249\n",
      "2020/01/13 18:38:42.957339 Parsing instance 250\n",
      "2020/01/13 18:38:42.965318 Parsing instance 251\n",
      "2020/01/13 18:38:43.010534 Parsing instance 252\n",
      "2020/01/13 18:38:43.064247 Parsing instance 253\n",
      "2020/01/13 18:38:43.087391 Parsing instance 254\n",
      "2020/01/13 18:38:43.161552 Parsing instance 255\n",
      "2020/01/13 18:38:43.205047 Parsing instance 256\n",
      "2020/01/13 18:38:43.280260 Parsing instance 257\n",
      "2020/01/13 18:38:43.361619 Parsing instance 258\n",
      "2020/01/13 18:38:43.375463 Parsing instance 259\n",
      "2020/01/13 18:38:43.440419 Parsing instance 260\n",
      "2020/01/13 18:38:43.525525 Parsing instance 261\n",
      "2020/01/13 18:38:43.563112 Parsing instance 262\n",
      "2020/01/13 18:38:43.649048 Parsing instance 263\n",
      "2020/01/13 18:38:43.880316 Parsing instance 264\n",
      "2020/01/13 18:38:44.006310 Parsing instance 265\n",
      "2020/01/13 18:38:44.087173 Parsing instance 266\n",
      "2020/01/13 18:38:44.279141 Parsing instance 267\n",
      "2020/01/13 18:38:44.475761 Parsing instance 268\n",
      "2020/01/13 18:38:44.666886 Parsing instance 269\n",
      "2020/01/13 18:38:44.710044 Parsing instance 270\n",
      "2020/01/13 18:38:44.875941 Parsing instance 271\n",
      "2020/01/13 18:38:45.003213 Parsing instance 272\n",
      "2020/01/13 18:38:45.099562 Parsing instance 273\n",
      "2020/01/13 18:38:45.152572 Parsing instance 274\n",
      "2020/01/13 18:38:45.195202 Parsing instance 275\n",
      "2020/01/13 18:38:45.228523 Parsing instance 276\n",
      "2020/01/13 18:38:45.253945 Parsing instance 277\n",
      "2020/01/13 18:38:45.310604 Parsing instance 278\n",
      "2020/01/13 18:38:45.385362 Parsing instance 279\n",
      "2020/01/13 18:38:45.456272 Parsing instance 280\n",
      "2020/01/13 18:38:45.534946 Parsing instance 281\n",
      "2020/01/13 18:38:45.607490 Parsing instance 282\n",
      "2020/01/13 18:38:45.646999 Parsing instance 283\n",
      "2020/01/13 18:38:45.752668 Parsing instance 284\n",
      "2020/01/13 18:38:45.806495 Parsing instance 285\n",
      "2020/01/13 18:38:45.851750 Parsing instance 286\n",
      "2020/01/13 18:38:45.981108 Parsing instance 287\n",
      "2020/01/13 18:38:46.171713 Parsing instance 288\n",
      "2020/01/13 18:38:46.286712 Parsing instance 289\n",
      "2020/01/13 18:38:46.328940 Parsing instance 290\n",
      "2020/01/13 18:38:46.400558 Parsing instance 291\n",
      "2020/01/13 18:38:46.455979 Parsing instance 292\n",
      "2020/01/13 18:38:46.631924 Parsing instance 293\n",
      "2020/01/13 18:38:46.796270 Parsing instance 294\n",
      "2020/01/13 18:38:46.818182 Parsing instance 295\n",
      "2020/01/13 18:38:46.874616 Parsing instance 296\n",
      "2020/01/13 18:38:46.919699 Parsing instance 297\n",
      "2020/01/13 18:38:46.944487 Parsing instance 298\n",
      "2020/01/13 18:38:47.199696 Parsing instance 299\n",
      "2020/01/13 18:38:47.283747 Parsing instance 300\n",
      "2020/01/13 18:38:47.308531 Parsing instance 301\n",
      "2020/01/13 18:38:47.426378 Parsing instance 302\n",
      "2020/01/13 18:38:47.491064 Parsing instance 303\n",
      "2020/01/13 18:38:47.568724 Parsing instance 304\n",
      "2020/01/13 18:38:47.663938 Parsing instance 305\n",
      "2020/01/13 18:38:47.723733 Parsing instance 306\n",
      "2020/01/13 18:38:47.760646 Parsing instance 307\n",
      "2020/01/13 18:38:47.806495 Parsing instance 308\n",
      "2020/01/13 18:38:47.836675 Parsing instance 309\n",
      "2020/01/13 18:38:47.931867 Parsing instance 310\n",
      "2020/01/13 18:38:47.966678 Parsing instance 311\n",
      "2020/01/13 18:38:47.977795 Parsing instance 312\n",
      "2020/01/13 18:38:48.029774 Parsing instance 313\n",
      "2020/01/13 18:38:48.042859 Parsing instance 314\n",
      "2020/01/13 18:38:48.325086 Parsing instance 315\n",
      "2020/01/13 18:38:48.327186 Parsing instance 316\n",
      "2020/01/13 18:38:48.381432 Parsing instance 317\n",
      "2020/01/13 18:38:48.501294 Parsing instance 318\n",
      "2020/01/13 18:38:48.652523 Parsing instance 319\n",
      "2020/01/13 18:38:48.702557 Parsing instance 320\n",
      "2020/01/13 18:38:48.805642 Parsing instance 321\n",
      "2020/01/13 18:38:48.867165 Parsing instance 322\n",
      "2020/01/13 18:38:48.898389 Parsing instance 323\n",
      "2020/01/13 18:38:49.049488 Parsing instance 324\n",
      "2020/01/13 18:38:49.417879 Parsing instance 325\n",
      "2020/01/13 18:38:49.528183 Parsing instance 326\n",
      "2020/01/13 18:38:49.772323 Parsing instance 327\n",
      "2020/01/13 18:38:49.949379 Parsing instance 328\n",
      "2020/01/13 18:38:49.998716 Parsing instance 329\n",
      "2020/01/13 18:38:50.175046 Parsing instance 330\n",
      "2020/01/13 18:38:50.200651 Parsing instance 331\n",
      "2020/01/13 18:38:50.262648 Parsing instance 332\n",
      "2020/01/13 18:38:50.597793 Parsing instance 333\n",
      "2020/01/13 18:38:50.831090 Parsing instance 334\n",
      "2020/01/13 18:38:50.855943 Parsing instance 335\n",
      "2020/01/13 18:38:50.932558 Parsing instance 336\n",
      "2020/01/13 18:38:51.009476 Parsing instance 337\n",
      "2020/01/13 18:38:51.063837 Parsing instance 338\n",
      "2020/01/13 18:38:51.087546 Parsing instance 339\n",
      "2020/01/13 18:38:51.139276 Parsing instance 340\n",
      "2020/01/13 18:38:51.165301 Parsing instance 341\n",
      "2020/01/13 18:38:51.199745 Parsing instance 342\n",
      "2020/01/13 18:38:51.506421 Parsing instance 343\n",
      "2020/01/13 18:38:51.751140 Parsing instance 344\n",
      "2020/01/13 18:38:51.774640 Parsing instance 345\n",
      "2020/01/13 18:38:51.798351 Parsing instance 346\n",
      "2020/01/13 18:38:51.871464 Parsing instance 347\n",
      "2020/01/13 18:38:51.897627 Parsing instance 348\n",
      "2020/01/13 18:38:51.927790 Parsing instance 349\n",
      "2020/01/13 18:38:51.944960 Parsing instance 350\n",
      "2020/01/13 18:38:52.022856 Parsing instance 351\n",
      "2020/01/13 18:38:52.067342 Parsing instance 352\n",
      "2020/01/13 18:38:52.119958 Parsing instance 353\n",
      "2020/01/13 18:38:52.141170 Parsing instance 354\n",
      "2020/01/13 18:38:52.158674 Parsing instance 355\n",
      "2020/01/13 18:38:52.171469 Parsing instance 356\n",
      "2020/01/13 18:38:52.187791 Parsing instance 357\n",
      "2020/01/13 18:38:52.258269 Parsing instance 358\n",
      "2020/01/13 18:38:52.348665 Parsing instance 359\n",
      "2020/01/13 18:38:52.436953 Parsing instance 360\n",
      "2020/01/13 18:38:52.777974 Parsing instance 361\n",
      "2020/01/13 18:38:52.865869 Parsing instance 362\n",
      "2020/01/13 18:38:52.922303 Parsing instance 363\n",
      "2020/01/13 18:38:53.058201 Parsing instance 364\n",
      "2020/01/13 18:38:53.141323 Parsing instance 365\n",
      "2020/01/13 18:38:53.193685 Parsing instance 366\n",
      "2020/01/13 18:38:53.232876 Parsing instance 367\n",
      "2020/01/13 18:38:53.261801 Parsing instance 368\n",
      "2020/01/13 18:38:53.360194 Parsing instance 369\n",
      "2020/01/13 18:38:53.523348 Parsing instance 370\n",
      "2020/01/13 18:38:53.592269 Parsing instance 371\n",
      "2020/01/13 18:38:53.660311 Parsing instance 372\n",
      "2020/01/13 18:38:53.820357 Parsing instance 373\n",
      "2020/01/13 18:38:54.003762 Parsing instance 374\n",
      "2020/01/13 18:38:54.133428 Parsing instance 375\n",
      "2020/01/13 18:38:54.182890 Parsing instance 376\n",
      "2020/01/13 18:38:54.309407 Parsing instance 377\n",
      "2020/01/13 18:38:54.405314 Parsing instance 378\n",
      "2020/01/13 18:38:54.516524 Parsing instance 379\n",
      "2020/01/13 18:38:55.027648 Parsing instance 380\n",
      "2020/01/13 18:38:55.285973 Parsing instance 381\n",
      "2020/01/13 18:38:55.333197 Parsing instance 382\n",
      "2020/01/13 18:38:55.453964 Parsing instance 383\n",
      "2020/01/13 18:38:55.540336 Parsing instance 384\n",
      "2020/01/13 18:38:55.700363 Parsing instance 385\n",
      "2020/01/13 18:38:55.773158 Parsing instance 386\n",
      "2020/01/13 18:38:56.273848 Parsing instance 387\n",
      "2020/01/13 18:38:56.408167 Parsing instance 388\n",
      "2020/01/13 18:38:56.914588 Parsing instance 389\n",
      "2020/01/13 18:38:57.216353 Parsing instance 390\n",
      "2020/01/13 18:38:57.382755 Parsing instance 391\n",
      "2020/01/13 18:38:57.479865 Parsing instance 392\n",
      "2020/01/13 18:38:57.651872 Parsing instance 393\n",
      "2020/01/13 18:38:57.750037 Parsing instance 394\n",
      "2020/01/13 18:38:57.803282 Parsing instance 395\n",
      "2020/01/13 18:38:57.932170 Parsing instance 396\n",
      "2020/01/13 18:38:58.368222 Parsing instance 397\n",
      "2020/01/13 18:38:58.386248 Parsing instance 398\n",
      "2020/01/13 18:38:58.458355 Parsing instance 399\n",
      "2020/01/13 18:38:58.576628 Parsing instance 400\n",
      "2020/01/13 18:38:58.603487 Parsing instance 401\n",
      "2020/01/13 18:38:58.724673 Parsing instance 402\n",
      "2020/01/13 18:38:58.845757 Parsing instance 403\n",
      "2020/01/13 18:38:58.882501 Parsing instance 404\n",
      "2020/01/13 18:38:58.959508 Parsing instance 405\n",
      "2020/01/13 18:38:59.005389 Parsing instance 406\n",
      "2020/01/13 18:38:59.035797 Parsing instance 407\n",
      "2020/01/13 18:38:59.414763 Parsing instance 408\n",
      "2020/01/13 18:38:59.531904 Parsing instance 409\n",
      "2020/01/13 18:38:59.616879 Parsing instance 410\n",
      "2020/01/13 18:38:59.699496 Parsing instance 411\n",
      "2020/01/13 18:38:59.881629 Parsing instance 412\n",
      "2020/01/13 18:38:59.947468 Parsing instance 413\n",
      "2020/01/13 18:39:00.000562 Parsing instance 414\n",
      "2020/01/13 18:39:00.060735 Parsing instance 415\n",
      "2020/01/13 18:39:00.108490 Parsing instance 416\n",
      "2020/01/13 18:39:00.175860 Parsing instance 417\n",
      "2020/01/13 18:39:00.498147 Parsing instance 418\n",
      "2020/01/13 18:39:00.556471 Parsing instance 419\n",
      "2020/01/13 18:39:00.581221 Parsing instance 420\n",
      "2020/01/13 18:39:00.624370 Parsing instance 421\n",
      "2020/01/13 18:39:00.767998 Parsing instance 422\n",
      "2020/01/13 18:39:00.796395 Parsing instance 423\n",
      "2020/01/13 18:39:00.951758 Parsing instance 424\n",
      "2020/01/13 18:39:01.021134 Parsing instance 425\n",
      "2020/01/13 18:39:01.058644 Parsing instance 426\n",
      "2020/01/13 18:39:01.138082 Parsing instance 427\n",
      "2020/01/13 18:39:01.228668 Parsing instance 428\n",
      "2020/01/13 18:39:01.485440 Parsing instance 429\n",
      "2020/01/13 18:39:01.624750 Parsing instance 430\n",
      "2020/01/13 18:39:01.652720 Parsing instance 431\n",
      "2020/01/13 18:39:01.685155 Parsing instance 432\n",
      "2020/01/13 18:39:01.750592 Parsing instance 433\n",
      "2020/01/13 18:39:01.806384 Parsing instance 434\n",
      "2020/01/13 18:39:01.845686 Parsing instance 435\n",
      "2020/01/13 18:39:01.966794 Parsing instance 436\n",
      "2020/01/13 18:39:02.115123 Parsing instance 437\n",
      "2020/01/13 18:39:02.159689 Parsing instance 438\n",
      "2020/01/13 18:39:02.222766 Parsing instance 439\n",
      "2020/01/13 18:39:02.290765 Parsing instance 440\n",
      "2020/01/13 18:39:02.575879 Parsing instance 441\n",
      "2020/01/13 18:39:02.707221 Parsing instance 442\n",
      "2020/01/13 18:39:03.023551 Parsing instance 443\n",
      "2020/01/13 18:39:03.201434 Parsing instance 444\n",
      "2020/01/13 18:39:03.274887 Parsing instance 445\n",
      "2020/01/13 18:39:03.424911 Parsing instance 446\n",
      "2020/01/13 18:39:03.799302 Parsing instance 447\n",
      "2020/01/13 18:39:03.857977 Parsing instance 448\n",
      "2020/01/13 18:39:03.943590 Parsing instance 449\n",
      "2020/01/13 18:39:03.965904 Parsing instance 450\n",
      "2020/01/13 18:39:04.097126 Parsing instance 451\n",
      "2020/01/13 18:39:04.187105 Parsing instance 452\n",
      "2020/01/13 18:39:04.221759 Parsing instance 453\n",
      "2020/01/13 18:39:04.323159 Parsing instance 454\n",
      "2020/01/13 18:39:04.472483 Parsing instance 455\n",
      "2020/01/13 18:39:04.842171 Parsing instance 456\n",
      "2020/01/13 18:39:04.989217 Parsing instance 457\n",
      "2020/01/13 18:39:05.056210 Parsing instance 458\n",
      "2020/01/13 18:39:05.159727 Parsing instance 459\n",
      "2020/01/13 18:39:05.212569 Parsing instance 460\n",
      "2020/01/13 18:39:05.310956 Parsing instance 461\n",
      "2020/01/13 18:39:05.420115 Parsing instance 462\n",
      "2020/01/13 18:39:05.936620 Parsing instance 463\n",
      "2020/01/13 18:39:06.207415 Parsing instance 464\n",
      "2020/01/13 18:39:06.276746 Parsing instance 465\n",
      "2020/01/13 18:39:06.560181 Parsing instance 466\n",
      "2020/01/13 18:39:06.619350 Parsing instance 467\n",
      "2020/01/13 18:39:06.999512 Parsing instance 468\n",
      "2020/01/13 18:39:07.141234 Parsing instance 469\n",
      "2020/01/13 18:39:07.212096 Parsing instance 470\n",
      "2020/01/13 18:39:07.241803 Parsing instance 471\n",
      "2020/01/13 18:39:07.485208 Parsing instance 472\n",
      "2020/01/13 18:39:07.633135 Parsing instance 473\n",
      "2020/01/13 18:39:07.779873 Parsing instance 474\n",
      "2020/01/13 18:39:08.168190 Parsing instance 475\n",
      "2020/01/13 18:39:08.402893 Parsing instance 476\n",
      "2020/01/13 18:39:08.460181 Parsing instance 477\n",
      "2020/01/13 18:39:08.622349 Parsing instance 478\n",
      "2020/01/13 18:39:08.702420 Parsing instance 479\n",
      "2020/01/13 18:39:08.810652 Parsing instance 480\n",
      "2020/01/13 18:39:09.214461 Parsing instance 481\n",
      "2020/01/13 18:39:09.266383 Parsing instance 482\n",
      "2020/01/13 18:39:09.423436 Parsing instance 483\n",
      "2020/01/13 18:39:09.633777 Parsing instance 484\n",
      "2020/01/13 18:39:09.683475 Parsing instance 485\n",
      "2020/01/13 18:39:09.732189 Parsing instance 486\n",
      "2020/01/13 18:39:09.824484 Parsing instance 487\n",
      "2020/01/13 18:39:09.873238 Parsing instance 488\n",
      "2020/01/13 18:39:09.959577 Parsing instance 489\n",
      "2020/01/13 18:39:09.988281 Parsing instance 490\n",
      "2020/01/13 18:39:10.268770 Parsing instance 491\n",
      "2020/01/13 18:39:10.406894 Parsing instance 492\n",
      "2020/01/13 18:39:10.502699 Parsing instance 493\n",
      "2020/01/13 18:39:10.600020 Parsing instance 494\n",
      "2020/01/13 18:39:10.668364 Parsing instance 495\n",
      "2020/01/13 18:39:10.781478 Parsing instance 496\n",
      "2020/01/13 18:39:10.851946 Parsing instance 497\n",
      "2020/01/13 18:39:11.038180 Parsing instance 498\n",
      "2020/01/13 18:39:11.094927 Parsing instance 499\n",
      "2020/01/13 18:39:11.208427 Parsing instance 500\n",
      "2020/01/13 18:39:11.437870 Parsing instance 501\n",
      "2020/01/13 18:39:11.545130 Parsing instance 502\n",
      "2020/01/13 18:39:11.655353 Parsing instance 503\n",
      "2020/01/13 18:39:11.792742 Parsing instance 504\n",
      "2020/01/13 18:39:11.848659 Parsing instance 505\n",
      "2020/01/13 18:39:11.970488 Parsing instance 506\n",
      "2020/01/13 18:39:12.065707 Parsing instance 507\n",
      "2020/01/13 18:39:12.121258 Parsing instance 508\n",
      "2020/01/13 18:39:12.190901 Parsing instance 509\n",
      "2020/01/13 18:39:12.235306 Parsing instance 510\n",
      "2020/01/13 18:39:12.476367 Parsing instance 511\n",
      "2020/01/13 18:39:12.570130 Parsing instance 512\n",
      "2020/01/13 18:39:12.705384 Parsing instance 513\n",
      "2020/01/13 18:39:12.738668 Parsing instance 514\n",
      "2020/01/13 18:39:12.836286 Parsing instance 515\n",
      "2020/01/13 18:39:12.855952 Parsing instance 516\n",
      "2020/01/13 18:39:12.899193 Parsing instance 517\n",
      "2020/01/13 18:39:12.991641 Parsing instance 518\n",
      "2020/01/13 18:39:13.119177 Parsing instance 519\n",
      "2020/01/13 18:39:13.173597 Parsing instance 520\n",
      "2020/01/13 18:39:13.228058 Parsing instance 521\n",
      "2020/01/13 18:39:13.254163 Parsing instance 522\n",
      "2020/01/13 18:39:13.298541 Parsing instance 523\n",
      "2020/01/13 18:39:13.542293 Parsing instance 524\n",
      "2020/01/13 18:39:14.051062 Parsing instance 525\n",
      "2020/01/13 18:39:14.097834 Parsing instance 526\n",
      "2020/01/13 18:39:14.185855 Parsing instance 527\n",
      "2020/01/13 18:39:14.327527 Parsing instance 528\n",
      "2020/01/13 18:39:14.422545 Parsing instance 529\n",
      "2020/01/13 18:39:14.765952 Parsing instance 530\n",
      "2020/01/13 18:39:14.804630 Parsing instance 531\n",
      "2020/01/13 18:39:14.863964 Parsing instance 532\n",
      "2020/01/13 18:39:14.907520 Parsing instance 533\n",
      "2020/01/13 18:39:14.970154 Parsing instance 534\n",
      "2020/01/13 18:39:14.994961 Parsing instance 535\n",
      "2020/01/13 18:39:15.086591 Parsing instance 536\n",
      "2020/01/13 18:39:15.125142 Parsing instance 537\n",
      "2020/01/13 18:39:15.214357 Parsing instance 538\n",
      "2020/01/13 18:39:15.519466 Parsing instance 539\n",
      "2020/01/13 18:39:16.000257 Parsing instance 540\n",
      "2020/01/13 18:39:16.189537 Parsing instance 541\n",
      "2020/01/13 18:39:16.444442 Parsing instance 542\n",
      "2020/01/13 18:39:16.582887 Parsing instance 543\n",
      "2020/01/13 18:39:16.673884 Parsing instance 544\n",
      "2020/01/13 18:39:16.934358 Parsing instance 545\n",
      "2020/01/13 18:39:17.196455 Parsing instance 546\n",
      "2020/01/13 18:39:17.258605 Parsing instance 547\n",
      "2020/01/13 18:39:17.359063 Parsing instance 548\n",
      "2020/01/13 18:39:17.410625 Parsing instance 549\n",
      "2020/01/13 18:39:17.457343 Parsing instance 550\n",
      "2020/01/13 18:39:17.526444 Parsing instance 551\n",
      "2020/01/13 18:39:17.615531 Parsing instance 552\n",
      "2020/01/13 18:39:17.698499 Parsing instance 553\n",
      "2020/01/13 18:39:17.750336 Parsing instance 554\n",
      "2020/01/13 18:39:18.048029 Parsing instance 555\n",
      "2020/01/13 18:39:18.182356 Parsing instance 556\n",
      "2020/01/13 18:39:18.352309 Parsing instance 557\n",
      "2020/01/13 18:39:18.462553 Parsing instance 558\n",
      "2020/01/13 18:39:18.719856 Parsing instance 559\n",
      "2020/01/13 18:39:18.799083 Parsing instance 560\n",
      "2020/01/13 18:39:18.941071 Parsing instance 561\n",
      "2020/01/13 18:39:19.101010 Parsing instance 562\n",
      "2020/01/13 18:39:19.542334 Parsing instance 563\n",
      "2020/01/13 18:39:19.576097 Parsing instance 564\n",
      "2020/01/13 18:39:19.629564 Parsing instance 565\n",
      "2020/01/13 18:39:19.667015 Parsing instance 566\n",
      "2020/01/13 18:39:19.696787 Parsing instance 567\n",
      "2020/01/13 18:39:19.856795 Parsing instance 568\n",
      "2020/01/13 18:39:19.913800 Parsing instance 569\n",
      "2020/01/13 18:39:20.110774 Parsing instance 570\n",
      "2020/01/13 18:39:20.363270 Parsing instance 571\n",
      "2020/01/13 18:39:20.621431 Parsing instance 572\n",
      "2020/01/13 18:39:20.636120 Parsing instance 573\n",
      "2020/01/13 18:39:20.713346 Parsing instance 574\n",
      "2020/01/13 18:39:20.797340 Parsing instance 575\n",
      "2020/01/13 18:39:20.941691 Parsing instance 576\n",
      "2020/01/13 18:39:21.394667 Parsing instance 577\n",
      "2020/01/13 18:39:21.483136 Parsing instance 578\n",
      "2020/01/13 18:39:21.549066 Parsing instance 579\n",
      "2020/01/13 18:39:21.756272 Parsing instance 580\n",
      "2020/01/13 18:39:21.783731 Parsing instance 581\n",
      "2020/01/13 18:39:21.873407 Parsing instance 582\n",
      "2020/01/13 18:39:21.958606 Parsing instance 583\n",
      "2020/01/13 18:39:22.069458 Parsing instance 584\n",
      "2020/01/13 18:39:22.351032 Parsing instance 585\n",
      "2020/01/13 18:39:22.446944 Parsing instance 586\n",
      "2020/01/13 18:39:22.579749 Parsing instance 587\n",
      "2020/01/13 18:39:22.746130 Parsing instance 588\n",
      "2020/01/13 18:39:22.887236 Parsing instance 589\n",
      "2020/01/13 18:39:22.944821 Parsing instance 590\n",
      "2020/01/13 18:39:23.077010 Parsing instance 591\n",
      "2020/01/13 18:39:23.081425 Parsing instance 592\n",
      "2020/01/13 18:39:23.147519 Parsing instance 593\n",
      "2020/01/13 18:39:23.489124 Parsing instance 594\n",
      "2020/01/13 18:39:23.602099 Parsing instance 595\n",
      "2020/01/13 18:39:23.739366 Parsing instance 596\n",
      "2020/01/13 18:39:23.793317 Parsing instance 597\n",
      "2020/01/13 18:39:23.809909 Parsing instance 598\n",
      "2020/01/13 18:39:23.975619 Parsing instance 599\n",
      "2020/01/13 18:39:24.077382 Parsing instance 600\n",
      "2020/01/13 18:39:24.182421 Parsing instance 601\n",
      "2020/01/13 18:39:24.258422 Parsing instance 602\n",
      "2020/01/13 18:39:24.593040 Parsing instance 603\n",
      "2020/01/13 18:39:24.671859 Parsing instance 604\n",
      "2020/01/13 18:39:24.755314 Parsing instance 605\n",
      "2020/01/13 18:39:24.836204 Parsing instance 606\n",
      "2020/01/13 18:39:24.856355 Parsing instance 607\n",
      "2020/01/13 18:39:25.003322 Parsing instance 608\n",
      "2020/01/13 18:39:25.044989 Parsing instance 609\n",
      "2020/01/13 18:39:25.085268 Parsing instance 610\n",
      "2020/01/13 18:39:25.192443 Parsing instance 611\n",
      "2020/01/13 18:39:25.278469 Parsing instance 612\n",
      "2020/01/13 18:39:25.383437 Parsing instance 613\n",
      "2020/01/13 18:39:25.473552 Parsing instance 614\n",
      "2020/01/13 18:39:25.875309 Parsing instance 615\n",
      "2020/01/13 18:39:26.022334 Parsing instance 616\n",
      "2020/01/13 18:39:26.094862 Parsing instance 617\n",
      "2020/01/13 18:39:26.187835 Parsing instance 618\n",
      "2020/01/13 18:39:26.217240 Parsing instance 619\n",
      "2020/01/13 18:39:26.322470 Parsing instance 620\n",
      "2020/01/13 18:39:26.367081 Parsing instance 621\n",
      "2020/01/13 18:39:26.518464 Parsing instance 622\n",
      "2020/01/13 18:39:26.583588 Parsing instance 623\n",
      "2020/01/13 18:39:26.625977 Parsing instance 624\n",
      "2020/01/13 18:39:26.931988 Parsing instance 625\n",
      "2020/01/13 18:39:26.971239 Parsing instance 626\n",
      "2020/01/13 18:39:27.030307 Parsing instance 627\n",
      "2020/01/13 18:39:27.092747 Parsing instance 628\n",
      "2020/01/13 18:39:27.158341 Parsing instance 629\n",
      "2020/01/13 18:39:27.276697 Parsing instance 630\n",
      "2020/01/13 18:39:27.378291 Parsing instance 631\n",
      "2020/01/13 18:39:27.390389 Parsing instance 632\n",
      "2020/01/13 18:39:27.483009 Parsing instance 633\n",
      "2020/01/13 18:39:27.551400 Parsing instance 634\n",
      "2020/01/13 18:39:27.687935 Parsing instance 635\n",
      "2020/01/13 18:39:27.732745 Parsing instance 636\n",
      "2020/01/13 18:39:28.142569 Parsing instance 637\n",
      "2020/01/13 18:39:28.180387 Parsing instance 638\n",
      "2020/01/13 18:39:28.259900 Parsing instance 639\n",
      "2020/01/13 18:39:28.285881 Parsing instance 640\n",
      "2020/01/13 18:39:28.340298 Parsing instance 641\n",
      "2020/01/13 18:39:28.471878 Parsing instance 642\n",
      "2020/01/13 18:39:28.548196 Parsing instance 643\n",
      "2020/01/13 18:39:28.702493 Parsing instance 644\n",
      "2020/01/13 18:39:28.758773 Parsing instance 645\n",
      "2020/01/13 18:39:28.846859 Parsing instance 646\n",
      "2020/01/13 18:39:28.944696 Parsing instance 647\n",
      "2020/01/13 18:39:28.987900 Parsing instance 648\n",
      "2020/01/13 18:39:29.322951 Parsing instance 649\n",
      "2020/01/13 18:39:29.490173 Parsing instance 650\n",
      "2020/01/13 18:39:29.497662 Parsing instance 651\n",
      "2020/01/13 18:39:29.599620 Parsing instance 652\n",
      "2020/01/13 18:39:29.704826 Parsing instance 653\n",
      "2020/01/13 18:39:29.815415 Parsing instance 654\n",
      "2020/01/13 18:39:29.838736 Parsing instance 655\n",
      "2020/01/13 18:39:29.875581 Parsing instance 656\n",
      "2020/01/13 18:39:29.980521 Parsing instance 657\n",
      "2020/01/13 18:39:30.074257 Parsing instance 658\n",
      "2020/01/13 18:39:30.357128 Parsing instance 659\n",
      "2020/01/13 18:39:30.431907 Parsing instance 660\n",
      "2020/01/13 18:39:30.572869 Parsing instance 661\n",
      "2020/01/13 18:39:30.680204 Parsing instance 662\n",
      "2020/01/13 18:39:30.752014 Parsing instance 663\n",
      "2020/01/13 18:39:30.962689 Parsing instance 664\n",
      "2020/01/13 18:39:31.068527 Parsing instance 665\n",
      "2020/01/13 18:39:31.122494 Parsing instance 666\n",
      "2020/01/13 18:39:31.428138 Parsing instance 667\n",
      "2020/01/13 18:39:31.541719 Parsing instance 668\n",
      "2020/01/13 18:39:31.622840 Parsing instance 669\n",
      "2020/01/13 18:39:31.666906 Parsing instance 670\n",
      "2020/01/13 18:39:31.731931 Parsing instance 671\n",
      "2020/01/13 18:39:31.819734 Parsing instance 672\n",
      "2020/01/13 18:39:31.903937 Parsing instance 673\n",
      "2020/01/13 18:39:31.935707 Parsing instance 674\n",
      "2020/01/13 18:39:31.979854 Parsing instance 675\n",
      "2020/01/13 18:39:32.027910 Parsing instance 676\n",
      "2020/01/13 18:39:32.051678 Parsing instance 677\n",
      "2020/01/13 18:39:32.172122 Parsing instance 678\n",
      "2020/01/13 18:39:32.204917 Parsing instance 679\n",
      "2020/01/13 18:39:32.291711 Parsing instance 680\n",
      "2020/01/13 18:39:32.332574 Parsing instance 681\n",
      "2020/01/13 18:39:32.645510 Parsing instance 682\n",
      "2020/01/13 18:39:32.782934 Parsing instance 683\n",
      "2020/01/13 18:39:32.830515 Parsing instance 684\n",
      "2020/01/13 18:39:32.874315 Parsing instance 685\n",
      "2020/01/13 18:39:32.965452 Parsing instance 686\n",
      "2020/01/13 18:39:32.988236 Parsing instance 687\n",
      "2020/01/13 18:39:33.056529 Parsing instance 688\n",
      "2020/01/13 18:39:33.222864 Parsing instance 689\n",
      "2020/01/13 18:39:33.336729 Parsing instance 690\n",
      "2020/01/13 18:39:33.428310 Parsing instance 691\n",
      "2020/01/13 18:39:33.487947 Parsing instance 692\n",
      "2020/01/13 18:39:33.760957 Parsing instance 693\n",
      "2020/01/13 18:39:33.830788 Parsing instance 694\n",
      "2020/01/13 18:39:33.981447 Parsing instance 695\n",
      "2020/01/13 18:39:34.055635 Parsing instance 696\n",
      "2020/01/13 18:39:34.253042 Parsing instance 697\n",
      "2020/01/13 18:39:34.371058 Parsing instance 698\n",
      "2020/01/13 18:39:34.448186 Parsing instance 699\n",
      "2020/01/13 18:39:34.638543 Parsing instance 700\n",
      "2020/01/13 18:39:34.881038 Parsing instance 701\n",
      "2020/01/13 18:39:34.997146 Parsing instance 702\n",
      "2020/01/13 18:39:35.092883 Parsing instance 703\n",
      "2020/01/13 18:39:35.115480 Parsing instance 704\n",
      "2020/01/13 18:39:35.174593 Parsing instance 705\n",
      "2020/01/13 18:39:35.201693 PARSE Total Time: 1m18.531171291s\n",
      "2020/01/13 18:39:35.201725 Converting 706 to conll\n",
      "2020/01/13 18:39:35.201732 Writing to output file\n",
      "2020/01/13 18:39:35.268610 Wrote 706 in conll format to final_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.conll\n",
      "2020/01/13 18:39:35.268629 Writing to segmentation file\n",
      "2020/01/13 18:39:35.344655 Wrote 706 in segmentation format to final_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.seg\n",
      "2020/01/13 18:39:35.344669 Writing to mapping file\n",
      "2020/01/13 18:39:35.671546 Wrote 706 in mapping format to final_setup/pruned/yap_output/test.multitok.no_char.no_word.46_seed.map\n",
      "2020/01/13 18:39:35.671567 Writing to gold segmentation file\n"
     ]
    }
   ],
   "source": [
    "pruned_folder = 'final_setup/pruned/lattices'\n",
    "yap_output_folder = 'final_setup/pruned/yap_output'\n",
    "\n",
    "for file in os.scandir(pruned_folder):\n",
    "    #ds, unit, arch, w_embed, seed_num, _\n",
    "    base_out = '.'.join(file.name.split('.')[:-1])\n",
    "    seg_out, map_out, conll_out = [os.path.join(yap_output_folder, base_out+suf)\n",
    "                                   for suf in ['.seg', '.map', '.conll']]\n",
    "    if not os.path.exists(seg_out):\n",
    "        !{yap_path} joint -in {file.path} -os {seg_out} -om {map_out} -oc {conll_out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input files for NCRF\n",
    "with dummy O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "txt_folder = 'final_setup/pruned/txt'\n",
    "txt_map = defaultdict(list)\n",
    "for file in os.scandir(yap_output_folder):\n",
    "    if file.name.endswith('conll') and file.name!='.conll':\n",
    "        ds, unit, arch, w_embed, seed_num, _ = file.name.split('.')\n",
    "        out_name = '.'.join(file.name.split('.')[:-1])+'.txt'\n",
    "        out_path = os.path.join(txt_folder, out_name)\n",
    "        txt_map[(arch, w_embed)].append((ds, out_path))\n",
    "        with open(out_path, 'w') as of:\n",
    "            for line in open(file.path, 'r'):\n",
    "                if line=='\\n':\n",
    "                    of.write('\\n')\n",
    "                else:\n",
    "                    w = line.split('\\t')[1]\n",
    "                    of.write(w+' O\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs for NCRF decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'final_setup/decode_output'\n",
    "decode_conf_folder = 'final_setup/decode_conf'\n",
    "\n",
    "params = { 'status': 'decode' }\n",
    "\n",
    "erdf = pd.read_pickle('final_setup/erdf.pkl')\n",
    "\n",
    "for i, row in erdf[erdf.unit=='morph'].iterrows():\n",
    "    unit = row['unit']\n",
    "    for ds, set_path in txt_map[(row.arch, row.w_embed)]:\n",
    "        name = 'morph_'+ds+'_pruned'\n",
    "        row_par = params.copy()\n",
    "        row_par['load_model_dir'] = os.path.join(models_folder, row['model_file_name'])\n",
    "        row_par['dset_dir'] = os.path.join(models_folder, row['dset_file_name'])\n",
    "        row_par['decode_dir'] = os.path.join(output_folder, name+'.'+row['model_base_name']+'.bmes')\n",
    "        row_par['raw_dir'] = set_path\n",
    "        \n",
    "        conf_path = os.path.join(decode_conf_folder, name+'.'+row['model_base_name']+'.decode.conf')\n",
    "        if not os.path.exists(conf_path):\n",
    "            with open(conf_path, 'w', encoding='utf8') as of:\n",
    "                for k, v in row_par.items():\n",
    "                    of.write(k+'='+str(v)+'\\n')        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate segmentation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = spdf[spdf.set=='dev']\n",
    "test_gold = spdf[spdf.set=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "      .size().reset_index().rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (dev_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "dg['ner'] = tempn\n",
    "tg = (test_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index()\n",
    "      .rename(columns={0: 'morpheme_count'}))\n",
    "tempn = (test_gold.groupby(['sent_id', 'token_id', 'token_str'])\n",
    "         .biose_layer0.apply(lambda x: (x!='O').any()).reset_index()[['biose_layer0']])\n",
    "tg['ner'] = tempn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>w_embed</th>\n",
       "      <th>model_base_name</th>\n",
       "      <th>pred_set</th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>char_cnn</td>\n",
       "      <td>ft_yap</td>\n",
       "      <td>multitok.char_cnn.ft_yap.44_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.962607</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>0.963122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>char_cnn</td>\n",
       "      <td>ft_yap</td>\n",
       "      <td>multitok.char_cnn.ft_yap.44_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.956019</td>\n",
       "      <td>0.937417</td>\n",
       "      <td>0.958532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char_cnn</td>\n",
       "      <td>glv_yap</td>\n",
       "      <td>multitok.char_cnn.glv_yap.44_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.962021</td>\n",
       "      <td>0.953012</td>\n",
       "      <td>0.962992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>char_cnn</td>\n",
       "      <td>glv_yap</td>\n",
       "      <td>multitok.char_cnn.glv_yap.44_seed</td>\n",
       "      <td>test</td>\n",
       "      <td>0.957207</td>\n",
       "      <td>0.944075</td>\n",
       "      <td>0.958982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>char_cnn</td>\n",
       "      <td>glv_tok</td>\n",
       "      <td>multitok.char_cnn.glv_tok.44_seed</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.968585</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>0.968835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       arch  w_embed                    model_base_name pred_set       all  \\\n",
       "0  char_cnn   ft_yap   multitok.char_cnn.ft_yap.44_seed      dev  0.962607   \n",
       "1  char_cnn   ft_yap   multitok.char_cnn.ft_yap.44_seed     test  0.956019   \n",
       "2  char_cnn  glv_yap  multitok.char_cnn.glv_yap.44_seed      dev  0.962021   \n",
       "3  char_cnn  glv_yap  multitok.char_cnn.glv_yap.44_seed     test  0.957207   \n",
       "4  char_cnn  glv_tok  multitok.char_cnn.glv_tok.44_seed      dev  0.968585   \n",
       "\n",
       "        ner       non  \n",
       "0  0.957831  0.963122  \n",
       "1  0.937417  0.958532  \n",
       "2  0.953012  0.962992  \n",
       "3  0.944075  0.958982  \n",
       "4  0.966265  0.968835  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores = []\n",
    "for i, row in erdf[erdf.unit=='multitok'].iterrows():\n",
    "    dev_path = os.path.join(output_folder, \n",
    "                            'token_dev.'+row.model_base_name+'.bmes')\n",
    "    dev_bc = get_biose_count(dev_path, sent_id_shift=1)\n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'dev'}\n",
    "    sc['all'] = accuracy_score(dev_bc.biose_count, dg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(dev_bc[dg.ner].biose_count, dg[dg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(dev_bc[~dg.ner].biose_count, dg[~dg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    test_path = os.path.join(output_folder, \n",
    "                             'token_test.'+row.model_base_name+'.bmes')\n",
    "    test_bc = get_biose_count(test_path, sent_id_shift=5439)   \n",
    "    sc = { 'arch': row.arch,\n",
    "           'w_embed': row.w_embed,\n",
    "           'model_base_name': row.model_base_name,\n",
    "           'pred_set': 'test'}\n",
    "    sc['all'] = accuracy_score(test_bc.biose_count, tg.morpheme_count)\n",
    "    sc['ner'] = accuracy_score(test_bc[tg.ner].biose_count, tg[tg.ner].morpheme_count)\n",
    "    sc['non'] = accuracy_score(test_bc[~tg.ner].biose_count, tg[~tg.ner].morpheme_count)\n",
    "    acc_scores.append(sc)\n",
    "    \n",
    "acc_scores = pd.DataFrame(acc_scores)\n",
    "acc_scores.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_scores.to_pickle('final_setup/acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = pd.read_pickle('final_setup/acc_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">char_cnn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">char_lstm</th>\n",
       "      <th colspan=\"3\" halign=\"left\">no_char</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "      <th>all</th>\n",
       "      <th>ner</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_set</th>\n",
       "      <th>w_embed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dev</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.36</td>\n",
       "      <td>96.92</td>\n",
       "      <td>97.41</td>\n",
       "      <td>97.32</td>\n",
       "      <td>97.07</td>\n",
       "      <td>97.35</td>\n",
       "      <td>96.49</td>\n",
       "      <td>95.99</td>\n",
       "      <td>96.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_oov_yap</th>\n",
       "      <td>96.47</td>\n",
       "      <td>95.93</td>\n",
       "      <td>96.53</td>\n",
       "      <td>96.36</td>\n",
       "      <td>95.90</td>\n",
       "      <td>96.41</td>\n",
       "      <td>93.27</td>\n",
       "      <td>90.98</td>\n",
       "      <td>93.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_tok</th>\n",
       "      <td>97.21</td>\n",
       "      <td>96.61</td>\n",
       "      <td>97.28</td>\n",
       "      <td>97.16</td>\n",
       "      <td>96.41</td>\n",
       "      <td>97.24</td>\n",
       "      <td>95.89</td>\n",
       "      <td>94.92</td>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_yap</th>\n",
       "      <td>96.33</td>\n",
       "      <td>95.58</td>\n",
       "      <td>96.41</td>\n",
       "      <td>96.31</td>\n",
       "      <td>95.27</td>\n",
       "      <td>96.42</td>\n",
       "      <td>94.88</td>\n",
       "      <td>90.25</td>\n",
       "      <td>95.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glv_tok</th>\n",
       "      <td>96.86</td>\n",
       "      <td>96.60</td>\n",
       "      <td>96.89</td>\n",
       "      <td>96.81</td>\n",
       "      <td>96.20</td>\n",
       "      <td>96.88</td>\n",
       "      <td>93.83</td>\n",
       "      <td>91.77</td>\n",
       "      <td>94.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glv_yap</th>\n",
       "      <td>96.19</td>\n",
       "      <td>94.86</td>\n",
       "      <td>96.34</td>\n",
       "      <td>96.18</td>\n",
       "      <td>94.96</td>\n",
       "      <td>96.31</td>\n",
       "      <td>94.32</td>\n",
       "      <td>88.70</td>\n",
       "      <td>94.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_word</th>\n",
       "      <td>94.06</td>\n",
       "      <td>92.60</td>\n",
       "      <td>94.21</td>\n",
       "      <td>94.17</td>\n",
       "      <td>92.58</td>\n",
       "      <td>94.34</td>\n",
       "      <td>87.25</td>\n",
       "      <td>79.53</td>\n",
       "      <td>88.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">test</th>\n",
       "      <th>ft_oov_tok</th>\n",
       "      <td>97.18</td>\n",
       "      <td>96.64</td>\n",
       "      <td>97.26</td>\n",
       "      <td>97.17</td>\n",
       "      <td>96.44</td>\n",
       "      <td>97.26</td>\n",
       "      <td>96.07</td>\n",
       "      <td>95.69</td>\n",
       "      <td>96.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_oov_yap</th>\n",
       "      <td>96.17</td>\n",
       "      <td>94.88</td>\n",
       "      <td>96.35</td>\n",
       "      <td>96.04</td>\n",
       "      <td>94.66</td>\n",
       "      <td>96.22</td>\n",
       "      <td>92.98</td>\n",
       "      <td>90.01</td>\n",
       "      <td>93.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_tok</th>\n",
       "      <td>97.04</td>\n",
       "      <td>95.92</td>\n",
       "      <td>97.19</td>\n",
       "      <td>96.88</td>\n",
       "      <td>95.58</td>\n",
       "      <td>97.05</td>\n",
       "      <td>95.19</td>\n",
       "      <td>93.08</td>\n",
       "      <td>95.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft_yap</th>\n",
       "      <td>95.77</td>\n",
       "      <td>93.95</td>\n",
       "      <td>96.02</td>\n",
       "      <td>95.66</td>\n",
       "      <td>93.07</td>\n",
       "      <td>96.01</td>\n",
       "      <td>93.81</td>\n",
       "      <td>88.30</td>\n",
       "      <td>94.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glv_tok</th>\n",
       "      <td>96.53</td>\n",
       "      <td>95.72</td>\n",
       "      <td>96.64</td>\n",
       "      <td>96.46</td>\n",
       "      <td>95.45</td>\n",
       "      <td>96.59</td>\n",
       "      <td>93.14</td>\n",
       "      <td>91.70</td>\n",
       "      <td>93.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glv_yap</th>\n",
       "      <td>95.73</td>\n",
       "      <td>94.30</td>\n",
       "      <td>95.92</td>\n",
       "      <td>95.65</td>\n",
       "      <td>93.77</td>\n",
       "      <td>95.90</td>\n",
       "      <td>93.68</td>\n",
       "      <td>89.30</td>\n",
       "      <td>94.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_word</th>\n",
       "      <td>93.59</td>\n",
       "      <td>90.86</td>\n",
       "      <td>93.96</td>\n",
       "      <td>93.65</td>\n",
       "      <td>90.66</td>\n",
       "      <td>94.05</td>\n",
       "      <td>86.09</td>\n",
       "      <td>81.37</td>\n",
       "      <td>86.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "arch                char_cnn               char_lstm               no_char  \\\n",
       "                         all    ner    non       all    ner    non     all   \n",
       "pred_set w_embed                                                             \n",
       "dev      ft_oov_tok    97.36  96.92  97.41     97.32  97.07  97.35   96.49   \n",
       "         ft_oov_yap    96.47  95.93  96.53     96.36  95.90  96.41   93.27   \n",
       "         ft_tok        97.21  96.61  97.28     97.16  96.41  97.24   95.89   \n",
       "         ft_yap        96.33  95.58  96.41     96.31  95.27  96.42   94.88   \n",
       "         glv_tok       96.86  96.60  96.89     96.81  96.20  96.88   93.83   \n",
       "         glv_yap       96.19  94.86  96.34     96.18  94.96  96.31   94.32   \n",
       "         no_word       94.06  92.60  94.21     94.17  92.58  94.34   87.25   \n",
       "test     ft_oov_tok    97.18  96.64  97.26     97.17  96.44  97.26   96.07   \n",
       "         ft_oov_yap    96.17  94.88  96.35     96.04  94.66  96.22   92.98   \n",
       "         ft_tok        97.04  95.92  97.19     96.88  95.58  97.05   95.19   \n",
       "         ft_yap        95.77  93.95  96.02     95.66  93.07  96.01   93.81   \n",
       "         glv_tok       96.53  95.72  96.64     96.46  95.45  96.59   93.14   \n",
       "         glv_yap       95.73  94.30  95.92     95.65  93.77  95.90   93.68   \n",
       "         no_word       93.59  90.86  93.96     93.65  90.66  94.05   86.09   \n",
       "\n",
       "arch                               \n",
       "                       ner    non  \n",
       "pred_set w_embed                   \n",
       "dev      ft_oov_tok  95.99  96.54  \n",
       "         ft_oov_yap  90.98  93.52  \n",
       "         ft_tok      94.92  96.00  \n",
       "         ft_yap      90.25  95.38  \n",
       "         glv_tok     91.77  94.05  \n",
       "         glv_yap     88.70  94.93  \n",
       "         no_word     79.53  88.08  \n",
       "test     ft_oov_tok  95.69  96.13  \n",
       "         ft_oov_yap  90.01  93.39  \n",
       "         ft_tok      93.08  95.47  \n",
       "         ft_yap      88.30  94.55  \n",
       "         glv_tok     91.70  93.34  \n",
       "         glv_yap     89.30  94.28  \n",
       "         no_word     81.37  86.73  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = acc_scores.groupby(['pred_set','w_embed', 'arch']).mean().mul(100).round(2).unstack()\n",
    "x.columns = x.columns.reorder_levels([1,0])\n",
    "x.sort_index(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, dg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313253012048193"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[dg.ner].morpheme_count, dg[dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628619659784443"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~dg.ner].morpheme_count, dg[~dg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bclm.get_token_df(bclm.read_yap_output(treebank_set='test'), fields=['upostag'])\n",
    "yt['morpheme_count'] = yt.upostag.apply(lambda x: len(x.split('^')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547507726444251"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt.morpheme_count, tg.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961384820239681"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[tg.ner].morpheme_count, tg[tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626697850139426"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt[~tg.ner].morpheme_count, tg[~tg.ner].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/01/13 14:01:11.393933 GOMAXPROCS:\t40\n",
      "2020/01/13 14:01:11.394105 \n",
      "2020/01/13 14:01:11.413745 *** CONFIGURATION ***\n",
      "2020/01/13 14:01:11.413777 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/13 14:01:11.413839 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/13 14:01:11.413876 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/13 14:01:11.413893 Iterations:\t\t1\n",
      "2020/01/13 14:01:11.413914 Beam Size:\t\t64\n",
      "2020/01/13 14:01:11.413932 Beam Concurrent:\ttrue\n",
      "2020/01/13 14:01:11.413949 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/13 14:01:11.413965 Use Lemmas:\t\tfalse\n",
      "2020/01/13 14:01:11.413983 Use POP:\t\ttrue\n",
      "2020/01/13 14:01:11.414002 Infuse Gold Dev:\tfalse\n",
      "2020/01/13 14:01:11.414020 Limit (thousands):\t0\n",
      "2020/01/13 14:01:11.414035 Use CoNLL-U:\t\tfalse\n",
      "2020/01/13 14:01:11.414053 \n",
      "2020/01/13 14:01:11.414062 Features File:\tjointzeager.yaml\n",
      "2020/01/13 14:01:11.429420 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/13 14:01:11.430554 \n",
      "2020/01/13 14:01:11.430578 Data\n",
      "2020/01/13 14:01:11.430589 Test file  (ambig.  lattice):\tfinal_setup/pruned/dev_pruned_non_o_keep.lattices\n",
      "2020/01/13 14:01:11.430912 Out (disamb.) file:\t\t\tfinal_setup/pruned/dev_pruned_non_o_keep.conll\n",
      "2020/01/13 14:01:11.430945 Out (segmt.) file:\t\t\tfinal_setup/pruned/dev_pruned_non_o_keep.seg\n",
      "2020/01/13 14:01:11.430986 Out (mapping.) file:\t\t\tfinal_setup/pruned/dev_pruned_non_o_keep.map\n",
      "2020/01/13 14:01:11.441494 \n",
      "2020/01/13 14:01:11.441524 Setup enumerations\n",
      "2020/01/13 14:01:11.441656 ETrans Len is 96\n",
      "2020/01/13 14:01:11.441894 \n",
      "2020/01/13 14:01:11.441908 Loading features\n",
      "2020/01/13 14:01:11.451009 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/13 14:01:11.451093 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/13 14:01:11.451198 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/13 14:01:11.451274 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/13 14:01:11.451298 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/13 14:01:11.451410 Loading POP transition dependent feature group POP\n",
      "2020/01/13 14:01:11.451446 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/13 14:01:11.451478 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/13 14:01:11.451936 \n",
      "2020/01/13 14:01:11.451976 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/13 14:01:11.451989 \n",
      "2020/01/13 14:01:11.452004 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/13 14:01:38.100104 Loaded model\n",
      "2020/01/13 14:01:38.100169 \n",
      "2020/01/13 14:01:38.100175 *** PARSING ***\n",
      "2020/01/13 14:01:38.100180 Parsing test\n",
      "2020/01/13 14:01:38.100213 Reading ambiguous lattices from final_setup/pruned/dev_pruned_non_o_keep.lattices\n",
      "2020/01/13 14:01:38.209944 Read 500 ambiguous lattices from final_setup/pruned/dev_pruned_non_o_keep.lattices\n",
      "2020/01/13 14:01:38.209973 Converting lattice format to internal structure\n",
      "2020/01/13 14:01:39.023991 Parsing instance 0\n",
      "2020/01/13 14:01:39.139581 Parsing instance 1\n",
      "2020/01/13 14:01:39.246999 Parsing instance 2\n",
      "2020/01/13 14:01:39.417690 Parsing instance 3\n",
      "2020/01/13 14:01:39.784522 Parsing instance 4\n",
      "2020/01/13 14:01:40.011691 Parsing instance 5\n",
      "2020/01/13 14:01:40.217308 Parsing instance 6\n",
      "2020/01/13 14:01:40.310433 Parsing instance 7\n",
      "2020/01/13 14:01:40.478241 Parsing instance 8\n",
      "2020/01/13 14:01:40.554972 Parsing instance 9\n",
      "2020/01/13 14:01:40.941160 Parsing instance 10\n",
      "2020/01/13 14:01:41.076892 Parsing instance 11\n",
      "2020/01/13 14:01:41.145600 Parsing instance 12\n",
      "2020/01/13 14:01:41.359482 Parsing instance 13\n",
      "2020/01/13 14:01:41.512058 Parsing instance 14\n",
      "2020/01/13 14:01:41.606981 Parsing instance 15\n",
      "2020/01/13 14:01:41.677808 Parsing instance 16\n",
      "2020/01/13 14:01:41.745410 Parsing instance 17\n",
      "2020/01/13 14:01:41.827860 Parsing instance 18\n",
      "2020/01/13 14:01:42.162764 Parsing instance 19\n",
      "2020/01/13 14:01:42.273899 Parsing instance 20\n",
      "2020/01/13 14:01:42.346856 Parsing instance 21\n",
      "2020/01/13 14:01:42.428812 Parsing instance 22\n",
      "2020/01/13 14:01:42.653222 Parsing instance 23\n",
      "2020/01/13 14:01:42.791272 Parsing instance 24\n",
      "2020/01/13 14:01:43.258833 Parsing instance 25\n",
      "2020/01/13 14:01:43.459285 Parsing instance 26\n",
      "2020/01/13 14:01:43.629213 Parsing instance 27\n",
      "2020/01/13 14:01:43.800363 Parsing instance 28\n",
      "2020/01/13 14:01:43.930570 Parsing instance 29\n",
      "2020/01/13 14:01:44.046487 Parsing instance 30\n",
      "2020/01/13 14:01:44.412138 Parsing instance 31\n",
      "2020/01/13 14:01:44.512640 Parsing instance 32\n",
      "2020/01/13 14:01:44.543048 Parsing instance 33\n",
      "2020/01/13 14:01:44.703181 Parsing instance 34\n",
      "2020/01/13 14:01:44.793447 Parsing instance 35\n",
      "2020/01/13 14:01:44.958177 Parsing instance 36\n",
      "2020/01/13 14:01:45.034735 Parsing instance 37\n",
      "2020/01/13 14:01:45.141614 Parsing instance 38\n",
      "2020/01/13 14:01:45.238351 Parsing instance 39\n",
      "2020/01/13 14:01:45.618123 Parsing instance 40\n",
      "2020/01/13 14:01:45.746166 Parsing instance 41\n",
      "2020/01/13 14:01:45.813779 Parsing instance 42\n",
      "2020/01/13 14:01:45.816893 Parsing instance 43\n",
      "2020/01/13 14:01:45.835192 Parsing instance 44\n",
      "2020/01/13 14:01:45.924614 Parsing instance 45\n",
      "2020/01/13 14:01:45.930097 Parsing instance 46\n",
      "2020/01/13 14:01:46.015638 Parsing instance 47\n",
      "2020/01/13 14:01:46.139850 Parsing instance 48\n",
      "2020/01/13 14:01:46.240640 Parsing instance 49\n",
      "2020/01/13 14:01:46.437285 Parsing instance 50\n",
      "2020/01/13 14:01:47.040073 Parsing instance 51\n",
      "2020/01/13 14:01:47.137758 Parsing instance 52\n",
      "2020/01/13 14:01:47.205068 Parsing instance 53\n",
      "2020/01/13 14:01:47.421468 Parsing instance 54\n",
      "2020/01/13 14:01:47.905551 Parsing instance 55\n",
      "2020/01/13 14:01:48.146847 Parsing instance 56\n",
      "2020/01/13 14:01:48.379987 Parsing instance 57\n",
      "2020/01/13 14:01:48.476891 Parsing instance 58\n",
      "2020/01/13 14:01:49.150278 Parsing instance 59\n",
      "2020/01/13 14:01:49.249976 Parsing instance 60\n",
      "2020/01/13 14:01:49.261849 Parsing instance 61\n",
      "2020/01/13 14:01:49.481375 Parsing instance 62\n",
      "2020/01/13 14:01:49.588658 Parsing instance 63\n",
      "2020/01/13 14:01:49.717683 Parsing instance 64\n",
      "2020/01/13 14:01:50.029376 Parsing instance 65\n",
      "2020/01/13 14:01:50.138283 Parsing instance 66\n",
      "2020/01/13 14:01:50.381843 Parsing instance 67\n",
      "2020/01/13 14:01:50.486054 Parsing instance 68\n",
      "2020/01/13 14:01:50.610800 Parsing instance 69\n",
      "2020/01/13 14:01:50.777593 Parsing instance 70\n",
      "2020/01/13 14:01:50.854855 Parsing instance 71\n",
      "2020/01/13 14:01:51.128452 Parsing instance 72\n",
      "2020/01/13 14:01:51.291430 Parsing instance 73\n",
      "2020/01/13 14:01:51.349198 Parsing instance 74\n",
      "2020/01/13 14:01:51.510291 Parsing instance 75\n",
      "2020/01/13 14:01:51.571703 Parsing instance 76\n",
      "2020/01/13 14:01:51.655953 Parsing instance 77\n",
      "2020/01/13 14:01:51.723743 Parsing instance 78\n",
      "2020/01/13 14:01:51.744956 Parsing instance 79\n",
      "2020/01/13 14:01:51.827574 Parsing instance 80\n",
      "2020/01/13 14:01:51.900324 Parsing instance 81\n",
      "2020/01/13 14:01:51.990704 Parsing instance 82\n",
      "2020/01/13 14:01:52.364876 Parsing instance 83\n",
      "2020/01/13 14:01:52.445555 Parsing instance 84\n",
      "2020/01/13 14:01:52.549867 Parsing instance 85\n",
      "2020/01/13 14:01:52.621695 Parsing instance 86\n",
      "2020/01/13 14:01:52.679238 Parsing instance 87\n",
      "2020/01/13 14:01:52.808380 Parsing instance 88\n",
      "2020/01/13 14:01:52.856962 Parsing instance 89\n",
      "2020/01/13 14:01:52.927787 Parsing instance 90\n",
      "2020/01/13 14:01:52.990699 Parsing instance 91\n",
      "2020/01/13 14:01:53.115951 Parsing instance 92\n",
      "2020/01/13 14:01:53.141430 Parsing instance 93\n",
      "2020/01/13 14:01:53.275414 Parsing instance 94\n",
      "2020/01/13 14:01:53.824110 Parsing instance 95\n",
      "2020/01/13 14:01:53.850669 Parsing instance 96\n",
      "2020/01/13 14:01:53.927406 Parsing instance 97\n",
      "2020/01/13 14:01:54.180434 Parsing instance 98\n",
      "2020/01/13 14:01:54.237142 Parsing instance 99\n",
      "2020/01/13 14:01:54.404476 Parsing instance 100\n",
      "2020/01/13 14:01:54.647285 Parsing instance 101\n",
      "2020/01/13 14:01:54.732235 Parsing instance 102\n",
      "2020/01/13 14:01:54.963137 Parsing instance 103\n",
      "2020/01/13 14:01:55.033238 Parsing instance 104\n",
      "2020/01/13 14:01:55.157729 Parsing instance 105\n",
      "2020/01/13 14:01:55.252163 Parsing instance 106\n",
      "2020/01/13 14:01:55.391551 Parsing instance 107\n",
      "2020/01/13 14:01:55.488483 Parsing instance 108\n",
      "2020/01/13 14:01:55.833912 Parsing instance 109\n",
      "2020/01/13 14:01:55.929375 Parsing instance 110\n",
      "2020/01/13 14:01:55.946136 Parsing instance 111\n",
      "2020/01/13 14:01:56.041840 Parsing instance 112\n",
      "2020/01/13 14:01:56.104304 Parsing instance 113\n",
      "2020/01/13 14:01:56.279003 Parsing instance 114\n",
      "2020/01/13 14:01:56.346286 Parsing instance 115\n",
      "2020/01/13 14:01:56.530862 Parsing instance 116\n",
      "2020/01/13 14:01:56.584526 Parsing instance 117\n",
      "2020/01/13 14:01:57.013372 Parsing instance 118\n",
      "2020/01/13 14:01:57.252335 Parsing instance 119\n",
      "2020/01/13 14:01:57.417475 Parsing instance 120\n",
      "2020/01/13 14:01:57.609037 Parsing instance 121\n",
      "2020/01/13 14:01:57.677005 Parsing instance 122\n",
      "2020/01/13 14:01:58.070506 Parsing instance 123\n",
      "2020/01/13 14:01:58.096694 Parsing instance 124\n",
      "2020/01/13 14:01:58.181183 Parsing instance 125\n",
      "2020/01/13 14:01:58.273425 Parsing instance 126\n",
      "2020/01/13 14:01:58.316442 Parsing instance 127\n",
      "2020/01/13 14:01:58.382584 Parsing instance 128\n",
      "2020/01/13 14:01:58.424258 Parsing instance 129\n",
      "2020/01/13 14:01:58.476018 Parsing instance 130\n",
      "2020/01/13 14:01:58.539356 Parsing instance 131\n",
      "2020/01/13 14:01:58.611260 Parsing instance 132\n",
      "2020/01/13 14:01:58.652576 Parsing instance 133\n",
      "2020/01/13 14:01:58.765219 Parsing instance 134\n",
      "2020/01/13 14:01:58.785750 Parsing instance 135\n",
      "2020/01/13 14:01:58.885389 Parsing instance 136\n",
      "2020/01/13 14:01:59.173659 Parsing instance 137\n",
      "2020/01/13 14:01:59.326004 Parsing instance 138\n",
      "2020/01/13 14:01:59.420283 Parsing instance 139\n",
      "2020/01/13 14:01:59.441264 Parsing instance 140\n",
      "2020/01/13 14:01:59.597933 Parsing instance 141\n",
      "2020/01/13 14:01:59.657849 Parsing instance 142\n",
      "2020/01/13 14:01:59.759656 Parsing instance 143\n",
      "2020/01/13 14:01:59.899706 Parsing instance 144\n",
      "2020/01/13 14:01:59.935725 Parsing instance 145\n",
      "2020/01/13 14:01:59.992340 Parsing instance 146\n",
      "2020/01/13 14:02:00.014108 Parsing instance 147\n",
      "2020/01/13 14:02:00.050737 Parsing instance 148\n",
      "2020/01/13 14:02:00.104011 Parsing instance 149\n",
      "2020/01/13 14:02:00.434895 Parsing instance 150\n",
      "2020/01/13 14:02:00.748066 Parsing instance 151\n",
      "2020/01/13 14:02:00.760460 Parsing instance 152\n",
      "2020/01/13 14:02:00.769399 Parsing instance 153\n",
      "2020/01/13 14:02:00.871714 Parsing instance 154\n",
      "2020/01/13 14:02:00.880516 Parsing instance 155\n",
      "2020/01/13 14:02:01.204568 Parsing instance 156\n",
      "2020/01/13 14:02:01.503881 Parsing instance 157\n",
      "2020/01/13 14:02:01.617372 Parsing instance 158\n",
      "2020/01/13 14:02:01.639766 Parsing instance 159\n",
      "2020/01/13 14:02:01.676263 Parsing instance 160\n",
      "2020/01/13 14:02:01.798283 Parsing instance 161\n",
      "2020/01/13 14:02:01.820153 Parsing instance 162\n",
      "2020/01/13 14:02:01.899854 Parsing instance 163\n",
      "2020/01/13 14:02:02.156775 Parsing instance 164\n",
      "2020/01/13 14:02:02.354825 Parsing instance 165\n",
      "2020/01/13 14:02:02.366394 Parsing instance 166\n",
      "2020/01/13 14:02:02.537698 Parsing instance 167\n",
      "2020/01/13 14:02:02.702223 Parsing instance 168\n",
      "2020/01/13 14:02:02.750488 Parsing instance 169\n",
      "2020/01/13 14:02:02.947130 Parsing instance 170\n",
      "2020/01/13 14:02:03.024671 Parsing instance 171\n",
      "2020/01/13 14:02:03.281730 Parsing instance 172\n",
      "2020/01/13 14:02:03.366636 Parsing instance 173\n",
      "2020/01/13 14:02:03.742684 Parsing instance 174\n",
      "2020/01/13 14:02:03.989291 Parsing instance 175\n",
      "2020/01/13 14:02:04.025592 Parsing instance 176\n",
      "2020/01/13 14:02:04.153760 Parsing instance 177\n",
      "2020/01/13 14:02:04.311887 Parsing instance 178\n",
      "2020/01/13 14:02:04.466975 Parsing instance 179\n",
      "2020/01/13 14:02:04.482750 Parsing instance 180\n",
      "2020/01/13 14:02:04.510866 Parsing instance 181\n",
      "2020/01/13 14:02:04.572313 Parsing instance 182\n",
      "2020/01/13 14:02:05.142326 Parsing instance 183\n",
      "2020/01/13 14:02:05.178221 Parsing instance 184\n",
      "2020/01/13 14:02:05.274491 Parsing instance 185\n",
      "2020/01/13 14:02:05.452604 Parsing instance 186\n",
      "2020/01/13 14:02:05.614659 Parsing instance 187\n",
      "2020/01/13 14:02:05.687657 Parsing instance 188\n",
      "2020/01/13 14:02:05.702016 Parsing instance 189\n",
      "2020/01/13 14:02:05.740875 Parsing instance 190\n",
      "2020/01/13 14:02:06.150124 Parsing instance 191\n",
      "2020/01/13 14:02:06.324585 Parsing instance 192\n",
      "2020/01/13 14:02:06.376353 Parsing instance 193\n",
      "2020/01/13 14:02:06.389449 Parsing instance 194\n",
      "2020/01/13 14:02:06.407104 Parsing instance 195\n",
      "2020/01/13 14:02:06.534851 Parsing instance 196\n",
      "2020/01/13 14:02:06.616537 Parsing instance 197\n",
      "2020/01/13 14:02:06.677239 Parsing instance 198\n",
      "2020/01/13 14:02:06.811523 Parsing instance 199\n",
      "2020/01/13 14:02:06.831906 Parsing instance 200\n",
      "2020/01/13 14:02:07.167168 Parsing instance 201\n",
      "2020/01/13 14:02:07.202927 Parsing instance 202\n",
      "2020/01/13 14:02:07.314641 Parsing instance 203\n",
      "2020/01/13 14:02:07.345660 Parsing instance 204\n",
      "2020/01/13 14:02:07.465785 Parsing instance 205\n",
      "2020/01/13 14:02:07.479906 Parsing instance 206\n",
      "2020/01/13 14:02:07.496586 Parsing instance 207\n",
      "2020/01/13 14:02:07.556900 Parsing instance 208\n",
      "2020/01/13 14:02:07.732432 Parsing instance 209\n",
      "2020/01/13 14:02:07.819524 Parsing instance 210\n",
      "2020/01/13 14:02:07.975993 Parsing instance 211\n",
      "2020/01/13 14:02:08.235731 Parsing instance 212\n",
      "2020/01/13 14:02:08.447530 Parsing instance 213\n",
      "2020/01/13 14:02:08.516690 Parsing instance 214\n",
      "2020/01/13 14:02:08.623708 Parsing instance 215\n",
      "2020/01/13 14:02:08.840738 Parsing instance 216\n",
      "2020/01/13 14:02:08.854303 Parsing instance 217\n",
      "2020/01/13 14:02:08.903676 Parsing instance 218\n",
      "2020/01/13 14:02:09.004471 Parsing instance 219\n",
      "2020/01/13 14:02:09.493553 Parsing instance 220\n",
      "2020/01/13 14:02:09.663721 Parsing instance 221\n",
      "2020/01/13 14:02:09.743409 Parsing instance 222\n",
      "2020/01/13 14:02:09.809380 Parsing instance 223\n",
      "2020/01/13 14:02:09.928997 Parsing instance 224\n",
      "2020/01/13 14:02:10.221079 Parsing instance 225\n",
      "2020/01/13 14:02:10.312910 Parsing instance 226\n",
      "2020/01/13 14:02:10.594619 Parsing instance 227\n",
      "2020/01/13 14:02:10.863552 Parsing instance 228\n",
      "2020/01/13 14:02:11.586599 Parsing instance 229\n",
      "2020/01/13 14:02:11.634921 Parsing instance 230\n",
      "2020/01/13 14:02:11.797582 Parsing instance 231\n",
      "2020/01/13 14:02:11.904319 Parsing instance 232\n",
      "2020/01/13 14:02:11.956043 Parsing instance 233\n",
      "2020/01/13 14:02:12.061979 Parsing instance 234\n",
      "2020/01/13 14:02:12.184090 Parsing instance 235\n",
      "2020/01/13 14:02:12.305440 Parsing instance 236\n",
      "2020/01/13 14:02:12.399620 Parsing instance 237\n",
      "2020/01/13 14:02:12.544988 Parsing instance 238\n",
      "2020/01/13 14:02:13.020274 Parsing instance 239\n",
      "2020/01/13 14:02:13.417976 Parsing instance 240\n",
      "2020/01/13 14:02:13.522465 Parsing instance 241\n",
      "2020/01/13 14:02:13.600511 Parsing instance 242\n",
      "2020/01/13 14:02:13.702403 Parsing instance 243\n",
      "2020/01/13 14:02:13.921242 Parsing instance 244\n",
      "2020/01/13 14:02:14.160459 Parsing instance 245\n",
      "2020/01/13 14:02:14.175873 Parsing instance 246\n",
      "2020/01/13 14:02:14.200454 Parsing instance 247\n",
      "2020/01/13 14:02:14.255407 Parsing instance 248\n",
      "2020/01/13 14:02:14.478015 Parsing instance 249\n",
      "2020/01/13 14:02:14.528628 Parsing instance 250\n",
      "2020/01/13 14:02:14.630904 Parsing instance 251\n",
      "2020/01/13 14:02:14.741671 Parsing instance 252\n",
      "2020/01/13 14:02:14.847364 Parsing instance 253\n",
      "2020/01/13 14:02:14.864784 Parsing instance 254\n",
      "2020/01/13 14:02:14.887812 Parsing instance 255\n",
      "2020/01/13 14:02:15.244519 Parsing instance 256\n",
      "2020/01/13 14:02:15.372361 Parsing instance 257\n",
      "2020/01/13 14:02:15.516929 Parsing instance 258\n",
      "2020/01/13 14:02:15.820159 Parsing instance 259\n",
      "2020/01/13 14:02:15.846035 Parsing instance 260\n",
      "2020/01/13 14:02:16.043093 Parsing instance 261\n",
      "2020/01/13 14:02:16.383136 Parsing instance 262\n",
      "2020/01/13 14:02:16.530470 Parsing instance 263\n",
      "2020/01/13 14:02:16.896574 Parsing instance 264\n",
      "2020/01/13 14:02:16.902047 Parsing instance 265\n",
      "2020/01/13 14:02:17.055487 Parsing instance 266\n",
      "2020/01/13 14:02:17.096192 Parsing instance 267\n",
      "2020/01/13 14:02:17.303444 Parsing instance 268\n",
      "2020/01/13 14:02:17.547047 Parsing instance 269\n",
      "2020/01/13 14:02:17.638017 Parsing instance 270\n",
      "2020/01/13 14:02:17.892216 Parsing instance 271\n",
      "2020/01/13 14:02:17.953275 Parsing instance 272\n",
      "2020/01/13 14:02:18.061371 Parsing instance 273\n",
      "2020/01/13 14:02:18.113201 Parsing instance 274\n",
      "2020/01/13 14:02:18.568134 Parsing instance 275\n",
      "2020/01/13 14:02:18.677397 Parsing instance 276\n",
      "2020/01/13 14:02:18.741854 Parsing instance 277\n",
      "2020/01/13 14:02:18.999295 Parsing instance 278\n",
      "2020/01/13 14:02:19.112400 Parsing instance 279\n",
      "2020/01/13 14:02:19.193417 Parsing instance 280\n",
      "2020/01/13 14:02:19.369771 Parsing instance 281\n",
      "2020/01/13 14:02:19.622642 Parsing instance 282\n",
      "2020/01/13 14:02:19.768864 Parsing instance 283\n",
      "2020/01/13 14:02:19.859667 Parsing instance 284\n",
      "2020/01/13 14:02:19.907995 Parsing instance 285\n",
      "2020/01/13 14:02:19.993656 Parsing instance 286\n",
      "2020/01/13 14:02:20.045649 Parsing instance 287\n",
      "2020/01/13 14:02:20.097017 Parsing instance 288\n",
      "2020/01/13 14:02:20.216123 Parsing instance 289\n",
      "2020/01/13 14:02:20.228967 Parsing instance 290\n",
      "2020/01/13 14:02:20.250409 Parsing instance 291\n",
      "2020/01/13 14:02:20.293819 Parsing instance 292\n",
      "2020/01/13 14:02:20.320939 Parsing instance 293\n",
      "2020/01/13 14:02:20.476329 Parsing instance 294\n",
      "2020/01/13 14:02:20.554994 Parsing instance 295\n",
      "2020/01/13 14:02:20.585354 Parsing instance 296\n",
      "2020/01/13 14:02:20.898611 Parsing instance 297\n",
      "2020/01/13 14:02:21.006652 Parsing instance 298\n",
      "2020/01/13 14:02:21.053883 Parsing instance 299\n",
      "2020/01/13 14:02:21.150637 Parsing instance 300\n",
      "2020/01/13 14:02:21.180972 Parsing instance 301\n",
      "2020/01/13 14:02:21.310991 Parsing instance 302\n",
      "2020/01/13 14:02:21.370139 Parsing instance 303\n",
      "2020/01/13 14:02:21.400969 Parsing instance 304\n",
      "2020/01/13 14:02:21.560433 Parsing instance 305\n",
      "2020/01/13 14:02:22.454573 Parsing instance 306\n",
      "2020/01/13 14:02:22.616212 Parsing instance 307\n",
      "2020/01/13 14:02:22.709077 Parsing instance 308\n",
      "2020/01/13 14:02:22.811831 Parsing instance 309\n",
      "2020/01/13 14:02:23.171070 Parsing instance 310\n",
      "2020/01/13 14:02:23.213541 Parsing instance 311\n",
      "2020/01/13 14:02:23.245934 Parsing instance 312\n",
      "2020/01/13 14:02:23.282329 Parsing instance 313\n",
      "2020/01/13 14:02:23.325859 Parsing instance 314\n",
      "2020/01/13 14:02:23.389409 Parsing instance 315\n",
      "2020/01/13 14:02:23.459603 Parsing instance 316\n",
      "2020/01/13 14:02:23.503499 Parsing instance 317\n",
      "2020/01/13 14:02:23.576094 Parsing instance 318\n",
      "2020/01/13 14:02:23.641352 Parsing instance 319\n",
      "2020/01/13 14:02:23.920671 Parsing instance 320\n",
      "2020/01/13 14:02:23.951529 Parsing instance 321\n",
      "2020/01/13 14:02:23.971217 Parsing instance 322\n",
      "2020/01/13 14:02:24.582620 Parsing instance 323\n",
      "2020/01/13 14:02:24.644395 Parsing instance 324\n",
      "2020/01/13 14:02:24.704566 Parsing instance 325\n",
      "2020/01/13 14:02:24.731889 Parsing instance 326\n",
      "2020/01/13 14:02:24.956621 Parsing instance 327\n",
      "2020/01/13 14:02:25.072696 Parsing instance 328\n",
      "2020/01/13 14:02:25.189669 Parsing instance 329\n",
      "2020/01/13 14:02:25.563106 Parsing instance 330\n",
      "2020/01/13 14:02:25.695830 Parsing instance 331\n",
      "2020/01/13 14:02:25.743906 Parsing instance 332\n",
      "2020/01/13 14:02:25.837400 Parsing instance 333\n",
      "2020/01/13 14:02:25.961027 Parsing instance 334\n",
      "2020/01/13 14:02:25.992860 Parsing instance 335\n",
      "2020/01/13 14:02:26.056245 Parsing instance 336\n",
      "2020/01/13 14:02:26.188899 Parsing instance 337\n",
      "2020/01/13 14:02:26.309110 Parsing instance 338\n",
      "2020/01/13 14:02:26.390079 Parsing instance 339\n",
      "2020/01/13 14:02:26.645665 Parsing instance 340\n",
      "2020/01/13 14:02:26.688714 Parsing instance 341\n",
      "2020/01/13 14:02:26.783734 Parsing instance 342\n",
      "2020/01/13 14:02:26.820964 Parsing instance 343\n",
      "2020/01/13 14:02:26.883849 Parsing instance 344\n",
      "2020/01/13 14:02:26.971381 Parsing instance 345\n",
      "2020/01/13 14:02:27.127726 Parsing instance 346\n",
      "2020/01/13 14:02:27.211558 Parsing instance 347\n",
      "2020/01/13 14:02:27.311545 Parsing instance 348\n",
      "2020/01/13 14:02:27.355496 Parsing instance 349\n",
      "2020/01/13 14:02:27.504551 Parsing instance 350\n",
      "2020/01/13 14:02:27.902896 Parsing instance 351\n",
      "2020/01/13 14:02:28.058654 Parsing instance 352\n",
      "2020/01/13 14:02:28.086672 Parsing instance 353\n",
      "2020/01/13 14:02:28.207406 Parsing instance 354\n",
      "2020/01/13 14:02:28.230500 Parsing instance 355\n",
      "2020/01/13 14:02:28.297598 Parsing instance 356\n",
      "2020/01/13 14:02:28.391356 Parsing instance 357\n",
      "2020/01/13 14:02:28.495708 Parsing instance 358\n",
      "2020/01/13 14:02:28.517905 Parsing instance 359\n",
      "2020/01/13 14:02:28.628289 Parsing instance 360\n",
      "2020/01/13 14:02:28.681866 Parsing instance 361\n",
      "2020/01/13 14:02:28.970978 Parsing instance 362\n",
      "2020/01/13 14:02:29.087736 Parsing instance 363\n",
      "2020/01/13 14:02:29.171240 Parsing instance 364\n",
      "2020/01/13 14:02:29.194009 Parsing instance 365\n",
      "2020/01/13 14:02:29.204951 Parsing instance 366\n",
      "2020/01/13 14:02:29.304526 Parsing instance 367\n",
      "2020/01/13 14:02:29.470534 Parsing instance 368\n",
      "2020/01/13 14:02:29.550593 Parsing instance 369\n",
      "2020/01/13 14:02:29.669305 Parsing instance 370\n",
      "2020/01/13 14:02:29.725624 Parsing instance 371\n",
      "2020/01/13 14:02:29.806678 Parsing instance 372\n",
      "2020/01/13 14:02:29.844960 Parsing instance 373\n",
      "2020/01/13 14:02:29.937776 Parsing instance 374\n",
      "2020/01/13 14:02:30.164892 Parsing instance 375\n",
      "2020/01/13 14:02:30.282727 Parsing instance 376\n",
      "2020/01/13 14:02:30.348918 Parsing instance 377\n",
      "2020/01/13 14:02:30.439014 Parsing instance 378\n",
      "2020/01/13 14:02:30.529507 Parsing instance 379\n",
      "2020/01/13 14:02:30.570555 Parsing instance 380\n",
      "2020/01/13 14:02:30.595965 Parsing instance 381\n",
      "2020/01/13 14:02:30.722831 Parsing instance 382\n",
      "2020/01/13 14:02:30.763731 Parsing instance 383\n",
      "2020/01/13 14:02:30.863105 Parsing instance 384\n",
      "2020/01/13 14:02:30.906136 Parsing instance 385\n",
      "2020/01/13 14:02:30.927378 Parsing instance 386\n",
      "2020/01/13 14:02:31.014139 Parsing instance 387\n",
      "2020/01/13 14:02:31.429769 Parsing instance 388\n",
      "2020/01/13 14:02:31.457221 Parsing instance 389\n",
      "2020/01/13 14:02:31.506029 Parsing instance 390\n",
      "2020/01/13 14:02:31.578283 Parsing instance 391\n",
      "2020/01/13 14:02:31.642128 Parsing instance 392\n",
      "2020/01/13 14:02:31.754135 Parsing instance 393\n",
      "2020/01/13 14:02:31.852408 Parsing instance 394\n",
      "2020/01/13 14:02:31.991820 Parsing instance 395\n",
      "2020/01/13 14:02:32.119879 Parsing instance 396\n",
      "2020/01/13 14:02:32.206662 Parsing instance 397\n",
      "2020/01/13 14:02:32.617158 Parsing instance 398\n",
      "2020/01/13 14:02:32.643996 Parsing instance 399\n",
      "2020/01/13 14:02:32.763032 Parsing instance 400\n",
      "2020/01/13 14:02:32.918401 Parsing instance 401\n",
      "2020/01/13 14:02:33.031740 Parsing instance 402\n",
      "2020/01/13 14:02:33.092532 Parsing instance 403\n",
      "2020/01/13 14:02:33.154764 Parsing instance 404\n",
      "2020/01/13 14:02:33.264301 Parsing instance 405\n",
      "2020/01/13 14:02:33.319632 Parsing instance 406\n",
      "2020/01/13 14:02:33.374965 Parsing instance 407\n",
      "2020/01/13 14:02:33.670159 Parsing instance 408\n",
      "2020/01/13 14:02:33.961478 Parsing instance 409\n",
      "2020/01/13 14:02:33.978257 Parsing instance 410\n",
      "2020/01/13 14:02:34.029371 Parsing instance 411\n",
      "2020/01/13 14:02:34.222334 Parsing instance 412\n",
      "2020/01/13 14:02:34.275192 Parsing instance 413\n",
      "2020/01/13 14:02:34.357938 Parsing instance 414\n",
      "2020/01/13 14:02:34.382456 Parsing instance 415\n",
      "2020/01/13 14:02:34.433292 Parsing instance 416\n",
      "2020/01/13 14:02:34.888618 Parsing instance 417\n",
      "2020/01/13 14:02:34.936678 Parsing instance 418\n",
      "2020/01/13 14:02:34.988726 Parsing instance 419\n",
      "2020/01/13 14:02:35.074345 Parsing instance 420\n",
      "2020/01/13 14:02:35.105134 Parsing instance 421\n",
      "2020/01/13 14:02:35.249622 Parsing instance 422\n",
      "2020/01/13 14:02:35.260773 Parsing instance 423\n",
      "2020/01/13 14:02:35.286234 Parsing instance 424\n",
      "2020/01/13 14:02:35.313514 Parsing instance 425\n",
      "2020/01/13 14:02:35.370103 Parsing instance 426\n",
      "2020/01/13 14:02:35.422443 Parsing instance 427\n",
      "2020/01/13 14:02:35.555531 Parsing instance 428\n",
      "2020/01/13 14:02:35.706589 Parsing instance 429\n",
      "2020/01/13 14:02:36.088494 Parsing instance 430\n",
      "2020/01/13 14:02:36.169651 Parsing instance 431\n",
      "2020/01/13 14:02:36.249794 Parsing instance 432\n",
      "2020/01/13 14:02:36.296178 Parsing instance 433\n",
      "2020/01/13 14:02:36.332940 Parsing instance 434\n",
      "2020/01/13 14:02:36.359438 Parsing instance 435\n",
      "2020/01/13 14:02:36.424098 Parsing instance 436\n",
      "2020/01/13 14:02:36.539779 Parsing instance 437\n",
      "2020/01/13 14:02:36.568666 Parsing instance 438\n",
      "2020/01/13 14:02:36.633426 Parsing instance 439\n",
      "2020/01/13 14:02:36.700413 Parsing instance 440\n",
      "2020/01/13 14:02:36.752370 Parsing instance 441\n",
      "2020/01/13 14:02:36.963670 Parsing instance 442\n",
      "2020/01/13 14:02:37.085225 Parsing instance 443\n",
      "2020/01/13 14:02:37.409164 Parsing instance 444\n",
      "2020/01/13 14:02:37.562322 Parsing instance 445\n",
      "2020/01/13 14:02:37.619887 Parsing instance 446\n",
      "2020/01/13 14:02:37.641238 Parsing instance 447\n",
      "2020/01/13 14:02:37.739069 Parsing instance 448\n",
      "2020/01/13 14:02:37.929844 Parsing instance 449\n",
      "2020/01/13 14:02:37.953004 Parsing instance 450\n",
      "2020/01/13 14:02:37.984565 Parsing instance 451\n",
      "2020/01/13 14:02:38.112698 Parsing instance 452\n",
      "2020/01/13 14:02:38.129657 Parsing instance 453\n",
      "2020/01/13 14:02:38.158089 Parsing instance 454\n",
      "2020/01/13 14:02:38.610189 Parsing instance 455\n",
      "2020/01/13 14:02:38.621403 Parsing instance 456\n",
      "2020/01/13 14:02:38.640374 Parsing instance 457\n",
      "2020/01/13 14:02:38.661196 Parsing instance 458\n",
      "2020/01/13 14:02:38.735310 Parsing instance 459\n",
      "2020/01/13 14:02:38.833922 Parsing instance 460\n",
      "2020/01/13 14:02:38.843666 Parsing instance 461\n",
      "2020/01/13 14:02:38.874326 Parsing instance 462\n",
      "2020/01/13 14:02:39.075144 Parsing instance 463\n",
      "2020/01/13 14:02:39.124636 Parsing instance 464\n",
      "2020/01/13 14:02:39.167898 Parsing instance 465\n",
      "2020/01/13 14:02:39.224749 Parsing instance 466\n",
      "2020/01/13 14:02:39.278351 Parsing instance 467\n",
      "2020/01/13 14:02:39.297287 Parsing instance 468\n",
      "2020/01/13 14:02:39.366930 Parsing instance 469\n",
      "2020/01/13 14:02:39.710603 Parsing instance 470\n",
      "2020/01/13 14:02:39.783897 Parsing instance 471\n",
      "2020/01/13 14:02:39.869855 Parsing instance 472\n",
      "2020/01/13 14:02:39.885445 Parsing instance 473\n",
      "2020/01/13 14:02:39.938091 Parsing instance 474\n",
      "2020/01/13 14:02:40.003474 Parsing instance 475\n",
      "2020/01/13 14:02:40.029470 Parsing instance 476\n",
      "2020/01/13 14:02:40.049465 Parsing instance 477\n",
      "2020/01/13 14:02:40.069495 Parsing instance 478\n",
      "2020/01/13 14:02:40.141855 Parsing instance 479\n",
      "2020/01/13 14:02:40.159889 Parsing instance 480\n",
      "2020/01/13 14:02:40.182511 Parsing instance 481\n",
      "2020/01/13 14:02:40.222949 Parsing instance 482\n",
      "2020/01/13 14:02:40.252143 Parsing instance 483\n",
      "2020/01/13 14:02:40.318759 Parsing instance 484\n",
      "2020/01/13 14:02:40.369757 Parsing instance 485\n",
      "2020/01/13 14:02:40.415153 Parsing instance 486\n",
      "2020/01/13 14:02:40.534382 Parsing instance 487\n",
      "2020/01/13 14:02:40.623038 Parsing instance 488\n",
      "2020/01/13 14:02:40.879841 Parsing instance 489\n",
      "2020/01/13 14:02:40.938504 Parsing instance 490\n",
      "2020/01/13 14:02:40.974262 Parsing instance 491\n",
      "2020/01/13 14:02:41.067991 Parsing instance 492\n",
      "2020/01/13 14:02:41.159213 Parsing instance 493\n",
      "2020/01/13 14:02:41.217420 Parsing instance 494\n",
      "2020/01/13 14:02:41.233577 Parsing instance 495\n",
      "2020/01/13 14:02:41.292981 Parsing instance 496\n",
      "2020/01/13 14:02:41.399983 Parsing instance 497\n",
      "2020/01/13 14:02:41.445563 Parsing instance 498\n",
      "2020/01/13 14:02:41.459523 Parsing instance 499\n",
      "2020/01/13 14:02:41.473273 PARSE Total Time: 1m2.449271699s\n",
      "2020/01/13 14:02:41.473300 Converting 500 to conll\n",
      "2020/01/13 14:02:41.473307 Writing to output file\n",
      "2020/01/13 14:02:41.525330 Wrote 500 in conll format to final_setup/pruned/dev_pruned_non_o_keep.conll\n",
      "2020/01/13 14:02:41.525359 Writing to segmentation file\n",
      "2020/01/13 14:02:41.577664 Wrote 500 in segmentation format to final_setup/pruned/dev_pruned_non_o_keep.seg\n",
      "2020/01/13 14:02:41.577678 Writing to mapping file\n",
      "2020/01/13 14:02:41.800509 Wrote 500 in mapping format to final_setup/pruned/dev_pruned_non_o_keep.map\n",
      "2020/01/13 14:02:41.800529 Writing to gold segmentation file\n"
     ]
    }
   ],
   "source": [
    "!{yap_path} joint -in final_setup/pruned/dev_pruned_non_o_keep.lattices -os final_setup/pruned/dev_pruned_non_o_keep.seg -om final_setup/pruned/dev_pruned_non_o_keep.map -oc final_setup/pruned/dev_pruned_non_o_keep.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/01/13 14:02:42.529730 GOMAXPROCS:\t40\n",
      "2020/01/13 14:02:42.529909 \n",
      "2020/01/13 14:02:42.530536 *** CONFIGURATION ***\n",
      "2020/01/13 14:02:42.530560 Beam:             \tStandard Beam [Not Aligned & Not Averaged]\n",
      "2020/01/13 14:02:42.530605 Transition System:\tJoint Morpho-Syntactic [MD:Morpheme-Based Morphological Disambiguator, ArcSys:Arc Zeager (zpar acl '11) [a.k.a. ArcZEager]] - Strategy: ArcGreedy\n",
      "2020/01/13 14:02:42.530627 Transition Oracle:\tJoint Morpho-Syntactic - Strategy: ArcGreedy\n",
      "2020/01/13 14:02:42.530645 Iterations:\t\t1\n",
      "2020/01/13 14:02:42.530665 Beam Size:\t\t64\n",
      "2020/01/13 14:02:42.530686 Beam Concurrent:\ttrue\n",
      "2020/01/13 14:02:42.530703 Parameter Func:\tFuncs_Main_POS_Both_Prop\n",
      "2020/01/13 14:02:42.530720 Use Lemmas:\t\tfalse\n",
      "2020/01/13 14:02:42.530740 Use POP:\t\ttrue\n",
      "2020/01/13 14:02:42.530760 Infuse Gold Dev:\tfalse\n",
      "2020/01/13 14:02:42.530777 Limit (thousands):\t0\n",
      "2020/01/13 14:02:42.530795 Use CoNLL-U:\t\tfalse\n",
      "2020/01/13 14:02:42.530836 \n",
      "2020/01/13 14:02:42.530855 Features File:\tjointzeager.yaml\n",
      "2020/01/13 14:02:42.531324 Labels File:\t\thebtb.labels.conf\n",
      "2020/01/13 14:02:42.531609 \n",
      "2020/01/13 14:02:42.531641 Data\n",
      "2020/01/13 14:02:42.531657 Test file  (ambig.  lattice):\tfinal_setup/pruned/dev_pruned_all_keep.lattices\n",
      "2020/01/13 14:02:42.531921 Out (disamb.) file:\t\t\tfinal_setup/pruned/dev_pruned_all_keep.conll\n",
      "2020/01/13 14:02:42.531950 Out (segmt.) file:\t\t\tfinal_setup/pruned/dev_pruned_all_keep.seg\n",
      "2020/01/13 14:02:42.531973 Out (mapping.) file:\t\t\tfinal_setup/pruned/dev_pruned_all_keep.map\n",
      "2020/01/13 14:02:42.532508 \n",
      "2020/01/13 14:02:42.532527 Setup enumerations\n",
      "2020/01/13 14:02:42.532642 ETrans Len is 96\n",
      "2020/01/13 14:02:42.532950 \n",
      "2020/01/13 14:02:42.532966 Loading features\n",
      "2020/01/13 14:02:42.534627 Loading MD transition dependent feature group Past Morphemes Unigram\n",
      "2020/01/13 14:02:42.534710 Loading MD transition dependent feature group Past Morphemes Bigram\n",
      "2020/01/13 14:02:42.534822 Loading MD transition dependent feature group Past Morphemes Trigram\n",
      "2020/01/13 14:02:42.534890 Loading MD transition dependent feature group Next Morphemes Unigram\n",
      "2020/01/13 14:02:42.534915 Loading MD transition dependent feature group Next Morphemes Bigram\n",
      "2020/01/13 14:02:42.535003 Loading POP transition dependent feature group POP\n",
      "2020/01/13 14:02:42.535049 Loading Lexical transition dependent feature group Lexical\n",
      "2020/01/13 14:02:42.535075 Loading Arc transition dependent feature group ZhangNivre11\n",
      "2020/01/13 14:02:42.535511 \n",
      "2020/01/13 14:02:42.535541 Using Family HEBTB of Main_POS_Types [ [ADVERB BN BNT CD CDT JJ JJT NN NNP NNT RB VB] ]\n",
      "2020/01/13 14:02:42.535554 \n",
      "2020/01/13 14:02:42.535567 Found model file /home/nlp/danb/yapproj/src/yap/data/joint_arc_zeager_model_temp_i33.b64  ... loading model\n",
      "2020/01/13 14:03:06.060794 Loaded model\n",
      "2020/01/13 14:03:06.060844 \n",
      "2020/01/13 14:03:06.060850 *** PARSING ***\n",
      "2020/01/13 14:03:06.060856 Parsing test\n",
      "2020/01/13 14:03:06.060922 Reading ambiguous lattices from final_setup/pruned/dev_pruned_all_keep.lattices\n",
      "2020/01/13 14:03:06.159228 Read 500 ambiguous lattices from final_setup/pruned/dev_pruned_all_keep.lattices\n",
      "2020/01/13 14:03:06.159277 Converting lattice format to internal structure\n",
      "2020/01/13 14:03:06.579151 Parsing instance 0\n",
      "2020/01/13 14:03:06.696238 Parsing instance 1\n",
      "2020/01/13 14:03:06.796901 Parsing instance 2\n",
      "2020/01/13 14:03:06.976014 Parsing instance 3\n",
      "2020/01/13 14:03:07.133064 Parsing instance 4\n",
      "2020/01/13 14:03:07.543193 Parsing instance 5\n",
      "2020/01/13 14:03:07.743098 Parsing instance 6\n",
      "2020/01/13 14:03:07.872141 Parsing instance 7\n",
      "2020/01/13 14:03:08.040644 Parsing instance 8\n",
      "2020/01/13 14:03:08.113775 Parsing instance 9\n",
      "2020/01/13 14:03:08.314109 Parsing instance 10\n",
      "2020/01/13 14:03:08.412712 Parsing instance 11\n",
      "2020/01/13 14:03:08.695330 Parsing instance 12\n",
      "2020/01/13 14:03:08.901686 Parsing instance 13\n",
      "2020/01/13 14:03:09.043042 Parsing instance 14\n",
      "2020/01/13 14:03:09.133003 Parsing instance 15\n",
      "2020/01/13 14:03:09.196876 Parsing instance 16\n",
      "2020/01/13 14:03:09.259914 Parsing instance 17\n",
      "2020/01/13 14:03:09.335980 Parsing instance 18\n",
      "2020/01/13 14:03:09.445128 Parsing instance 19\n",
      "2020/01/13 14:03:09.542883 Parsing instance 20\n",
      "2020/01/13 14:03:09.822485 Parsing instance 21\n",
      "2020/01/13 14:03:09.897685 Parsing instance 22\n",
      "2020/01/13 14:03:10.132639 Parsing instance 23\n",
      "2020/01/13 14:03:10.318347 Parsing instance 24\n",
      "2020/01/13 14:03:10.619791 Parsing instance 25\n",
      "2020/01/13 14:03:10.864917 Parsing instance 26\n",
      "2020/01/13 14:03:11.314649 Parsing instance 27\n",
      "2020/01/13 14:03:11.478404 Parsing instance 28\n",
      "2020/01/13 14:03:11.596302 Parsing instance 29\n",
      "2020/01/13 14:03:11.705908 Parsing instance 30\n",
      "2020/01/13 14:03:11.818619 Parsing instance 31\n",
      "2020/01/13 14:03:11.861153 Parsing instance 32\n",
      "2020/01/13 14:03:11.888341 Parsing instance 33\n",
      "2020/01/13 14:03:12.020618 Parsing instance 34\n",
      "2020/01/13 14:03:12.318038 Parsing instance 35\n",
      "2020/01/13 14:03:12.467999 Parsing instance 36\n",
      "2020/01/13 14:03:12.543769 Parsing instance 37\n",
      "2020/01/13 14:03:12.643758 Parsing instance 38\n",
      "2020/01/13 14:03:12.733935 Parsing instance 39\n",
      "2020/01/13 14:03:12.894948 Parsing instance 40\n",
      "2020/01/13 14:03:12.956167 Parsing instance 41\n",
      "2020/01/13 14:03:13.020794 Parsing instance 42\n",
      "2020/01/13 14:03:13.023608 Parsing instance 43\n",
      "2020/01/13 14:03:13.039683 Parsing instance 44\n",
      "2020/01/13 14:03:13.119318 Parsing instance 45\n",
      "2020/01/13 14:03:13.124474 Parsing instance 46\n",
      "2020/01/13 14:03:13.302747 Parsing instance 47\n",
      "2020/01/13 14:03:13.602402 Parsing instance 48\n",
      "2020/01/13 14:03:13.699352 Parsing instance 49\n",
      "2020/01/13 14:03:13.904309 Parsing instance 50\n",
      "2020/01/13 14:03:14.297184 Parsing instance 51\n",
      "2020/01/13 14:03:14.587681 Parsing instance 52\n",
      "2020/01/13 14:03:14.656765 Parsing instance 53\n",
      "2020/01/13 14:03:14.899495 Parsing instance 54\n",
      "2020/01/13 14:03:15.203066 Parsing instance 55\n",
      "2020/01/13 14:03:15.419828 Parsing instance 56\n",
      "2020/01/13 14:03:15.847143 Parsing instance 57\n",
      "2020/01/13 14:03:15.944798 Parsing instance 58\n",
      "2020/01/13 14:03:16.410331 Parsing instance 59\n",
      "2020/01/13 14:03:16.536656 Parsing instance 60\n",
      "2020/01/13 14:03:16.672795 Parsing instance 61\n",
      "2020/01/13 14:03:16.942486 Parsing instance 62\n",
      "2020/01/13 14:03:17.043450 Parsing instance 63\n",
      "2020/01/13 14:03:17.174582 Parsing instance 64\n",
      "2020/01/13 14:03:17.260310 Parsing instance 65\n",
      "2020/01/13 14:03:17.360132 Parsing instance 66\n",
      "2020/01/13 14:03:17.580802 Parsing instance 67\n",
      "2020/01/13 14:03:17.920169 Parsing instance 68\n",
      "2020/01/13 14:03:18.040466 Parsing instance 69\n",
      "2020/01/13 14:03:18.203934 Parsing instance 70\n",
      "2020/01/13 14:03:18.268116 Parsing instance 71\n",
      "2020/01/13 14:03:18.331757 Parsing instance 72\n",
      "2020/01/13 14:03:18.461326 Parsing instance 73\n",
      "2020/01/13 14:03:18.502231 Parsing instance 74\n",
      "2020/01/13 14:03:18.607147 Parsing instance 75\n",
      "2020/01/13 14:03:18.671453 Parsing instance 76\n",
      "2020/01/13 14:03:18.746942 Parsing instance 77\n",
      "2020/01/13 14:03:19.022994 Parsing instance 78\n",
      "2020/01/13 14:03:19.042030 Parsing instance 79\n",
      "2020/01/13 14:03:19.137451 Parsing instance 80\n",
      "2020/01/13 14:03:19.209450 Parsing instance 81\n",
      "2020/01/13 14:03:19.290633 Parsing instance 82\n",
      "2020/01/13 14:03:19.451636 Parsing instance 83\n",
      "2020/01/13 14:03:19.484762 Parsing instance 84\n",
      "2020/01/13 14:03:19.573416 Parsing instance 85\n",
      "2020/01/13 14:03:19.636399 Parsing instance 86\n",
      "2020/01/13 14:03:19.688871 Parsing instance 87\n",
      "2020/01/13 14:03:19.810107 Parsing instance 88\n",
      "2020/01/13 14:03:19.854880 Parsing instance 89\n",
      "2020/01/13 14:03:19.942840 Parsing instance 90\n",
      "2020/01/13 14:03:20.168658 Parsing instance 91\n",
      "2020/01/13 14:03:20.339791 Parsing instance 92\n",
      "2020/01/13 14:03:20.363351 Parsing instance 93\n",
      "2020/01/13 14:03:20.494686 Parsing instance 94\n",
      "2020/01/13 14:03:20.816773 Parsing instance 95\n",
      "2020/01/13 14:03:20.842170 Parsing instance 96\n",
      "2020/01/13 14:03:20.915064 Parsing instance 97\n",
      "2020/01/13 14:03:21.393498 Parsing instance 98\n",
      "2020/01/13 14:03:21.446780 Parsing instance 99\n",
      "2020/01/13 14:03:21.575498 Parsing instance 100\n",
      "2020/01/13 14:03:21.625645 Parsing instance 101\n",
      "2020/01/13 14:03:21.696788 Parsing instance 102\n",
      "2020/01/13 14:03:21.892475 Parsing instance 103\n",
      "2020/01/13 14:03:21.952632 Parsing instance 104\n",
      "2020/01/13 14:03:22.065580 Parsing instance 105\n",
      "2020/01/13 14:03:22.148201 Parsing instance 106\n",
      "2020/01/13 14:03:22.479130 Parsing instance 107\n",
      "2020/01/13 14:03:22.607104 Parsing instance 108\n",
      "2020/01/13 14:03:22.737259 Parsing instance 109\n",
      "2020/01/13 14:03:22.831226 Parsing instance 110\n",
      "2020/01/13 14:03:22.848039 Parsing instance 111\n",
      "2020/01/13 14:03:22.953220 Parsing instance 112\n",
      "2020/01/13 14:03:23.018910 Parsing instance 113\n",
      "2020/01/13 14:03:23.192360 Parsing instance 114\n",
      "2020/01/13 14:03:23.252558 Parsing instance 115\n",
      "2020/01/13 14:03:23.652867 Parsing instance 116\n",
      "2020/01/13 14:03:23.704788 Parsing instance 117\n",
      "2020/01/13 14:03:23.879054 Parsing instance 118\n",
      "2020/01/13 14:03:24.099029 Parsing instance 119\n",
      "2020/01/13 14:03:24.245924 Parsing instance 120\n",
      "2020/01/13 14:03:24.412636 Parsing instance 121\n",
      "2020/01/13 14:03:24.600855 Parsing instance 122\n",
      "2020/01/13 14:03:24.860741 Parsing instance 123\n",
      "2020/01/13 14:03:24.882689 Parsing instance 124\n",
      "2020/01/13 14:03:24.968011 Parsing instance 125\n",
      "2020/01/13 14:03:25.034464 Parsing instance 126\n",
      "2020/01/13 14:03:25.075851 Parsing instance 127\n",
      "2020/01/13 14:03:25.144534 Parsing instance 128\n",
      "2020/01/13 14:03:25.187935 Parsing instance 129\n",
      "2020/01/13 14:03:25.237370 Parsing instance 130\n",
      "2020/01/13 14:03:25.300130 Parsing instance 131\n",
      "2020/01/13 14:03:25.365945 Parsing instance 132\n",
      "2020/01/13 14:03:25.407681 Parsing instance 133\n",
      "2020/01/13 14:03:25.517617 Parsing instance 134\n",
      "2020/01/13 14:03:25.537304 Parsing instance 135\n",
      "2020/01/13 14:03:25.749196 Parsing instance 136\n",
      "2020/01/13 14:03:25.932340 Parsing instance 137\n",
      "2020/01/13 14:03:26.047278 Parsing instance 138\n",
      "2020/01/13 14:03:26.134216 Parsing instance 139\n",
      "2020/01/13 14:03:26.160168 Parsing instance 140\n",
      "2020/01/13 14:03:26.307916 Parsing instance 141\n",
      "2020/01/13 14:03:26.361090 Parsing instance 142\n",
      "2020/01/13 14:03:26.449635 Parsing instance 143\n",
      "2020/01/13 14:03:26.571646 Parsing instance 144\n",
      "2020/01/13 14:03:26.599822 Parsing instance 145\n",
      "2020/01/13 14:03:26.652857 Parsing instance 146\n",
      "2020/01/13 14:03:26.672558 Parsing instance 147\n",
      "2020/01/13 14:03:26.703821 Parsing instance 148\n",
      "2020/01/13 14:03:26.756740 Parsing instance 149\n",
      "2020/01/13 14:03:27.034123 Parsing instance 150\n",
      "2020/01/13 14:03:27.330892 Parsing instance 151\n",
      "2020/01/13 14:03:27.345351 Parsing instance 152\n",
      "2020/01/13 14:03:27.353599 Parsing instance 153\n",
      "2020/01/13 14:03:27.463972 Parsing instance 154\n",
      "2020/01/13 14:03:27.472906 Parsing instance 155\n",
      "2020/01/13 14:03:27.782290 Parsing instance 156\n",
      "2020/01/13 14:03:28.076846 Parsing instance 157\n",
      "2020/01/13 14:03:28.145616 Parsing instance 158\n",
      "2020/01/13 14:03:28.162367 Parsing instance 159\n",
      "2020/01/13 14:03:28.190722 Parsing instance 160\n",
      "2020/01/13 14:03:28.307017 Parsing instance 161\n",
      "2020/01/13 14:03:28.325362 Parsing instance 162\n",
      "2020/01/13 14:03:28.407211 Parsing instance 163\n",
      "2020/01/13 14:03:28.652991 Parsing instance 164\n",
      "2020/01/13 14:03:28.834717 Parsing instance 165\n",
      "2020/01/13 14:03:28.844325 Parsing instance 166\n",
      "2020/01/13 14:03:28.871866 Parsing instance 167\n",
      "2020/01/13 14:03:28.947737 Parsing instance 168\n",
      "2020/01/13 14:03:28.989196 Parsing instance 169\n",
      "2020/01/13 14:03:29.423453 Parsing instance 170\n",
      "2020/01/13 14:03:29.498375 Parsing instance 171\n",
      "2020/01/13 14:03:29.725090 Parsing instance 172\n",
      "2020/01/13 14:03:29.790155 Parsing instance 173\n",
      "2020/01/13 14:03:29.937282 Parsing instance 174\n",
      "2020/01/13 14:03:30.330394 Parsing instance 175\n",
      "2020/01/13 14:03:30.368155 Parsing instance 176\n",
      "2020/01/13 14:03:30.486472 Parsing instance 177\n",
      "2020/01/13 14:03:30.624320 Parsing instance 178\n",
      "2020/01/13 14:03:30.772698 Parsing instance 179\n",
      "2020/01/13 14:03:30.782741 Parsing instance 180\n",
      "2020/01/13 14:03:30.810207 Parsing instance 181\n",
      "2020/01/13 14:03:30.871230 Parsing instance 182\n",
      "2020/01/13 14:03:31.226549 Parsing instance 183\n",
      "2020/01/13 14:03:31.462606 Parsing instance 184\n",
      "2020/01/13 14:03:31.577051 Parsing instance 185\n",
      "2020/01/13 14:03:31.729666 Parsing instance 186\n",
      "2020/01/13 14:03:31.870145 Parsing instance 187\n",
      "2020/01/13 14:03:31.935523 Parsing instance 188\n",
      "2020/01/13 14:03:31.945267 Parsing instance 189\n",
      "2020/01/13 14:03:31.975220 Parsing instance 190\n",
      "2020/01/13 14:03:32.148728 Parsing instance 191\n",
      "2020/01/13 14:03:32.323876 Parsing instance 192\n",
      "2020/01/13 14:03:32.429124 Parsing instance 193\n",
      "2020/01/13 14:03:32.514963 Parsing instance 194\n",
      "2020/01/13 14:03:32.600638 Parsing instance 195\n",
      "2020/01/13 14:03:32.757419 Parsing instance 196\n",
      "2020/01/13 14:03:32.838785 Parsing instance 197\n",
      "2020/01/13 14:03:32.896880 Parsing instance 198\n",
      "2020/01/13 14:03:33.024608 Parsing instance 199\n",
      "2020/01/13 14:03:33.046210 Parsing instance 200\n",
      "2020/01/13 14:03:33.166246 Parsing instance 201\n",
      "2020/01/13 14:03:33.200900 Parsing instance 202\n",
      "2020/01/13 14:03:33.277628 Parsing instance 203\n",
      "2020/01/13 14:03:33.307796 Parsing instance 204\n",
      "2020/01/13 14:03:33.418169 Parsing instance 205\n",
      "2020/01/13 14:03:33.427667 Parsing instance 206\n",
      "2020/01/13 14:03:33.437127 Parsing instance 207\n",
      "2020/01/13 14:03:33.499569 Parsing instance 208\n",
      "2020/01/13 14:03:33.865879 Parsing instance 209\n",
      "2020/01/13 14:03:33.939809 Parsing instance 210\n",
      "2020/01/13 14:03:34.084540 Parsing instance 211\n",
      "2020/01/13 14:03:34.183348 Parsing instance 212\n",
      "2020/01/13 14:03:34.304193 Parsing instance 213\n",
      "2020/01/13 14:03:34.370682 Parsing instance 214\n",
      "2020/01/13 14:03:34.472924 Parsing instance 215\n",
      "2020/01/13 14:03:34.896928 Parsing instance 216\n",
      "2020/01/13 14:03:34.906625 Parsing instance 217\n",
      "2020/01/13 14:03:34.988774 Parsing instance 218\n",
      "2020/01/13 14:03:35.093964 Parsing instance 219\n",
      "2020/01/13 14:03:35.361554 Parsing instance 220\n",
      "2020/01/13 14:03:35.514936 Parsing instance 221\n",
      "2020/01/13 14:03:35.593149 Parsing instance 222\n",
      "2020/01/13 14:03:35.643881 Parsing instance 223\n",
      "2020/01/13 14:03:35.752840 Parsing instance 224\n",
      "2020/01/13 14:03:36.226714 Parsing instance 225\n",
      "2020/01/13 14:03:36.305821 Parsing instance 226\n",
      "2020/01/13 14:03:36.365594 Parsing instance 227\n",
      "2020/01/13 14:03:36.610119 Parsing instance 228\n",
      "2020/01/13 14:03:37.370581 Parsing instance 229\n",
      "2020/01/13 14:03:37.375939 Parsing instance 230\n",
      "2020/01/13 14:03:37.518816 Parsing instance 231\n",
      "2020/01/13 14:03:37.626258 Parsing instance 232\n",
      "2020/01/13 14:03:37.675088 Parsing instance 233\n",
      "2020/01/13 14:03:37.781061 Parsing instance 234\n",
      "2020/01/13 14:03:37.901210 Parsing instance 235\n",
      "2020/01/13 14:03:38.015736 Parsing instance 236\n",
      "2020/01/13 14:03:38.323926 Parsing instance 237\n",
      "2020/01/13 14:03:38.475941 Parsing instance 238\n",
      "2020/01/13 14:03:38.686596 Parsing instance 239\n",
      "2020/01/13 14:03:39.045132 Parsing instance 240\n",
      "2020/01/13 14:03:39.146637 Parsing instance 241\n",
      "2020/01/13 14:03:39.421383 Parsing instance 242\n",
      "2020/01/13 14:03:39.513733 Parsing instance 243\n",
      "2020/01/13 14:03:39.576849 Parsing instance 244\n",
      "2020/01/13 14:03:39.719914 Parsing instance 245\n",
      "2020/01/13 14:03:39.729121 Parsing instance 246\n",
      "2020/01/13 14:03:39.758480 Parsing instance 247\n",
      "2020/01/13 14:03:39.810793 Parsing instance 248\n",
      "2020/01/13 14:03:40.029585 Parsing instance 249\n",
      "2020/01/13 14:03:40.075883 Parsing instance 250\n",
      "2020/01/13 14:03:40.173331 Parsing instance 251\n",
      "2020/01/13 14:03:40.276871 Parsing instance 252\n",
      "2020/01/13 14:03:40.596196 Parsing instance 253\n",
      "2020/01/13 14:03:40.605715 Parsing instance 254\n",
      "2020/01/13 14:03:40.645497 Parsing instance 255\n",
      "2020/01/13 14:03:40.767716 Parsing instance 256\n",
      "2020/01/13 14:03:40.884286 Parsing instance 257\n",
      "2020/01/13 14:03:41.017471 Parsing instance 258\n",
      "2020/01/13 14:03:41.282442 Parsing instance 259\n",
      "2020/01/13 14:03:41.304748 Parsing instance 260\n",
      "2020/01/13 14:03:41.695780 Parsing instance 261\n",
      "2020/01/13 14:03:41.810168 Parsing instance 262\n",
      "2020/01/13 14:03:41.943609 Parsing instance 263\n",
      "2020/01/13 14:03:42.297012 Parsing instance 264\n",
      "2020/01/13 14:03:42.302785 Parsing instance 265\n",
      "2020/01/13 14:03:42.428710 Parsing instance 266\n",
      "2020/01/13 14:03:42.466701 Parsing instance 267\n",
      "2020/01/13 14:03:42.539273 Parsing instance 268\n",
      "2020/01/13 14:03:42.906499 Parsing instance 269\n",
      "2020/01/13 14:03:42.996797 Parsing instance 270\n",
      "2020/01/13 14:03:43.215050 Parsing instance 271\n",
      "2020/01/13 14:03:43.267676 Parsing instance 272\n",
      "2020/01/13 14:03:43.357315 Parsing instance 273\n",
      "2020/01/13 14:03:43.402966 Parsing instance 274\n",
      "2020/01/13 14:03:43.652412 Parsing instance 275\n",
      "2020/01/13 14:03:43.779238 Parsing instance 276\n",
      "2020/01/13 14:03:44.003615 Parsing instance 277\n",
      "2020/01/13 14:03:44.230957 Parsing instance 278\n",
      "2020/01/13 14:03:44.330219 Parsing instance 279\n",
      "2020/01/13 14:03:44.406826 Parsing instance 280\n",
      "2020/01/13 14:03:44.545309 Parsing instance 281\n",
      "2020/01/13 14:03:44.685439 Parsing instance 282\n",
      "2020/01/13 14:03:44.722752 Parsing instance 283\n",
      "2020/01/13 14:03:44.809027 Parsing instance 284\n",
      "2020/01/13 14:03:44.854075 Parsing instance 285\n",
      "2020/01/13 14:03:45.154747 Parsing instance 286\n",
      "2020/01/13 14:03:45.210222 Parsing instance 287\n",
      "2020/01/13 14:03:45.262506 Parsing instance 288\n",
      "2020/01/13 14:03:45.384409 Parsing instance 289\n",
      "2020/01/13 14:03:45.397737 Parsing instance 290\n",
      "2020/01/13 14:03:45.421847 Parsing instance 291\n",
      "2020/01/13 14:03:45.466546 Parsing instance 292\n",
      "2020/01/13 14:03:45.490615 Parsing instance 293\n",
      "2020/01/13 14:03:45.639160 Parsing instance 294\n",
      "2020/01/13 14:03:45.724140 Parsing instance 295\n",
      "2020/01/13 14:03:45.749965 Parsing instance 296\n",
      "2020/01/13 14:03:45.838535 Parsing instance 297\n",
      "2020/01/13 14:03:45.923459 Parsing instance 298\n",
      "2020/01/13 14:03:45.965298 Parsing instance 299\n",
      "2020/01/13 14:03:46.277602 Parsing instance 300\n",
      "2020/01/13 14:03:46.309001 Parsing instance 301\n",
      "2020/01/13 14:03:46.460369 Parsing instance 302\n",
      "2020/01/13 14:03:46.511990 Parsing instance 303\n",
      "2020/01/13 14:03:46.543844 Parsing instance 304\n",
      "2020/01/13 14:03:46.687553 Parsing instance 305\n",
      "2020/01/13 14:03:47.514104 Parsing instance 306\n",
      "2020/01/13 14:03:47.670419 Parsing instance 307\n",
      "2020/01/13 14:03:47.750007 Parsing instance 308\n",
      "2020/01/13 14:03:47.837852 Parsing instance 309\n",
      "2020/01/13 14:03:47.947389 Parsing instance 310\n",
      "2020/01/13 14:03:47.991189 Parsing instance 311\n",
      "2020/01/13 14:03:48.016302 Parsing instance 312\n",
      "2020/01/13 14:03:48.050170 Parsing instance 313\n",
      "2020/01/13 14:03:48.088956 Parsing instance 314\n",
      "2020/01/13 14:03:48.146766 Parsing instance 315\n",
      "2020/01/13 14:03:48.208327 Parsing instance 316\n",
      "2020/01/13 14:03:48.250319 Parsing instance 317\n",
      "2020/01/13 14:03:48.519601 Parsing instance 318\n",
      "2020/01/13 14:03:48.634226 Parsing instance 319\n",
      "2020/01/13 14:03:48.887945 Parsing instance 320\n",
      "2020/01/13 14:03:48.920126 Parsing instance 321\n",
      "2020/01/13 14:03:48.939820 Parsing instance 322\n",
      "2020/01/13 14:03:49.303253 Parsing instance 323\n",
      "2020/01/13 14:03:49.357829 Parsing instance 324\n",
      "2020/01/13 14:03:49.406650 Parsing instance 325\n",
      "2020/01/13 14:03:49.430527 Parsing instance 326\n",
      "2020/01/13 14:03:49.842052 Parsing instance 327\n",
      "2020/01/13 14:03:49.954651 Parsing instance 328\n",
      "2020/01/13 14:03:50.073265 Parsing instance 329\n",
      "2020/01/13 14:03:50.219893 Parsing instance 330\n",
      "2020/01/13 14:03:50.347502 Parsing instance 331\n",
      "2020/01/13 14:03:50.393390 Parsing instance 332\n",
      "2020/01/13 14:03:50.492270 Parsing instance 333\n",
      "2020/01/13 14:03:50.711425 Parsing instance 334\n",
      "2020/01/13 14:03:50.840980 Parsing instance 335\n",
      "2020/01/13 14:03:50.920749 Parsing instance 336\n",
      "2020/01/13 14:03:51.046911 Parsing instance 337\n",
      "2020/01/13 14:03:51.173583 Parsing instance 338\n",
      "2020/01/13 14:03:51.232853 Parsing instance 339\n",
      "2020/01/13 14:03:51.284816 Parsing instance 340\n",
      "2020/01/13 14:03:51.307928 Parsing instance 341\n",
      "2020/01/13 14:03:51.401415 Parsing instance 342\n",
      "2020/01/13 14:03:51.434118 Parsing instance 343\n",
      "2020/01/13 14:03:51.496044 Parsing instance 344\n",
      "2020/01/13 14:03:51.571837 Parsing instance 345\n",
      "2020/01/13 14:03:51.710752 Parsing instance 346\n",
      "2020/01/13 14:03:51.904887 Parsing instance 347\n",
      "2020/01/13 14:03:52.080623 Parsing instance 348\n",
      "2020/01/13 14:03:52.152823 Parsing instance 349\n",
      "2020/01/13 14:03:52.304656 Parsing instance 350\n",
      "2020/01/13 14:03:52.487914 Parsing instance 351\n",
      "2020/01/13 14:03:52.644280 Parsing instance 352\n",
      "2020/01/13 14:03:52.669634 Parsing instance 353\n",
      "2020/01/13 14:03:52.784213 Parsing instance 354\n",
      "2020/01/13 14:03:52.810812 Parsing instance 355\n",
      "2020/01/13 14:03:52.876990 Parsing instance 356\n",
      "2020/01/13 14:03:53.005406 Parsing instance 357\n",
      "2020/01/13 14:03:53.286554 Parsing instance 358\n",
      "2020/01/13 14:03:53.307187 Parsing instance 359\n",
      "2020/01/13 14:03:53.409230 Parsing instance 360\n",
      "2020/01/13 14:03:53.456864 Parsing instance 361\n",
      "2020/01/13 14:03:53.533522 Parsing instance 362\n",
      "2020/01/13 14:03:53.631453 Parsing instance 363\n",
      "2020/01/13 14:03:53.709730 Parsing instance 364\n",
      "2020/01/13 14:03:53.725651 Parsing instance 365\n",
      "2020/01/13 14:03:53.733888 Parsing instance 366\n",
      "2020/01/13 14:03:53.837375 Parsing instance 367\n",
      "2020/01/13 14:03:53.991588 Parsing instance 368\n",
      "2020/01/13 14:03:54.058573 Parsing instance 369\n",
      "2020/01/13 14:03:54.384664 Parsing instance 370\n",
      "2020/01/13 14:03:54.446761 Parsing instance 371\n",
      "2020/01/13 14:03:54.508715 Parsing instance 372\n",
      "2020/01/13 14:03:54.550825 Parsing instance 373\n",
      "2020/01/13 14:03:54.576639 Parsing instance 374\n",
      "2020/01/13 14:03:54.630506 Parsing instance 375\n",
      "2020/01/13 14:03:54.746542 Parsing instance 376\n",
      "2020/01/13 14:03:54.806277 Parsing instance 377\n",
      "2020/01/13 14:03:54.888734 Parsing instance 378\n",
      "2020/01/13 14:03:54.975839 Parsing instance 379\n",
      "2020/01/13 14:03:55.009739 Parsing instance 380\n",
      "2020/01/13 14:03:55.027798 Parsing instance 381\n",
      "2020/01/13 14:03:55.143358 Parsing instance 382\n",
      "2020/01/13 14:03:55.183782 Parsing instance 383\n",
      "2020/01/13 14:03:55.272770 Parsing instance 384\n",
      "2020/01/13 14:03:55.484994 Parsing instance 385\n",
      "2020/01/13 14:03:55.540556 Parsing instance 386\n",
      "2020/01/13 14:03:55.678123 Parsing instance 387\n",
      "2020/01/13 14:03:55.820404 Parsing instance 388\n",
      "2020/01/13 14:03:55.846163 Parsing instance 389\n",
      "2020/01/13 14:03:55.887669 Parsing instance 390\n",
      "2020/01/13 14:03:55.948014 Parsing instance 391\n",
      "2020/01/13 14:03:56.007871 Parsing instance 392\n",
      "2020/01/13 14:03:56.114174 Parsing instance 393\n",
      "2020/01/13 14:03:56.206608 Parsing instance 394\n",
      "2020/01/13 14:03:56.327397 Parsing instance 395\n",
      "2020/01/13 14:03:56.446815 Parsing instance 396\n",
      "2020/01/13 14:03:56.755849 Parsing instance 397\n",
      "2020/01/13 14:03:56.964211 Parsing instance 398\n",
      "2020/01/13 14:03:56.987363 Parsing instance 399\n",
      "2020/01/13 14:03:57.092753 Parsing instance 400\n",
      "2020/01/13 14:03:57.248004 Parsing instance 401\n",
      "2020/01/13 14:03:57.352360 Parsing instance 402\n",
      "2020/01/13 14:03:57.411452 Parsing instance 403\n",
      "2020/01/13 14:03:57.473702 Parsing instance 404\n",
      "2020/01/13 14:03:57.575331 Parsing instance 405\n",
      "2020/01/13 14:03:57.626398 Parsing instance 406\n",
      "2020/01/13 14:03:57.677246 Parsing instance 407\n",
      "2020/01/13 14:03:57.958457 Parsing instance 408\n",
      "2020/01/13 14:03:58.201356 Parsing instance 409\n",
      "2020/01/13 14:03:58.217789 Parsing instance 410\n",
      "2020/01/13 14:03:58.264077 Parsing instance 411\n",
      "2020/01/13 14:03:58.437087 Parsing instance 412\n",
      "2020/01/13 14:03:58.485491 Parsing instance 413\n",
      "2020/01/13 14:03:58.558662 Parsing instance 414\n",
      "2020/01/13 14:03:58.579988 Parsing instance 415\n",
      "2020/01/13 14:03:58.621533 Parsing instance 416\n",
      "2020/01/13 14:03:59.049783 Parsing instance 417\n",
      "2020/01/13 14:03:59.098002 Parsing instance 418\n",
      "2020/01/13 14:03:59.189282 Parsing instance 419\n",
      "2020/01/13 14:03:59.266567 Parsing instance 420\n",
      "2020/01/13 14:03:59.297763 Parsing instance 421\n",
      "2020/01/13 14:03:59.426260 Parsing instance 422\n",
      "2020/01/13 14:03:59.434023 Parsing instance 423\n",
      "2020/01/13 14:03:59.454124 Parsing instance 424\n",
      "2020/01/13 14:03:59.479525 Parsing instance 425\n",
      "2020/01/13 14:03:59.523890 Parsing instance 426\n",
      "2020/01/13 14:03:59.571074 Parsing instance 427\n",
      "2020/01/13 14:03:59.686726 Parsing instance 428\n",
      "2020/01/13 14:03:59.824073 Parsing instance 429\n",
      "2020/01/13 14:03:59.958487 Parsing instance 430\n",
      "2020/01/13 14:04:00.084101 Parsing instance 431\n",
      "2020/01/13 14:04:00.307619 Parsing instance 432\n",
      "2020/01/13 14:04:00.357778 Parsing instance 433\n",
      "2020/01/13 14:04:00.385621 Parsing instance 434\n",
      "2020/01/13 14:04:00.411390 Parsing instance 435\n",
      "2020/01/13 14:04:00.439929 Parsing instance 436\n",
      "2020/01/13 14:04:00.502321 Parsing instance 437\n",
      "2020/01/13 14:04:00.523962 Parsing instance 438\n",
      "2020/01/13 14:04:00.588524 Parsing instance 439\n",
      "2020/01/13 14:04:00.648413 Parsing instance 440\n",
      "2020/01/13 14:04:00.696489 Parsing instance 441\n",
      "2020/01/13 14:04:00.871567 Parsing instance 442\n",
      "2020/01/13 14:04:00.982770 Parsing instance 443\n",
      "2020/01/13 14:04:01.067565 Parsing instance 444\n",
      "2020/01/13 14:04:01.249873 Parsing instance 445\n",
      "2020/01/13 14:04:01.488957 Parsing instance 446\n",
      "2020/01/13 14:04:01.507260 Parsing instance 447\n",
      "2020/01/13 14:04:01.635406 Parsing instance 448\n",
      "2020/01/13 14:04:01.837523 Parsing instance 449\n",
      "2020/01/13 14:04:01.855632 Parsing instance 450\n",
      "2020/01/13 14:04:01.886122 Parsing instance 451\n",
      "2020/01/13 14:04:02.006402 Parsing instance 452\n",
      "2020/01/13 14:04:02.021655 Parsing instance 453\n",
      "2020/01/13 14:04:02.046507 Parsing instance 454\n",
      "2020/01/13 14:04:02.219417 Parsing instance 455\n",
      "2020/01/13 14:04:02.230256 Parsing instance 456\n",
      "2020/01/13 14:04:02.238402 Parsing instance 457\n",
      "2020/01/13 14:04:02.255719 Parsing instance 458\n",
      "2020/01/13 14:04:02.318560 Parsing instance 459\n",
      "2020/01/13 14:04:02.402622 Parsing instance 460\n",
      "2020/01/13 14:04:02.477708 Parsing instance 461\n",
      "2020/01/13 14:04:02.644373 Parsing instance 462\n",
      "2020/01/13 14:04:02.842170 Parsing instance 463\n",
      "2020/01/13 14:04:02.887513 Parsing instance 464\n",
      "2020/01/13 14:04:02.921399 Parsing instance 465\n",
      "2020/01/13 14:04:02.970043 Parsing instance 466\n",
      "2020/01/13 14:04:03.029018 Parsing instance 467\n",
      "2020/01/13 14:04:03.046540 Parsing instance 468\n",
      "2020/01/13 14:04:03.108581 Parsing instance 469\n",
      "2020/01/13 14:04:03.236911 Parsing instance 470\n",
      "2020/01/13 14:04:03.277589 Parsing instance 471\n",
      "2020/01/13 14:04:03.347080 Parsing instance 472\n",
      "2020/01/13 14:04:03.361262 Parsing instance 473\n",
      "2020/01/13 14:04:03.409862 Parsing instance 474\n",
      "2020/01/13 14:04:03.466391 Parsing instance 475\n",
      "2020/01/13 14:04:03.488386 Parsing instance 476\n",
      "2020/01/13 14:04:03.507320 Parsing instance 477\n",
      "2020/01/13 14:04:03.527921 Parsing instance 478\n",
      "2020/01/13 14:04:03.822498 Parsing instance 479\n",
      "2020/01/13 14:04:03.838064 Parsing instance 480\n",
      "2020/01/13 14:04:03.868489 Parsing instance 481\n",
      "2020/01/13 14:04:03.908400 Parsing instance 482\n",
      "2020/01/13 14:04:03.931692 Parsing instance 483\n",
      "2020/01/13 14:04:03.990164 Parsing instance 484\n",
      "2020/01/13 14:04:04.041608 Parsing instance 485\n",
      "2020/01/13 14:04:04.081954 Parsing instance 486\n",
      "2020/01/13 14:04:04.175557 Parsing instance 487\n",
      "2020/01/13 14:04:04.272557 Parsing instance 488\n",
      "2020/01/13 14:04:04.363634 Parsing instance 489\n",
      "2020/01/13 14:04:04.374988 Parsing instance 490\n",
      "2020/01/13 14:04:04.404219 Parsing instance 491\n",
      "2020/01/13 14:04:04.486153 Parsing instance 492\n",
      "2020/01/13 14:04:04.568406 Parsing instance 493\n",
      "2020/01/13 14:04:04.625444 Parsing instance 494\n",
      "2020/01/13 14:04:04.640551 Parsing instance 495\n",
      "2020/01/13 14:04:04.685786 Parsing instance 496\n",
      "2020/01/13 14:04:04.999651 Parsing instance 497\n",
      "2020/01/13 14:04:05.040212 Parsing instance 498\n",
      "2020/01/13 14:04:05.052848 Parsing instance 499\n",
      "2020/01/13 14:04:05.067247 PARSE Total Time: 58.488093205s\n",
      "2020/01/13 14:04:05.067294 Converting 500 to conll\n",
      "2020/01/13 14:04:05.067305 Writing to output file\n",
      "2020/01/13 14:04:05.117736 Wrote 500 in conll format to final_setup/pruned/dev_pruned_all_keep.conll\n",
      "2020/01/13 14:04:05.117758 Writing to segmentation file\n",
      "2020/01/13 14:04:05.172236 Wrote 500 in segmentation format to final_setup/pruned/dev_pruned_all_keep.seg\n",
      "2020/01/13 14:04:05.172280 Writing to mapping file\n",
      "2020/01/13 14:04:05.387415 Wrote 500 in mapping format to final_setup/pruned/dev_pruned_all_keep.map\n",
      "2020/01/13 14:04:05.387448 Writing to gold segmentation file\n"
     ]
    }
   ],
   "source": [
    "!{yap_path} joint -in final_setup/pruned/dev_pruned_all_keep.lattices -os final_setup/pruned/dev_pruned_all_keep.seg -om final_setup/pruned/dev_pruned_all_keep.map -oc final_setup/pruned/dev_pruned_all_keep.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_out_non_o_keep = bclm.read_yap_output(treebank_set=None, tokens_path=bclm.TREEBANK_TOKEN_PATHS['dev'], \n",
    "                                     dep_path='final_setup/pruned/dev_pruned_non_o_keep.conll',\n",
    "                                     map_path='final_setup/pruned/dev_pruned_non_o_keep.map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_out_all_keep = bclm.read_yap_output(treebank_set=None, tokens_path=bclm.TREEBANK_TOKEN_PATHS['dev'], \n",
    "                                     dep_path='final_setup/pruned/dev_pruned_all_keep.conll',\n",
    "                                     map_path='final_setup/pruned/dev_pruned_all_keep.map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold = bclm.read_dataframe('spmrl', subset='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap_dev_regular = bclm.read_yap_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10445 correct.\n",
      "Precision: 91.41\n",
      "Recall:    92.43\n",
      "F1:        91.92\n",
      "FP ex.: [(1, 5, 'לישראל', 'NNP'), (1, 8, 'ה', 'DEF'), (2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN')]\n",
      "FN ex.: [(1, 5, 'ישראל', 'NNP'), (1, 5, 'ל', 'PREPOSITION'), (2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.41431822159986, 92.42544907530306, 91.91710300523606)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11405 predicted, 10492 correct.\n",
      "Precision: 91.99\n",
      "Recall:    92.84\n",
      "F1:        92.42\n",
      "FP ex.: [(2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN'), (4, 19, 'פחות', 'NN'), (5, 9, 'ה', 'DEF')]\n",
      "FN ex.: [(2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN'), (4, 19, 'פחות', 'RB'), (5, 9, 'מזכיר', 'NNT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.99473914949583, 92.84134147420582, 92.41610147097681)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11301 predicted, 10515 correct.\n",
      "Precision: 93.04\n",
      "Recall:    93.04\n",
      "F1:        93.04\n",
      "FP ex.: [(2, 11, 'דנה', 'BN'), (3, 4, 'ח\"כ', 'NNT'), (3, 28, 'הם', 'S-PRN'), (5, 13, 'ה', 'DEF'), (6, 24, 'ה', 'REL')]\n",
      "FN ex.: [(2, 11, 'דנה', 'VB'), (3, 4, 'ח\"כ', 'NN'), (3, 28, 'המ', 'S-PRN'), (6, 24, 'ה', 'DEF'), (8, 1, 'מרגלית', 'NNP')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.04486328643483, 93.04486328643483, 93.04486328643482)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_all_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sent_id', 'token_id', 'upostag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11426 predicted, 10541 correct.\n",
      "Precision: 92.25\n",
      "Recall:    93.27\n",
      "F1:        92.76\n",
      "FP ex.: [(1, 8, 'DEF'), (2, 11, 'BN'), (3, 4, 'NNT'), (4, 19, 'NN'), (5, 9, 'DEF')]\n",
      "FN ex.: [(1, 5, 'PREPOSITION'), (2, 11, 'VB'), (3, 4, 'NN'), (4, 19, 'RB'), (5, 9, 'NNT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.25450726413443, 93.27493142199805, 92.76191314295771)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11405 predicted, 10576 correct.\n",
      "Precision: 92.73\n",
      "Recall:    93.58\n",
      "F1:        93.16\n",
      "FP ex.: [(2, 11, 'BN'), (3, 4, 'NNT'), (4, 19, 'NN'), (5, 9, 'DEF'), (5, 9, 'NN')]\n",
      "FN ex.: [(2, 11, 'VB'), (3, 4, 'NN'), (4, 19, 'RB'), (5, 9, 'NNT'), (6, 25, 'NNT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.73125822007891, 93.58463852756394, 93.15599401039374)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301 gold tokens/morphems, 11301 predicted, 10602 correct.\n",
      "Precision: 93.81\n",
      "Recall:    93.81\n",
      "F1:        93.81\n",
      "FP ex.: [(2, 11, 'BN'), (3, 4, 'NNT'), (5, 13, 'DEF'), (6, 24, 'REL'), (8, 1, 'NNT')]\n",
      "FN ex.: [(2, 11, 'VB'), (3, 4, 'NN'), (6, 24, 'DEF'), (8, 1, 'NNP'), (8, 17, 'VB')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.81470666312715, 93.81470666312715, 93.81470666312717)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_dfs(dev_gold, yap_out_all_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evluate Token Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/danb/bclm/evaluations.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gold_df['upostag'] = gold_df.upostag.str.replace('_','-')\n",
      "/home/nlp/danb/bclm/evaluations.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['upostag'] = pred_df.upostag.str.replace('_','-')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.39245106083693, 92.66107920134412, 92.47467220389504)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.84276950728714, 93.06548665650764, 92.90810545294192)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.27550502090416, 93.33313796741297, 93.27243498501264)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11426, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.07232446372053, 93.42691360919001, 93.13696267394545)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_dev_regular, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11405, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.40346969874575, 93.73754542257649, 93.47466662201161)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_non_o_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11301, 27) (11301, 13)\n",
      "(8531,) (8531,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.8264369163443, 93.94463329816746, 93.82024102572689)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclm.evaluate_means(dev_gold, yap_out_all_keep, cols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #Segment accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = dev_gold.groupby(['sent_id', 'token_id', 'token_str']).size().reset_index().rename(columns={0: 'morpheme_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str  morpheme_count\n",
       "0        1         1     עשרות               1\n",
       "1        1         2     אנשים               1\n",
       "2        1         3    מגיעים               1\n",
       "3        1         4   מתאילנד               2\n",
       "4        1         5    לישראל               2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8531, 8531)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ps), len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974328918063533"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ps.biose_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835616438356164"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[(ps.biose.str.contains('-'))].biose_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9734649403922574"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ps[~(ps.biose.str.contains('-'))].biose_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6078\n",
       "2    2143\n",
       "3     303\n",
       "4       7\n",
       "Name: morpheme_count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.morpheme_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6056\n",
       "2    2156\n",
       "3     316\n",
       "4       3\n",
       "Name: biose_count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.biose_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>במלחמת</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>שכונת</td>\n",
       "      <td>O^B-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>I-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>227</td>\n",
       "      <td>6</td>\n",
       "      <td>לנקובסקי</td>\n",
       "      <td>O^S-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>229</td>\n",
       "      <td>8</td>\n",
       "      <td>שקריסטול</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>O^B-GPE^E-GPE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>לאקספרס</td>\n",
       "      <td>B-ORG^E-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>בלין</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id token_str          biose  biose_count\n",
       "633        30         1    במלחמת  O^B-LOC^I-LOC            3\n",
       "641        30         9     שכונת        O^B-LOC            2\n",
       "2075      103        16    הארקין    B-ORG^E-ORG            2\n",
       "2212      110         6    הארקין    B-ORG^E-ORG            2\n",
       "4133      225        13     הדסון    I-ORG^E-ORG            2\n",
       "4180      227         6  לנקובסקי        O^S-PER            2\n",
       "4232      229         8  שקריסטול          S-PER            1\n",
       "4478      239        26     באיסט        O^B-GPE            2\n",
       "6254      337         1      בארץ  O^B-GPE^E-GPE            3\n",
       "6573      356        11       בשן          S-PER            1\n",
       "7198      398         7   לאקספרס    B-ORG^E-ORG            2\n",
       "7376      408         6      בלין          S-PER            1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>biose</th>\n",
       "      <th>biose_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>כברית</td>\n",
       "      <td>O^B-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>המועצות</td>\n",
       "      <td>I-GPE^E-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>במערב</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>גימי</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "      <td>קרטר</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>איובה</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>דה</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>מוין</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>88</td>\n",
       "      <td>11</td>\n",
       "      <td>רגיסטר</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>באנגלית</td>\n",
       "      <td>O^S-ANG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>שלום</td>\n",
       "      <td>B-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>עכשיו</td>\n",
       "      <td>E-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>וייטנאם</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>גורג</td>\n",
       "      <td>S-WOA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>גורג</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>בוש</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>O^B-PER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>הארקין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>95</td>\n",
       "      <td>23</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>95</td>\n",
       "      <td>27</td>\n",
       "      <td>המפרץ</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>בית</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>המשפט</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>הבין</td>\n",
       "      <td>I-ORG^I-ORG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>לאומי</td>\n",
       "      <td>E-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>בהאג</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>המערב</td>\n",
       "      <td>B-LOC^I-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>התיכון</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>98</td>\n",
       "      <td>26</td>\n",
       "      <td>ארה\"ב</td>\n",
       "      <td>S-GPE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>98</td>\n",
       "      <td>36</td>\n",
       "      <td>סדאם</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "      <td>חוסיין</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>במפרץ</td>\n",
       "      <td>O^B-LOC^I-LOC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>הפרסי</td>\n",
       "      <td>I-LOC^E-LOC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>באיובה</td>\n",
       "      <td>O^S-GPE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>טום</td>\n",
       "      <td>S-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>טום</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>טקי</td>\n",
       "      <td>E-PER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id  token_str          biose  biose_count\n",
       "1693       82         6      ארה\"ב          S-GPE            1\n",
       "1700       82        13      כברית        O^B-GPE            2\n",
       "1701       82        14    המועצות    I-GPE^E-GPE            2\n",
       "1705       83         3      איובה          S-GPE            1\n",
       "1712       83        10      במערב  O^B-LOC^I-LOC            3\n",
       "1713       83        11     התיכון    I-LOC^E-LOC            2\n",
       "1719       83        17       גימי          B-PER            1\n",
       "1720       83        18       קרטר          E-PER            1\n",
       "1730       83        28  לאפגניסטן        O^S-GPE            2\n",
       "1732       84         1      איובה          S-GPE            1\n",
       "1751       85        11     בארה\"ב        O^S-GPE            2\n",
       "1763       86         7     באיובה        O^S-GPE            2\n",
       "1780       87         9      במפרץ  O^B-LOC^I-LOC            3\n",
       "1781       87        10      הפרסי    I-LOC^E-LOC            2\n",
       "1791       88         9         דה          B-ORG            1\n",
       "1792       88        10       מוין          I-ORG            1\n",
       "1793       88        11     רגיסטר          E-ORG            1\n",
       "1809       89         5    באנגלית        O^S-ANG            2\n",
       "1812       89         8       שלום          B-WOA            1\n",
       "1813       89         9      עכשיו          E-WOA            1\n",
       "1826       90        11    וייטנאם          S-GPE            1\n",
       "1856       92        17       גורג          S-PER            1\n",
       "1860       92        21    וייטנאם          S-GPE            1\n",
       "1864       93         2       גורג          S-WOA            1\n",
       "1868       93         6       גורג          B-PER            1\n",
       "1869       93         7        בוש          E-PER            1\n",
       "1900       95         4       לטום        O^B-PER            2\n",
       "1901       95         5     הארקין          E-PER            1\n",
       "1919       95        23      ארה\"ב          S-GPE            1\n",
       "1923       95        27      המפרץ    B-LOC^I-LOC            2\n",
       "1924       95        28      הפרסי    I-LOC^E-LOC            2\n",
       "1933       95        37        בית          B-ORG            1\n",
       "1934       95        38      המשפט    I-ORG^I-ORG            2\n",
       "1935       95        39       הבין    I-ORG^I-ORG            2\n",
       "1936       95        40          -          I-ORG            1\n",
       "1937       95        41      לאומי          E-ORG            1\n",
       "1939       95        43       בהאג        O^S-GPE            2\n",
       "1955       97         9     בארה\"ב        O^S-GPE            2\n",
       "1964       98         2      המערב    B-LOC^I-LOC            2\n",
       "1965       98         3     התיכון    I-LOC^E-LOC            2\n",
       "1967       98         5      ארה\"ב          S-GPE            1\n",
       "1988       98        26      ארה\"ב          S-GPE            1\n",
       "1998       98        36       סדאם          B-PER            1\n",
       "1999       98        37     חוסיין          E-PER            1\n",
       "2002       99         2      במפרץ  O^B-LOC^I-LOC            3\n",
       "2003       99         3      הפרסי    I-LOC^E-LOC            2\n",
       "2009       99         9     באיובה        O^S-GPE            2\n",
       "2011      100         1        טום          S-PER            1\n",
       "2018      100         8        טום          B-PER            1\n",
       "2019      100         9        טקי          E-PER            1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[(ps.biose_count==gs.morpheme_count) & (ps.biose.str.contains('-'))].iloc[140:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag\n",
       "0        1         1     עשרות              CDT\n",
       "1        1         2     אנשים               NN\n",
       "2        1         3    מגיעים               BN\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP\n",
       "4        1         5    לישראל              NNP"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = bclm.get_token_df(bclm.read_yap_output(treebank_set='dev'), fields=['upostag'])\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>עשרות</td>\n",
       "      <td>CDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>אנשים</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>מגיעים</td>\n",
       "      <td>BN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>מתאילנד</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id  token_id token_str          upostag  morpheme_count\n",
       "0        1         1     עשרות              CDT               1\n",
       "1        1         2     אנשים               NN               1\n",
       "2        1         3    מגיעים               BN               1\n",
       "3        1         4   מתאילנד  PREPOSITION^NNP               2\n",
       "4        1         5    לישראל              NNP               1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['morpheme_count'] = ys.upostag.apply(lambda x: len(x.split('^')))\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597936935880905"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys.morpheme_count, gs.morpheme_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260273972602739"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[(ps.biose.str.contains('-'))].morpheme_count, gs[(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629534675041661"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ys[~(ps.biose.str.contains('-'))].morpheme_count, gs[~(ps.biose.str.contains('-'))].morpheme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>upostag</th>\n",
       "      <th>morpheme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>שצה\"ל</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>כמנזר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>ביחד</td>\n",
       "      <td>PREPOSITION^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "      <td>ואד</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>אלי</td>\n",
       "      <td>IN^S_PRN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>לטום</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>שלמה</td>\n",
       "      <td>REL^QW</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>לשיקאגו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>לניו</td>\n",
       "      <td>BN^POS^S_PRN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>בבוסטון</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>לישראל</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>בשיקאגו</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>לירושלים</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>בירושלים</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>בצלם</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>ואראלה</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>ואיה</td>\n",
       "      <td>CONJ^RB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>161</td>\n",
       "      <td>17</td>\n",
       "      <td>בלוס</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>213</td>\n",
       "      <td>8</td>\n",
       "      <td>בבלאגיו</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>224</td>\n",
       "      <td>16</td>\n",
       "      <td>לזלי</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>הדסון</td>\n",
       "      <td>DEF^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>229</td>\n",
       "      <td>48</td>\n",
       "      <td>בראדלו</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>231</td>\n",
       "      <td>8</td>\n",
       "      <td>שקרן</td>\n",
       "      <td>NNT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>232</td>\n",
       "      <td>14</td>\n",
       "      <td>לאחד</td>\n",
       "      <td>PREPOSITION^CD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>לקרן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>239</td>\n",
       "      <td>26</td>\n",
       "      <td>באיסט</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>245</td>\n",
       "      <td>5</td>\n",
       "      <td>למקורות</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>245</td>\n",
       "      <td>16</td>\n",
       "      <td>ברוקינגס</td>\n",
       "      <td>PREPOSITION^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>לאפגניסטן</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>בקליפורניה</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>294</td>\n",
       "      <td>19</td>\n",
       "      <td>לסילבר</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>294</td>\n",
       "      <td>26</td>\n",
       "      <td>וולד</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>323</td>\n",
       "      <td>34</td>\n",
       "      <td>מניו</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>327</td>\n",
       "      <td>22</td>\n",
       "      <td>בניו</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>327</td>\n",
       "      <td>33</td>\n",
       "      <td>ויטמן</td>\n",
       "      <td>CONJ^VB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>330</td>\n",
       "      <td>13</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6254</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>בארץ</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>בשן</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>בטקסס</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>370</td>\n",
       "      <td>15</td>\n",
       "      <td>ורמונט</td>\n",
       "      <td>CONJ^NN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>376</td>\n",
       "      <td>23</td>\n",
       "      <td>ולסטון</td>\n",
       "      <td>CONJ^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>378</td>\n",
       "      <td>5</td>\n",
       "      <td>במינסוטה</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>384</td>\n",
       "      <td>14</td>\n",
       "      <td>בארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>לסנאט</td>\n",
       "      <td>PREPOSITION^NNT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>412</td>\n",
       "      <td>26</td>\n",
       "      <td>ובאיטליה</td>\n",
       "      <td>CONJ^PREPOSITION^DEF^NNP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>416</td>\n",
       "      <td>4</td>\n",
       "      <td>בוסקה</td>\n",
       "      <td>PREPOSITION^DEF^NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>439</td>\n",
       "      <td>11</td>\n",
       "      <td>מארה\"ב</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>כהן</td>\n",
       "      <td>ADVERB^PRP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>455</td>\n",
       "      <td>16</td>\n",
       "      <td>לכנסת</td>\n",
       "      <td>PREPOSITION^NNP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>496</td>\n",
       "      <td>8</td>\n",
       "      <td>ליוסי</td>\n",
       "      <td>PREPOSITION^DEF^NNP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent_id  token_id   token_str                   upostag  morpheme_count\n",
       "4           1         5      לישראל                       NNP               1\n",
       "766        37         3       שצה\"ל                       NNP               1\n",
       "819        40         9       כמנזר        PREPOSITION^DEF^NN               3\n",
       "1168       56        30        ביחד            PREPOSITION^RB               2\n",
       "1182       57        12    לירושלים                       NNP               1\n",
       "1193       57        23         ואד                   CONJ^NN               2\n",
       "1199       57        29         אלי                  IN^S_PRN               2\n",
       "1222       58        12    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "1730       83        28   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "1900       95         4        לטום                       NNP               1\n",
       "2441      121         8        שלמה                    REL^QW               2\n",
       "2549      128         7     לשיקאגו                       NNP               1\n",
       "2552      128        10        לניו              BN^POS^S_PRN               3\n",
       "2564      129         9     בבוסטון       PREPOSITION^DEF^NNP               3\n",
       "2575      130        10      לישראל       PREPOSITION^DEF^NNP               3\n",
       "2630      135         2     בשיקאגו       PREPOSITION^DEF^NNP               3\n",
       "2632      135         4    לירושלים       PREPOSITION^DEF^NNP               3\n",
       "2636      136         3    בירושלים                       NNP               1\n",
       "2746      143         2        בצלם           PREPOSITION^NNT               2\n",
       "2993      159         5      ואראלה                  CONJ^NNP               2\n",
       "3014      161        11        ואיה                   CONJ^RB               2\n",
       "3020      161        17        בלוס                        VB               1\n",
       "3884      213         8     בבלאגיו        PREPOSITION^DEF^NN               3\n",
       "4114      224        16        לזלי            PREPOSITION^NN               2\n",
       "4133      225        13       הדסון                    DEF^NN               2\n",
       "4272      229        48      בראדלו            PREPOSITION^NN               2\n",
       "4294      231         8        שקרן                       NNT               1\n",
       "4324      232        14        לאחד            PREPOSITION^CD               2\n",
       "4427      238         2        לקרן        PREPOSITION^DEF^NN               3\n",
       "4478      239        26       באיסט           PREPOSITION^NNP               2\n",
       "4604      245         5     למקורות        PREPOSITION^DEF^NN               3\n",
       "4615      245        16    ברוקינגס            PREPOSITION^NN               2\n",
       "4684      250         4   לאפגניסטן       PREPOSITION^DEF^NNP               3\n",
       "5228      278         1  בקליפורניה                       NNP               1\n",
       "5490      294        19      לסילבר        PREPOSITION^DEF^NN               3\n",
       "5497      294        26        וולד                  CONJ^NNP               2\n",
       "6018      323        34        מניו                       NNP               1\n",
       "6085      327        22        בניו                        NN               1\n",
       "6096      327        33       ויטמן                   CONJ^VB               2\n",
       "6149      330        13      בארה\"ב                       NNP               1\n",
       "6254      337         1        בארץ        PREPOSITION^DEF^NN               3\n",
       "6573      356        11         בשן        PREPOSITION^DEF^NN               3\n",
       "6577      357         2       בטקסס                        NN               1\n",
       "6792      370        15      ורמונט                   CONJ^NN               2\n",
       "6873      376        23      ולסטון                  CONJ^NNP               2\n",
       "6892      378         5    במינסוטה       PREPOSITION^DEF^NNP               3\n",
       "6985      384        14      בארה\"ב                        NN               1\n",
       "7083      392         5       לסנאט           PREPOSITION^NNT               2\n",
       "7464      412        26    ובאיטליה  CONJ^PREPOSITION^DEF^NNP               4\n",
       "7505      416         4       בוסקה        PREPOSITION^DEF^NN               3\n",
       "7806      439        11      מארה\"ב                        NN               1\n",
       "7913      445        15         כהן                ADVERB^PRP               2\n",
       "8048      455        16       לכנסת           PREPOSITION^NNP               2\n",
       "8492      496         8       ליוסי       PREPOSITION^DEF^NNP               3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[(ys.morpheme_count!=gs.morpheme_count) & (ps.biose.str.contains('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
